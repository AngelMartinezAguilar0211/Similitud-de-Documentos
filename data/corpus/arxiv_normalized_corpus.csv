DOI	Title	Authors	Abstract	Section	Date
10.48550/arXiv.2510.05096	paper2video : automatic video generation from scientific paper	Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou	academic presentation video have become an essential medium for research communication , yet produce them remain highly labor-intensive , often require hour of slide design , recording , and edit for a short 2 to 10 minute video . unlike natural video , presentation video generation involve distinctive challenge : input from research paper , dense multi-modal information ( text , figure , table ) , and the need to coordinate multiple align channel such a slide , subtitle , speech , and human talker . to address these challenge , we introduce papertalker , the first benchmark of 101 research paper pair with author-created presentation video , slide , and speaker metadata . we further design four tailored evaluation metric -- meta similarity , presentarena , presentquiz , and ip memory -- to measure how videos convey the paper 's information to the audience . building on this foundation , we propose papertalker , the first multi-agent framework for academic presentation video generation . it integrate slide generation with effective layout refinement by a novel effective tree search visual choice , cursor grounding , subtitle , speech synthesis , and talking-head rendering , while parallelize slide-wise generation for efficiency . experiment on paper2video demonstrate that the presentation video produce by our approach be more faithful and informative than exist baseline , establish a practical step toward automate and ready-to-use academic video generation . our dataset , agent , and code be available at http : //github.com/showlab/paper2video .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05095	from noisy trace to stable gradient : bias-variance optimized preference optimization for align large reasoning model	Mingkang Zhu, Xi Chen, Bei Yu, Hengshuang Zhao, Jiaya Jia	large reason model ( lrms ) generate intermediate reasoning trace before produce final answer , yield strong gain on multi-step and mathematical task . yet align lrms with human preference , a crucial prerequisite for model deployment , remain underexplored . the statistically correct objective for preference alignment require marginalize over reason trace , but this computation be intractable in practice . a common workaround optimize a single sampled trajectory , which introduce substantial gradient variance from stochastic trace sample . to address this challenge , we frame preference optimization for lrms through the lens of the bias -- variance trade-off and propose bias -- variance optimize preference optimization ( bvpo ) , a simple , drop-in method that mix two gradient estimator : a high-variance trace-based estimator and a low-variance empty-trace estimator obtain by disable reason trace generation . our theory show that bvpo strictly reduce trace-induced variance for any nontrivial mixture , provide a closed-form choice of the mixing weight that minimize mean-squared error relative to the true marginal gradient , and under standard smoothness and step-size condition , tighten classical convergence bound for stochastic gradient descent . empirically , bvpo improves alignment over the best baseline by up to 7.8 point on alpacaeval~2 and 6.8 point on arena-hard . despite be train only on general conversational data , bvpo also boost reason performance for base model by up to 4.0 point on the average of six math reason benchmark . these result identify variance from trace sample a a key bottleneck and demonstrate that directly optimize the bias -- variance trade-off yield more stable training and strong overall performance .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05092	learn to interpret weight difference in language model	Avichal Goel, Yoon Kim, Nir Shavit, Tony T. Wang	finetuning ( pretrained ) language model be a standard approach for update their internal parametric knowledge and specialize them to new task and domain . however , the corresponding model weight change ( `` weight diffs '' ) be not generally interpretable . while inspect the finetuning dataset can give a sense of how the model might have change , these datasets be often not publicly available or be too large to work with directly . towards the goal of comprehensively understand weight diffs in natural language , we introduce diff interpretation tuning ( dit ) , a method that train model to describe their own finetuning-induced modification . our approach use synthetic , label weight diffs to train a dit adapter , which can be apply to a compatible finetuned model to make it describe how it have change . we demonstrate in two proof-of-concept setting ( report hide behavior and summarize finetuned knowledge ) that our method enable model to describe their finetuning-induced modification use accurate natural language description .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05090	finish first , perfect later : test-time token-level cross-validation for diffusion large language model	Runchu Tian, Junxia Cui, Xueqiang Xu, Feng Yao, Jingbo Shang	diffusion large language model ( dllms ) have recently emerge a a promising alternative to autoregressive ( ar ) model , offer advantage such a accelerated parallel decoding and bidirectional context modeling . however , the vanilla decode strategy in discrete dllms suffers from a critical limitation : once a token be accept , it can no longer be revise in subsequent step . a a result , early mistake persist across iteration , harm both intermediate prediction and final output quality . to address this issue , we propose tolerator ( token-level cross-validation refinement ) , a training-free decoding strategy that leverage cross-validation among predicted token . unlike exist method that follow a single progressive unmasking procedure , tolerator introduces a two-stage process : ( i ) sequence fill-up and ( ii ) iterative refinement by remasking and decode a subset of token while treat the remain a context . this design enable previously accept token to be reconsider and correct when necessary , lead to more reliable diffusion decode output . we evaluate tolerator on five standard benchmark cover language understanding , code generation , and mathematics . experiment show that our method achieve consistent improvement over the baseline under the same computational budget . these finding suggest that decode algorithm be crucial to realize the full potential of diffusion large language model . code and data be publicly available .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05087	teachlm : post-training llm for education use authentic learning data	Janos Perczel, Jin Chow, Dorottya Demszky	the promise of generative ai to revolutionize education be constrain by the pedagogical limit of large language model ( llm ) . a major issue be the lack of access to high-quality training data that reflect the learning of actual student . prompt engineering have emerge a a stopgap , but the ability of prompt to encode complex pedagogical strategy in rule-based natural language be inherently limit . to address this gap we introduce teachlm - an llm optimize for teach through parameter-efficient fine-tuning of state-of-the-art model . teachlm be train on a dataset comprise of 100,000 hour of one-on-one , longitudinal student-tutor interaction maintain by polygence , which undergo a rigorous anonymization process to protect privacy . we use parameter-efficient fine-tuning to develop an authentic student model that enable the generation of high-fidelity synthetic student-tutor dialogue . building on this capability , we propose a novel multi-turn evaluation protocol that leverage synthetic dialogue generation to provide fast , scalable , and reproducible assessment of the dialogical capability of llm . our evaluation demonstrate that fine-tuning on authentic learning data significantly improve conversational and pedagogical performance - double student talk time , improve question style , increase dialogue turn by 50 % , and great personalization of instruction .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05077	slm-mux : orchestrate small language model for reason	Chenyu Wang, Zishen Wan, Hao Kang, Emma Chen, Zhiqiang Xie, Tushar Krishna, Vijay Janapa Reddi, Yilun Du	with the rapid development of language model , the number of small language model ( slms ) have grow significantly . although they do not achieve state-of-the-art accuracy , they be more efficient and often excel at specific task . this raise a natural question : can multiple slms be orchestrate into a system where each contribute effectively , achieve high accuracy than any individual model ? exist orchestration method have primarily target frontier model ( e.g. , gpt-4 ) and perform suboptimally when apply to slms . to address this gap , we propose a three-stage approach for orchestrate slms . first , we introduce slm-mux , a multi-model architecture that effectively coordinate multiple slms . building on this , we develop two optimization strategy : ( i ) a model selection search that identify the most complementary slms from a give pool , and ( ii ) test-time scaling tailor to slm-mux . our approach delivers strong result : compare to exist orchestration method , our approach achieve up to 13.4 % improvement on math , 8.8 % on gpqa , and 7.0 % on gsm8k . with just two slms , slm-mux outperforms qwen 2.5 72b on gpqa and gsm8k , and match it performance on math . we further provide theoretical analysis to substantiate the advantage of our method . in summary , we demonstrate that slms can be effectively orchestrate into more accurate and efficient system through the propose approach .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05069	swireasoning : switch-thinking in latent and explicit for pareto-superior reasoning llm	Dachuan Shi, Abedelkadir Asi, Keying Li, Xiangchi Yuan, Leyan Pan, Wenke Lee, Wen Xiao	recent work show that , beyond discrete reason through explicit chain-of-thought step , which be limit by the boundary of natural language , large language model ( llm ) can also reason continuously in latent space , allow rich information per step and thereby improve token efficiency . despite this promise , latent reasoning still face two challenge , especially in training-free setting : 1 ) purely latent reason broaden the search distribution by maintain multiple implicit path , which diffuse probability mass , introduces noise , and impedes convergence to a single high-confidence solution , thereby hurt accuracy ; and 2 ) overthinking persists even without explicit text , waste token and degrade efficiency . to address these issue , we introduce swireasoning , a training-free framework for llm reason which feature two key innovation : 1 ) swireasoning dynamically switch between explicit and latent reasoning , guide by block-wise confidence estimate from entropy trend in next-token distribution , to balance exploration and exploitation and promote timely convergence . 2 ) by limit the maximum number of thinking-block switch , swireasoning curb overthinking and improves token efficiency across vary problem difficulty . on widely use mathematics and stem benchmark , swireasoning consistently improve average accuracy by 1.5 % -2.8 % across reason llm of different model family and scale . furthermore , under constrain budget , swireasoning improves average token efficiency by 56 % -79 % , with large gain a budget tighten .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05052	proactive defense against llm jailbreak	Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang	the proliferation of powerful large language model ( llm ) have necessitate robust safety alignment , yet these model remain vulnerable to evolve adversarial attack , include multi-turn jailbreak that iteratively search for successful query . current defense , primarily reactive and static , often fail to counter these search-based attack . in this paper , we introduce proact , a novel proactive defense framework design to disrupt and mislead autonomous jailbreaking process . our core idea be to intentionally provide adversary with `` spurious response '' that appear to be result of successful jailbreak attack but contain no actual harmful content . these misleading response provide false signal to the attacker 's internal optimization loop , cause the adversarial search to terminate prematurely and effectively jailbreaking the jailbreak . by conduct extensive experiment across state-of-the-art llm , jailbreaking framework , and safety benchmark , our method consistently and significantly reduces attack success rate by up to 92\ % . when combine with other defense framework , it far reduce the success rate of the late attack strategy to 0\ % . proact represent an orthogonal defense strategy that can serve a an additional guardrail to enhance llm safety against the most effective jailbreaking attack .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05046	cole : a comprehensive benchmark for french language understanding evaluation	David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury	to address the need for a more comprehensive evaluation of french natural language understanding ( nlu ) , we introduce cole , a new benchmark compose of 23 diverse task cover a broad range of nlu capability , include sentiment analysis , paraphrase detection , grammatical judgment , and reason , with a particular focus on linguistic phenomenon relevant to the french language . we benchmark 94 large language model ( llm ) , provide an extensive analysis of the current state of french nlu . our result highlight a significant performance gap between closed- and open-weights model and identify key challenge frontier for current llm , such a zero-shot extractive question-answering ( qa ) , fine-grained word sense disambiguation , and understanding of regional language variation . we release cole a a public resource to foster further progress in french language modelling .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05038	guide query refinement : multimodal hybrid retrieval with test-time optimization	Omri Uzan, Asaf Yehudai, Roi pony, Eyal Shnarch, Ariel Gera	multimodal encoders have push the boundary of visual document retrieval , match textual query tokens directly to image patch and achieve state-of-the-art performance on public benchmark . recent model rely on this paradigm have massively scale the size of their query and document representation , present obstacle to deployment and scalability in real-world pipeline . furthermore , purely vision-centric approach may be constrain by the inherent modality gap still exhibit by modern vision-language model . in this work , we connect these challenge to the paradigm of hybrid retrieval , investigate whether a lightweight dense text retriever can enhance a strong vision-centric model . exist hybrid method , which rely on coarse-grained fusion of rank or score , fail to exploit the rich interaction within each model 's representation space . to address this , we introduce guided query refinement ( gqr ) , a novel test-time optimization method that refine a primary retriever 's query embed use guidance from a complementary retriever 's score . through extensive experiment on visual document retrieval benchmark , we demonstrate that gqr allow vision-centric model to match the performance of model with significantly large representation , while be up to 14x faster and require 54x less memory . our finding show that gqr effectively push the pareto frontier for performance and efficiency in multimodal retrieval . we release our code at http : //github.com/ibm/test-time-hybrid-retrieval	Computation and Language	06/10/2025
10.48550/arXiv.2510.05026	a set of quebec-french corpus of regional expression and term	David Beauchemin, Yan Tremblay, Mohamed Amine Youssef, Richard Khoury	the task of idiom understanding and dialect understanding be both well-established benchmark in natural language processing . in this paper , we propose combine them , and use regional idiom a a test of dialect understanding . towards this end , we propose two new benchmark datasets for the quebec dialect of french : qfrcore , which contain 4,633 instance of idiomatic phrase , and qfrcort , which comprise 171 regional instance of idiomatic word . we explain how to construct these corpus , so that our methodology can be replicate for other dialect . our experiment with 94 llm demonstrate that our regional idiom benchmark be a reliable tool for measure a model 's proficiency in a specific dialect .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05025	imperceptible jailbreaking against large language model	Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang	jailbreaking attack on the vision modality typically rely on imperceptible adversarial perturbation , whereas attack on the textual modality be generally assume to require visible modification ( e.g. , non-semantic suffix ) . in this paper , we introduce imperceptible jailbreak that exploit a class of unicode character call variation selector . by append invisible variation selector to malicious question , the jailbreak prompt appear visually identical to original malicious question on screen , while their tokenization be `` secretly '' alter . we propose a chain-of-search pipeline to generate such adversarial suffix to induce harmful response . our experiment show that our imperceptible jailbreak achieve high attack success rate against four aligned llm and generalize to prompt injection attack , all without produce any visible modification in the write prompt . our code be available at http : //github.com/sail-sg/imperceptible-jailbreaks .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05016	large language model achieve gold medal performance at international astronomy & astrophysics olympiad	Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun	while task-specific demonstration show early success in apply large language model ( llm ) to automate some astronomical research task , they only provide incomplete view of all necessary capability in solve astronomy problem , call for more thorough understanding of llm ' strength and limitation . so far , exist benchmark and evaluation focus on simple question-answering that primarily test astronomical knowledge and fail to evaluate the complex reasoning require for real-world research in the discipline . here , we address this gap by systematically benchmarking five state-of-the-art llm on the international olympiad on astronomy and astrophysics ( ioaa ) exam , which be design to examine deep conceptual understanding , multi-step derivation , and multimodal analysis . with average score of 85.6 % and 84.2 % , gemini 2.5 pro and gpt-5 ( the two top-performing model ) not only achieve gold medal level performance but also rank in the top two among ~200-300 participant in all four ioaa theory exam evaluate ( 2022-2025 ) . in comparison , result on the data analysis exams show more divergence . gpt-5 still excel in the exam with an 88.5 % average score , rank top 10 among the participant in the four most recent ioaas , while other model ' performance drop to 48-76 % . furthermore , our in-depth error analysis underscore conceptual reasoning , geometric reasoning , and spatial visualization ( 52-79 % accuracy ) a consistent weakness among all llm . hence , although llms approach peak human performance in theory exam , critical gap must be address before they can serve a autonomous research agent in astronomy .	Computation and Language	06/10/2025
10.48550/arXiv.2510.05003	resource-efficient fine-tuning of llama-3.2-3b for medical chain-of-thought reasoning	Imran Mansha	large language model ( llm ) such a gpt-4 and llama have demonstrate remarkable reason ability but require significant computational resource for fine-tuning . this paper present a resource-efficient fine-tuning approach for llama-3.2-3b to enhance medical chain-of-thought reasoning while operate under constrain gpu and memory setting . use parameter-efficient tune technique such a lora and qlora , we adapt the base model on publicly available medical reason datasets . the model achieve improved reason coherence and factual accuracy while reduce memory usage by up to 60 % compare to standard full fine-tuning . experimental evaluation demonstrate that lightweight adaptation can retain strong reasoning capability in medical question-answering task . this work highlights practical strategy for deploy llm in low-resource research environment and provide insight into balance efficiency and domain specialization for medical ai system .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04996	reinforce-ada : an adaptive sampling framework for reinforce-style llm training	Wei Xiong, Chenlu Ye, Baohao Liao, Hanze Dong, Xinxing Xu, Christof Monz, Jiang Bian, Nan Jiang, Tong Zhang	reinforcement learn apply to large language model ( llm ) for reason task be often bottleneck by unstable gradient estimate due to fix and uniform sampling of response across prompt . prior work such a gvm-raft address this by dynamically allocate inference budget per prompt to minimize stochastic gradient variance under a budget constraint . inspire by this insight , we propose reinforce-ada , an adaptive sampling framework for online rl post-training of llm that continuously reallocate sample effort to the prompt with the great uncertainty or learn potential . unlike conventional two-stage allocation method , reinforce-ada interleaf estimation and sampling in an online successive elimination process , and automatically stop sample for a prompt once sufficient signal be collect . to stabilize update , we form fixed-size group with enforced reward diversity and compute advantage baseline use global statistic aggregate over the adaptive sampling phase . empirical result across multiple model architecture and reason benchmark show that reinforce-ada accelerates convergence and improve final performance compare to grpo , especially when use the balanced sampling variant . our work highlight the central role of variance-aware , adaptive data curation in enable efficient and reliable reinforcement learn for reasoning-capable llm . code be available at http : //github.com/rlhflow/reinforce-ada .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04983	aware , beyond sentence boundary : a contextual transformer framework for identify cultural capital in stem narrative	Khalid Mehtab Khan, Anagha Kulkarni	identify cultural capital ( cc ) theme in student reflection can offer valuable insight that help foster equitable learn environment in classroom . however , theme such a aspirational goal or family support be often weave into narrative , rather than appear a direct keywords . this make them difficult to detect for standard nlp model that process sentence in isolation . the core challenge stem from a lack of awareness , a standard model be pre-trained on general corpus , leave them blind to the domain-specific language and narrative context inherent to the data . to address this , we introduce aware , a framework that systematically attempt to improve a transformer model 's awareness for this nuanced task . aware have three core component : 1 ) domain awareness , adapt the model 's vocabulary to the linguistic style of student reflection ; 2 ) context awareness , generate sentence embeddings that be aware of the full essay context ; and 3 ) class overlap awareness , employ a multi-label strategy to recognize the coexistence of theme in a single sentence . our result show that by make the model explicitly aware of the property of the input , aware outperform a strong baseline by 2.1 percentage point in macro-f1 and show considerable improvement across all theme . this work provide a robust and generalizable methodology for any text classification task in which mean depends on the context of the narrative .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04980	llm-hanabi : evaluate multi-agent gameplays with theory-of-mind and rationale inference in imperfect information collaboration game	Fangzhou Liang, Tianshi Zheng, Chunkit Chan, Yauwai Yim, Yangqiu Song	effective multi-agent collaboration require agent to infer the rationale behind others ' action , a capability root in theory-of-mind ( tom ) . while recent large language model ( llm ) excel at logical inference , their ability to infer rationale in dynamic , collaborative setting remain under-explored . this study introduce llm-hanabi , a novel benchmark that use the cooperative game hanabi to evaluate the rationale inference and tom of llm . our framework feature an automated evaluation system that measure both game performance and tom proficiency . across a range of model , we find a significant positive correlation between tom and in-game success . notably , first-order tom ( interpret others ' intent ) correlate more strongly with performance than second-order tom ( predict others ' interpretation ) . these finding highlight that for effective ai collaboration , the ability to accurately interpret a partner 's rationale be more critical than higher-order reasoning . we conclude that prioritize first-order tom be a promising direction for enhance the collaborative capability of future model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04950	mind your tone : investigate how prompt politeness affect llm accuracy ( short paper )	Om Dobariya, Akhil Kumar	the wording of natural language prompt have be show to influence the performance of large language model ( llm ) , yet the role of politeness and tone remain underexplored . in this study , we investigate how varying level of prompt politeness affect model accuracy on multiple-choice question . we create a dataset of 50 base question span mathematics , science , and history , each rewritten into five tone variant : very polite , polite , neutral , rude , and very rude , yield 250 unique prompt . use chatgpt 4o , we evaluate response across these condition and apply paired sample t-tests to assess statistical significance . contrary to expectation , impolite prompt consistently outperform polite one , with accuracy range from 80.8 % for very polite prompt to 84.8 % for very rude prompt . these finding differ from early study that associate rudeness with poor outcome , suggest that new llm may respond differently to tonal variation . our result highlight the importance of study pragmatic aspect of prompting and raise broad question about the social dimension of human-ai interaction .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04945	a first context-free grammar apply to nawatl corpus augmentation	Juan-José Guzmán-Landa, Juan-Manuel Torres-Moreno, Miguel Figueroa-Saavedra, Ligia Quintana-Torres, Martha-Lorena Avendaño-Garrido, Graham Ranger	in this article we introduce a context-free grammar ( cfg ) for the nawatl language . nawatl ( or nahuatl ) be an amerindian language of the $ \pi $ -language type , i.e . a language with few digital resource , in which the corpus available for machine learning be virtually non-existent . the objective here be to generate a significant number of grammatically correct artificial sentence , in order to increase the corpus available for language model training . we want to show that a grammar enable u significantly to expand a corpus in nawatl which we call $ \pi $ -\textsc { yalli } . the corpus , thus enrich , enable u to train algorithm such a fasttext and to evaluate them on sentence-level semantic task . preliminary result show that by use the grammar , comparative improvement be achieve over some llm . however , it be observe that to achieve more significant improvement , grammar that model the nawatl language even more effectively be require .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04944	on structure state-space duality	Jerry Yao-Chieh Hu, Xiwen Zhang, Weimin Wu, Han Liu	structure state-space duality ( ssd ) [ dao & gu , icml 2024 ] be an equivalence between a simple structured state-space model ( ssm ) and a masked attention mechanism . in particular , a state-space model with a scalar-times-identity state matrix be equivalent to a mask self-attention with a $ 1 $ -semiseparable causal mask . consequently , the same sequence transformation ( model ) have two algorithmic realization : a a linear-time $ o ( t ) $ recurrence or a a quadratic-time $ o ( t^2 ) $ attention . in this note , we formalize and generalize this duality : ( i ) we extend ssd from the scalar-identity case to general diagonal ssms ( diagonal state matrix ) ; ( ii ) we show that these diagonal ssms match the scalar case 's training complexity low bound while support rich dynamic ; ( iii ) we establish a necessary and sufficient condition under which an ssm be equivalent to $ 1 $ -semiseparable mask attention ; and ( iv ) we show that such duality fails to extend to standard softmax attention due to rank explosion . together , these result tighten bridge between recurrent ssms and transformer , and widen the design space for expressive yet efficient sequence model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04938	onnx-net : towards universal representation and instant performance prediction for neural architecture	Shiwen Qin, Alexander Auras, Shay B. Cohen, Elliot J. Crowley, Michael Moeller, Linus Ericsson, Jovita Lukasik	neural architecture search ( nas ) automate the design process of high-performing architecture , but remain bottleneck by expensive performance evaluation . most existing study that achieve fast evaluation be mostly tie to cell-based search space and graph encoding tailor to those individual search space , limit their flexibility and scalability when apply to more expressive search space . in this work , we aim to close the gap of individual search space restriction and search space dependent network representation . we present onnx-bench , a benchmark consisting of a collection of neural network in a unified format base on onnx file . onnx-bench include all open-source nas-bench-based neural network , result in a total size of more than 600k { architecture , accuracy } pair . this benchmark allow create a share neural network representation , onnx-net , able to represent any neural architecture use natural language description act a an input to a performance predictor . this text-based encoding can accommodate arbitrary layer type , operation parameter , and heterogeneous topology , enable a single surrogate to generalise across all neural architecture rather than be confine to cell-based search space . experiment show strong zero-shot performance across disparate search space use only a small amount of pretraining sample , enable the unprecedented ability to evaluate any neural network architecture instantly .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04935	mar : optimize dual-system deep research via multi-agent reinforcement learning	Guoxin Chen, Zile Qiao, Wenqing Wang, Donglei Yu, Xuanzhong Chen, Hao Sun, Minpeng Liao, Kai Fan, Yong Jiang, Penguin Xie, Wayne Xin Zhao, Ruihua Song, Fei Huang	large reason model ( lrms ) often exhibit a tendency for overanalysis in simple task , where the model excessively utilize system 2-type , deliberate reasoning , lead to inefficient token generation . furthermore , these model face challenge in adapt their reasoning capability to rapidly change environment due to the static nature of their pretraining data . to address these issue , advance large language model ( llm ) for complex reasoning task require innovative approach that bridge intuitive and deliberate cognitive process , akin to human cognition 's dual-system dynamic . this paper introduce a multi-agent system for deep research ( mar ) enable seamless integration of system 1 's fast , intuitive thinking with system 2 's deliberate reasoning within llm . mar strategically integrate multiple external tool , such a google search , google scholar , and python interpreter , to access up-to-date information and execute complex computation , while create a specialized division of labor where system 1 efficiently process and summarize high-volume external information , provide distil insight that expand system 2 's reason context without overwhelm it capacity . furthermore , we propose a multi-agent reinforcement learn framework extend group relative policy optimization to simultaneously optimize both system with multi-turn tool interaction , bin-packing optimization , and sample balancing strategy that enhance collaborative efficiency . extensive experiment demonstrate mar achieve substantial improvement of 3.86 % on the challenging humanity 's last exam ( hle ) benchmark and an average gain of 8.9 % across 7 knowledge-intensive task , validate the effectiveness of our dual-system paradigm for complex reasoning in dynamic information environment .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04933	the geometry of truth : layer-wise semantic dynamic for hallucination detection in large language model	Amir Hameed Mir	large language model ( llm ) often produce fluent yet factually incorrect statements-a phenomenon know a hallucination-posing serious risk in high-stakes domain . we present layer-wise semantic dynamic ( lsd ) , a geometric framework for hallucination detection that analyze the evolution of hidden-state semantics across transformer layer . unlike prior method that rely on multiple sample pass or external verification source , lsd operate intrinsically within the model 's representational space . use margin-based contrastive learning , lsd aligns hidden activation with ground-truth embeddings derive from a factual encoder , reveal a distinct separation in semantic trajectory : factual response preserve stable alignment , while hallucination exhibit pronounced semantic drift across depth . evaluate on the truthfulqa and synthetic factual-hallucination datasets , lsd achieves an f1-score of 0.92 , auroc of 0.96 , and cluster accuracy of 0.89 , outperform selfcheckgpt and semantic entropy baseline while require only a single forward pas . this efficiency yield a 5-20x speedup over sampling-based method without sacrifice precision or interpretability . lsd offer a scalable , model-agnostic mechanism for real-time hallucination monitoring and provide new insight into the geometry of factual consistency within large language model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04919	do llm align with my task ? evaluate text-to-sql via dataset alignment	Davood Rafiei, Morgan Lindsay Heisler, Weiwei Zhang, Mohammadreza Pourreza, Yong Zhang	supervise fine-tuning ( sft ) be an effective method for adapt large language model ( llm ) on downstream task . however , variability in train data can hinder a model 's ability to generalize across domain . this paper study the problem of dataset alignment for natural language to sql ( nl2sql or text to sql ) , examine how well sft train data match the structural characteristic of target query and how this alignment impact model performance . we hypothesize that alignment can be accurately estimate by compare the distribution of structural sql feature across the training set , target data , and the model 's prediction prior to sft . through comprehensive experiment on three large cross-domain nl2sql benchmark and multiple model family , we show that structural alignment be a strong predictor of fine-tuning success . when alignment be high , sft yield substantial gain in accuracy and sql generation quality ; when alignment be low , improvement be marginal or absent . these finding highlight the importance of alignment-aware data selection for effective fine-tuning and generalization in nl2sql task .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04905	retrieval-augmented code generation : a survey with focus on repository-level approach	Yicheng Tao, Yao Qin, Yepang Liu	recent advancement in large language model ( llm ) have substantially improve automated code generation . while function-level and file-level generation have achieve promising result , real-world software development typically require reason across entire repository . this give rise to the challenge task of repository-level code generation ( rlcg ) , where model must capture long-range dependency , ensure global semantic consistency , and generate coherent code span multiple file or module . to address these challenge , retrieval-augmented generation ( rag ) have emerge a a powerful paradigm that integrate external retrieval mechanism with llm , enhance context-awareness and scalability . in this survey , we provide a comprehensive review of research on retrieval-augmented code generation ( racg ) , with an emphasis on repository-level approach . we categorize exist work along several dimension , include generation strategy , retrieval modality , model architecture , train paradigm , and evaluation protocol . furthermore , we summarize widely use datasets and benchmark , analyze current limitation , and outline key challenge and opportunity for future research . our goal be to establish a unified analytical framework for understand this rapidly evolve field and to inspire continued progress in ai-powered software engineering .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04891	socialharmbench : revealing llm vulnerability to socially harmful request	Punya Syon Pandey, Hai Son Le, Devansh Bhardwaj, Rada Mihalcea, Zhijing Jin	large language model ( llm ) be increasingly deploy in context where their failure can have direct sociopolitical consequence . yet , exist safety benchmark rarely test vulnerability in domain such a political manipulation , propaganda and disinformation generation , or surveillance and information control . we introduce socialharmbench , a dataset of 585 prompt span 7 sociopolitical category and 34 country , design to surface where llm most acutely fail in politically charge context . our evaluation reveal several shortcoming : open-weight model exhibit high vulnerability to harmful compliance , with mistral-7b reach attack success rate as high a 97 % to 98 % in domain such a historical revisionism , propaganda , and political manipulation . moreover , temporal and geographic analysis show that llm be most fragile when confront with 21st-century or pre-20th-century context , and when respond to prompt tie to region such a latin america , the usa , and the uk . these finding demonstrate that current safeguard fail to generalize to high-stakes sociopolitical setting , expose systematic bias and raise concern about the reliability of llm in preserve human right and democratic value . we share the socialharmbench benchmark at http : //huggingface.co/datasets/psyonp/socialharmbench .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04850	detect distillation data from reason model	Hengxiang Zhang, Hyeong Kyu Choi, Yixuan Li, Hongxin Wei	reason distillation have emerge a an efficient and powerful paradigm for enhance the reason capability of large language model . however , reason distillation may inadvertently cause benchmark contamination , where evaluation data include in distillation datasets can inflate performance metric of distilled model . in this work , we formally define the task of distillation data detection , which be uniquely challenge due to the partial availability of distillation data . then , we propose a novel and effective method token probability deviation ( tbd ) , which leverage the probability pattern of the generate output token . our method be motivate by the analysis that distil model tend to generate near-deterministic token for see question , while produce more low-probability token for unseen question . our key idea behind tbd be to quantify how far the generated token ' probability deviate from a high reference probability . in effect , our method achieves competitive detection performance by produce low score for see question than for unseen question . extensive experiment demonstrate the effectiveness of our method , achieve an auc of 0.918 and a tpr @ 1 % fpr of 0.470 on the s1 dataset .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04849	when model lie , we learn : multilingual span-level hallucination detection with psiloqa	Elisei Rykov, Kseniia Petrushina, Maksim Savkin, Valerii Olisov, Artem Vazhentsev, Kseniia Titova, Alexander Panchenko, Vasily Konovalov, Julia Belikova	hallucination detection remain a fundamental challenge for the safe and reliable deployment of large language model ( llm ) , especially in application require factual accuracy . exist hallucination benchmark often operate at the sequence level and be limit to english , lack the fine-grained , multilingual supervision need for a comprehensive evaluation . in this work , we introduce psiloqa , a large-scale , multilingual dataset annotate with span-level hallucination across 14 language . psiloqa be construct through an automated three-stage pipeline : generate question-answer pair from wikipedia use gpt-4o , elicit potentially hallucinate answer from diverse llm in a no-context setting , and automatically annotate hallucinate span use gpt-4o by compare against golden answer and retrieve context . we evaluate a wide range of hallucination detection method -- include uncertainty quantification , llm-based tagging , and fine-tuned encoder model -- and show that encoder-based model achieve the strong performance across language . furthermore , psiloqa demonstrates effective cross-lingual generalization and support robust knowledge transfer to other benchmark , all while be significantly more cost-efficient than human-annotated datasets . our dataset and result advance the development of scalable , fine-grained hallucination detection in multilingual setting .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04848	instability in downstream task performance during llm pretraining	Yuto Nishida, Masaru Isonuma, Yusuke Oda	when train large language model ( llm ) , it be common practice to track downstream task performance throughout the training process and select the checkpoint with the high validation score . however , downstream metric often exhibit substantial fluctuation , make it difficult to identify the checkpoint that truly represent the best-performing model . in this study , we empirically analyze the stability of downstream task performance in an llm train on diverse web-scale corpus . we find that task score frequently fluctuate throughout training , both at the aggregate and example level . to address this instability , we investigate two post-hoc checkpoint integration method : checkpoint averaging and ensemble , motivate by the hypothesis that aggregate neighbor checkpoint can reduce performance volatility . we demonstrate both empirically and theoretically that these method improve downstream performance stability without require any change to the training procedure .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04832	how i build asr for endanger language with a spoken dictionary	Christopher Bartley, Anton Ragni	nearly half of the world 's language be endanger . speech technology such a automatic speech recognition ( asr ) be central to revival effort , yet most language remain unsupported because standard pipeline expect utterance-level supervised data . speech data often exist for endanger language but rarely match these format . manx gaelic ( $ \sim $ 2,200 speaker ) , for example , have have transcribe speech since 1948 , yet remains unsupported by modern system . in this paper , we explore how little data , and in what form , be need to build asr for critically endanger language . we show that a short-form pronunciation resource be a viable alternative , and that 40 minute of such data produce usable asr for manx ( $ < $ 50\ % wer ) . we replicate our approach , apply it to cornish ( $ \sim $ 600 speaker ) , another critically endanger language . result show that the barrier to entry , in quantity and form , be far low than previously think , give hope to endanger language community that can not afford to meet the requirement arbitrarily impose upon them .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04819	visual representation inside the language model	Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay Krishna	despite interpretability work analyze vit encoders and transformer activation , we do n't yet understand why multimodal language model ( mlms ) struggle on perception-heavy task . we offer an under-studied perspective by examine how popular mlms ( llava-onevision , qwen2.5-vl , and llama-3-llava-next ) process their visual key-value token . we first study the flow of visual information through the language model , find that image value tokens encode sufficient information to perform several perception-heavy task zero-shot : segmentation , semantic correspondence , temporal correspondence , and refer expression detection . we find that while the language model do augment the visual information receive from the projection of input visual encodings-which we reveal correlate with overall mlm perception capability-it contain less visual information on several task than the equivalent visual encoder ( siglip ) that have not undergone mlm finetuning . far , we find that the visual information correspond to input-agnostic image key token in late layer of language model contain artifact which reduce perception capability of the overall mlm . next , we discuss control visual information in the language model , show that add a text prefix to the image input improve perception capability of visual representation . finally , we reveal that if language model be able to well control their visual information , their perception would significantly improve ; e.g. , in 33.3 % of art style question in the blink benchmark , perception information present in the language model be not surface to the output ! our finding reveal insight into the role of key-value token in multimodal system , pave the way for deep mechanistic interpretability of mlms and suggest new direction for train their visual encoder and language model component .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04800	hybrid architecture for language model : systematic analysis and design insight	Sangmin Bae, Bilge Acun, Haroun Habeeb, Seungyeon Kim, Chien-Yu Lin, Liang Luo, Junjie Wang, Carole-Jean Wu	recent progress in large language model demonstrate that hybrid architecture -- combine self-attention mechanism with structured state space model like mamba -- can achieve a compelling balance between model quality and computational efficiency , particularly for long-context task . while these hybrid model show promising performance , systematic comparison of hybridization strategy and analysis on the key factor behind their effectiveness have not be clearly share to the community . in this work , we present a holistic evaluation of hybrid architecture base on inter-layer ( sequential ) or intra-layer ( parallel ) fusion . we evaluate these design from a variety of perspective : language model performance , long-context capability , scale analysis , and training and inference efficiency . by investigate the core characteristic of their computational primitive , we identify the most critical element for each hybridization strategy and far propose optimal design recipe for both hybrid model . our comprehensive analysis provide practical guidance and valuable insight for develop hybrid language model , facilitate the optimization of architectural configuration .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04764	be babylms deaf to gricean maxim ? a pragmatic evaluation of sample-efficient language model	Raha Askari, Sina Zarrieß, Özge Alacam, Judith Sieker	implicit meaning be integral to human communication , make it essential for language model to be capable of identify and interpret them . grice ( 1975 ) propose a set of conversational maxim that guide cooperative dialogue , note that speaker may deliberately violate these principle to express meaning beyond literal word , and that listener , in turn , recognize such violation to draw pragmatic inference . building on surian et al . ( 1996 ) 's study of child 's sensitivity to violation of gricean maxim , we introduce a novel benchmark to test whether language model pretrained on less than 10m and less than 100m token can distinguish maxim-adhering from maxim-violating utterance . we compare these babylms across five maxim and situate their performance relative to child and a large language model ( llm ) pretrained on 3t token . we find that overall , model train on less than 100m token outperform those train on less than 10m , yet fall short of child-level and llm competence . our result suggest that modest data increase improve some aspect of pragmatic behavior , lead to finer-grained differentiation between pragmatic dimension .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04757	modernbert + colbert : enhance biomedical rag through an advanced re-ranking retriever	Eduardo Martínez Rivera, Filippo Menolascina	retrieval-augmented generation ( rag ) be a powerful technique for enrich large language model ( llm ) with external knowledge , allow for factually grounded response , a critical requirement in high-stakes domain such a healthcare . however , the efficacy of rag system be fundamentally restrict by the performance of their retrieval module , since irrelevant or semantically misaligned document directly compromise the accuracy of the final generate response . general-purpose dense retriever can struggle with the nuanced language of specialised domain , while the high accuracy of in-domain model be often achieve at prohibitive computational cost . in this work , we aim to address this trade-off by develop and evaluate a two-stage retrieval architecture that combine a lightweight modernbert bidirectional encoder for efficient initial candidate retrieval with a colbertv2 late-interaction model for fine-grained re-ranking . we conduct comprehensive evaluation of our retriever module performance and rag system performance in the biomedical context , fine-tune the ir module use 10k question-passage pair from pubmedqa . our analysis of the retriever module confirm the positive impact of the colbert re-ranker , which improve recall @ 3 by up to 4.2 percentage point compare to it retrieve-only counterpart . when integrate into the biomedical rag , our ir module lead to a state-of-the-art average accuracy of 0.4448 on the five task of the mirage question-answering benchmark , outperform strong baseline such a medcpt ( 0.4436 ) . our ablation study reveal that this performance be critically dependent on a joint fine-tuning process that align the retriever and re-ranker ; otherwise , the re-ranker might degrade the performance .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04750	a low-resource speech-driven nlp pipeline for sinhala dyslexia assistance	Peshala Perera, Deshan Sumanathilaka	dyslexia in adult remain an under-researched and under-served area , particularly in non-english-speaking context , despite it significant impact on personal and professional life . this work address that gap by focus on sinhala , a low-resource language with limited tool for linguistic accessibility . we present an assistive system explicitly design for sinhala-speaking adult with dyslexia . the system integrate whisper for speech-to-text conversion , sinbert , an open-sourced fine-tuned bert model train for sinhala to identify common dyslexic error , and a combined mt5 and mistral-based model to generate correct text . finally , the output be convert back to speech use gtts , create a complete multimodal feedback loop . despite the challenge pose by limited sinhala-language datasets , the system achieve 0.66 transcription accuracy and 0.7 correction accuracy with 0.65 overall system accuracy . these result demonstrate both the feasibility and effectiveness of the approach . ultimately , this work highlight the importance of inclusive natural language processing ( nlp ) technology in underrepresented language and showcases a practical	Computation and Language	06/10/2025
10.48550/arXiv.2510.04738	speak , edit , repeat : high-fidelity voice edit and zero-shot tt with cross-attentive mamba	Baher Mohammad, Magauiya Zhussip, Stamatios Lefkimmiatis	we introduce mave ( mamba with cross-attention for voice editing and synthesis ) , a novel autoregressive architecture for text-conditioned voice edit and high-fidelity text-to-speech ( tt ) synthesis , build on a cross-attentive mamba backbone . mave achieves state-of-the-art performance in speech editing and very competitive result in zero-shot tt , while not be explicitly train on the latter task , outperform lead autoregressive and diffusion model on diverse , real-world audio . by integrate mamba for efficient audio sequence model with cross-attention for precise text-acoustic alignment , mave enables context-aware voice edit with exceptional naturalness and speaker consistency . in pairwise human evaluation on a random 40-sample subset of the realedit benchmark ( 400 judgment ) , 57.2 % of listener rat mave - edited speech a perceptually equal to the original , while 24.8 % prefer the original and 18.0 % mave - demonstrating that in the majority of case edits be indistinguishable from the source . mave compare favorably with voicecraft and fluentspeech both on pairwise comparison and standalone mean opinion score ( mo ) evaluation . for zero-shot tt , mave exceeds voicecraft in both speaker similarity and naturalness , without require multiple inference run or post-processing . remarkably , these quality gain come with a significantly low memory cost and approximately the same latency : mave require ~6x less memory than voicecraft during inference on utterance from the realedit database ( mean duration : 6.21s , a100 , fp16 , batch size 1 ) . our result demonstrate that mave establishes a new standard for flexible , high-fidelity voice edit and synthesis through the synergistic integration of structured state-space modeling and cross-modal attention .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04721	brokenmath : a benchmark for sycophancy in theorem prove with llm	Ivo Petrov, Jasper Dekoninck, Martin Vechev	large language model ( llm ) have recently show strong performance on mathematical benchmark . at the same time , they be prone to hallucination and sycophancy , often provide convince but flaw proof for incorrect mathematical statement provide by user . this significantly limit the applicability of llm in theorem proving , a verification of these flaw proof must be do manually by expert mathematician . however , exist benchmark that measure sycophancy in mathematics be limit : they focus solely on final-answer problem , rely on very simple and often contaminated datasets , and construct benchmark sample use synthetic modification that create ill-posed question rather than well-posed question that be demonstrably false . to address these issue , we introduce brokenmath , the first benchmark for evaluate sycophantic behavior in llm within the context of natural language theorem prove . brokenmath be build from advanced 2025 competition problem , which be perturb with an llm to produce false statement and subsequently refine through expert review . use an llm-as-a-judge framework , we evaluate state-of-the-art llm and agentic system and find that sycophancy be widespread , with the best model , gpt-5 , produce sycophantic answer 29 % of the time . we further investigate several mitigation strategy , include test-time intervention and supervise fine-tuning on curated sycophantic example . these approach substantially reduce , but do not eliminate , sycophantic behavior .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04717	json whisperer : efficient json edit with llm	Sarel Duanis, Asnat Greenstein-Messica, Eliya Habba	large language model ( llm ) can modify json document through natural language command , but current approach regenerate entire structure for each edit , result in computational inefficiency . we present json whisperer , a framework that enable llms to generate rfc 6902 diff patches-expressing only the necessary modifications-rather than complete document . we identify two key challenge in patch-based editing : ( 1 ) llm often miss relate update when generate isolated patch , and ( 2 ) array manipulation require track index shift across operation , which llms handle poorly . to address these issue , we introduce ease ( explicitly address sequence encode ) , which transform array into dictionary with stable key , eliminate index arithmetic complexity . our evaluation show that patch generation with ease reduces token usage by 31 % while maintain edit quality within 5 % of full regeneration with particular gain for complex instruction and list manipulation . the dataset be available at : http : //github.com/emnlp2025/json-whisperer/	Computation and Language	06/10/2025
10.48550/arXiv.2510.04704	atomworld : a benchmark for evaluate spatial reasoning in large language model on crystalline material	Taoyuze Lv, Alexander Chen, Fengyu Xie, Chu Wu, Jeffrey Meng, Dongzhan Zhou, Bram Hoex, Zhicheng Zhong, Tong Xie	large language model ( llm ) excel at textual reasoning and be begin to develop spatial understanding , prompt the question of whether these ability can be combine for complex , domain-specific task . this question be essential in field like material science , where deep understanding of 3d atomic structure be fundamental . while initial study have successfully apply llm to task involve pure crystal generation or coordinate understanding , a standardized benchmark to systematically evaluate their core reasoning ability across diverse atomic structure have be notably absent . to address this gap , we introduce the atomworld benchmark to evaluate llm on task base in crystallographic information file ( cifs ) , a standard structure representation format . these task , include structural editing , cif perception , and property-guided modeling , reveal a critical limitation : current model , despite establish promising baseline , consistently fail in structural understanding and spatial reasoning . our experiment show that these model make frequent error on structure modification task , and even in the basic cif format understanding , potentially lead to cumulative error in subsequent analysis and material insight . by define these standardized task , atomworld lay the ground for advance llm toward robust atomic-scale modeling , crucial for accelerate material research and automate scientific workflow .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04694	multilingual routing in mixture-of-experts	Lucas Bandarkar, Chenyuan Yang, Mohsen Fayyaz, Junlin Hu, Nanyun Peng	mixture-of-experts ( moe ) architecture have become the key to scale modern llm , yet little be understood about how their sparse rout dynamic respond to multilingual data . in this work , we analyze expert routing pattern use parallel multilingual datasets and present highly interpretable layer-wise phenomenon . we find that moe model route token in language-specific way in the early and late decoder layer but exhibit significant cross-lingual rout alignment in middle layer , mirror parameter-sharing trend observe in dense llm . in particular , we reveal a clear , strong correlation between a model 's performance in a give language and how similarly it token be rout to english in these layer . extend beyond correlation , we explore inference-time intervention that induce high cross-lingual routing alignment . we introduce a method that steer the router by promote middle-layer task expert frequently activate in english , and it successfully increase multilingual performance . these 1-2 % gain be remarkably consistent across two evaluation task , three model , and 15+ language , especially give that these simple intervention override router of extensively train , state-of-the-art llm . in comparison , intervention outside of the middle layer or target multilingual-specialized expert only yield performance degradation . altogether , we present numerous finding that explain how moes process non-english text and demonstrate that generalization be limit by the model 's ability to leverage language-universal expert in all language .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04682	titok : transfer token-level knowledge via contrastive excess to transplant lora	Chanjoo Jung, Jaehyung Kim	large language model ( llm ) be widely apply in real world scenario , but fine-tune them come with significant computational and storage cost . parameter-efficient fine-tuning ( peft ) method such a lora mitigate these cost , but the adapted parameter be dependent on the base model and can not be transfer across different backbone . one way to address this issue be through knowledge distillation , but it effectiveness inherently depend on train data . recent work such a translora avoids this by generate synthetic data , but this add complexity because it require train an additional discriminator model . in this paper , we propose titok , a new framework that enable effective lora transplantation through token-level knowledge transfer . specifically , titok capture task-relevant information through a contrastive excess between a source model with and without lora . this excess highlight informative token and enables selective filtering of synthetic data , all without additional model or overhead . through experiment on three benchmark across multiple transfer setting , our experiment show that the propose method be consistently effective , achieving average performance gain of +4~8 % compare to baselines overall .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04678	multi-agent tool-integrated policy optimization	Zhanfeng Mo, Xingxuan Li, Yuntao Chen, Lidong Bing	large language model ( llm ) increasingly rely on multi-turn tool-integrated planning for knowledge-intensive and complex reasoning task . exist implementation typically rely on a single agent , but they suffer from limited context length and noisy tool response . a natural solution be to adopt a multi-agent framework with planner- and worker-agents to manage context . however , no exist method support effective reinforcement learn post-training of tool-integrated multi-agent framework . to address this gap , we propose multi-agent tool-integrated policy optimization ( matpo ) , which enable distinct role ( planner and worker ) to be train within a single llm instance use role-specific prompt via reinforcement learning . matpo be derive from a principled credit assignment mechanism across planner and worker rollouts . this design eliminate the need to deploy multiple llm , which would be memory-intensive , while preserve the benefit of specialization . experiment on gaia-text , webwalkerqa , and frame show that matpo consistently outperform single-agent baseline by an average of 18.38 % relative improvement in performance and exhibit great robustness to noisy tool output . our finding highlight the effectiveness of unify multiple agent role within a single llm and provide practical insight for stable and efficient multi-agent rl training .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04671	focusmed : a large language model-based framework for enhance medical question summarization with focus identification	Chao Liu, Ling Luo, Tengxiao Lv, Huan Zhuang, Lejing Yu, Jian Wang, Hongfei Lin	with the rapid development of online medical platform , consumer health question ( chqs ) be inefficient in diagnosis due to redundant information and frequent non-professional term . the medical question summary ( mqs ) task aim to transform chqs into streamlined doctor ' frequently ask question ( faq ) , but exist method still face challenge such a poor identification of question focus and model hallucination . this paper explore the potential of large language model ( llm ) in the mqs task and find that direct fine-tuning be prone to focus identification bias and generates unfaithful content . to this end , we propose an optimization framework base on core focus guidance . first , a prompt template be design to drive the llm to extract the core focus from the chqs that be faithful to the original text . then , a fine-tuning dataset be construct in combination with the original chq-faq pair to improve the ability to identify the focus of the question . finally , a multi-dimensional quality evaluation and selection mechanism be propose to comprehensively improve the quality of the summary from multiple dimension . we conduct comprehensive experiment on two widely-adopted mqs datasets use three establish evaluation metric . the propose framework achieve state-of-the-art performance across all measure , demonstrate a significant boost in the model 's ability to identify critical focus of question and a notable mitigation of hallucination . the source code be freely available at http : //github.com/dut-liuchao/focusmed .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04655	ft-mdt : extracting decision tree from medical text via a novel low-rank adaptation method	Yuheng Li, Jiechao Gao, Wei Han, Wenwen Ouyang, Wei Zhu, Hui Yi Leong	knowledge of the medical decision process , which can be model a medical decision tree ( mdts ) , be critical to build clinical decision support system . however , current mdt construction method rely heavily on time-consuming and laborious manual annotation . to address this challenge , we propose pi-lora ( path-integrated lora ) , a novel low-rank adaptation method for automatically extract mdts from clinical guideline and textbook . we integrate gradient path information to capture synergistic effect between different module , enable more effective and reliable rank allocation . this framework ensure that the most critical module receive appropriate rank allocation while less important one be prune , result in a more efficient and accurate model for extract medical decision tree from clinical text . extensive experiment on medical guideline datasets demonstrate that our pi-lora method significantly outperform exist parameter-efficient fine-tuning approach for the text2mdt task , achieve well accuracy with substantially reduce model complexity . the propose method achieve state-of-the-art result while maintain a lightweight architecture , make it particularly suitable for clinical decision support system where computational resource may be limit .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04641	evaluate llm for demographic-targeted social bias detection : a comprehensive benchmark study	Ayan Majumdar, Feihao Chen, Jinghui Li, Xiaozhen Wang	large-scale web-scraped text corpus use to train general-purpose ai model often contain harmful demographic-targeted social bias , create a regulatory need for data audit and develop scalable bias-detection method . although prior work have investigate bias in text datasets and related detection method , these study remain narrow in scope . they typically focus on a single content type ( e.g. , hate speech ) , cover limited demographic ax , overlook bias affect multiple demographic simultaneously , and analyze limited technique . consequently , practitioner lack a holistic understanding of the strength and limitation of recent large language model ( llm ) for automate bias detection . in this study , we present a comprehensive evaluation framework aim at english text to assess the ability of llm in detect demographic-targeted social bias . to align with regulatory requirement , we frame bias detection a a multi-label task use a demographic-focused taxonomy . we then conduct a systematic evaluation with model across scale and technique , include prompting , in-context learning , and fine-tuning . use twelve datasets span diverse content type and demographic , our study demonstrate the promise of fine-tuned small model for scalable detection . however , our analysis also expose persistent gap across demographic ax and multi-demographic targeted bias , underscore the need for more effective and scalable auditing framework .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04631	contrastive learn use graph embeddings for domain adaptation of language model in the process industry	Anastasia Zhukova, Jonas Lührs, Christian E. Matt, Bela Gipp	recent trend in nlp utilize knowledge graph ( kg ) to enhance pretrained language model by incorporate additional knowledge from the graph structure to learn domain-specific terminology or relationship between document that might otherwise be overlook . this paper explore how scincl , a graph-aware neighborhood contrastive learn methodology originally design for scientific publication , can be apply to the process industry domain , where text log contain crucial information about daily operation and be often structure a sparse kg . our experiment demonstrate that language model fine-tune with triplet derive from ge outperform a state-of-the-art me5-large text encoder by 9.8-14.3 % ( 5.4-8.0p ) on the proprietary process industry text embed benchmark ( piteb ) while be 3-5 time small in size .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04618	agentic context engineering : evolving context for self-improving language model	Qizheng Zhang, Changran Hu, Shubhangi Upasani, Boyuan Ma, Fenglu Hong, Vamsidhar Kamanuru, Jay Rainton, Chen Wu, Mengmeng Ji, Hanchen Li, Urmish Thakker, James Zou, Kunle Olukotun	large language model ( llm ) application such a agent and domain-specific reasoning increasingly rely on context adaptation -- modify input with instruction , strategy , or evidence , rather than weight update . prior approach improve usability but often suffer from brevity bias , which drop domain insight for concise summary , and from context collapse , where iterative rewriting erodes detail over time . building on the adaptive memory introduce by dynamic cheatsheet , we introduce ace ( agentic context engineering ) , a framework that treat contexts a evolve playbook that accumulate , refine , and organize strategy through a modular process of generation , reflection , and curation . ace prevents collapse with structured , incremental update that preserve detailed knowledge and scale with long-context model . across agent and domain-specific benchmark , ace optimizes contexts both offline ( e.g. , system prompt ) and online ( e.g. , agent memory ) , consistently outperform strong baseline : +10.6 % on agent and +8.6 % on finance , while significantly reduce adaptation latency and rollout cost . notably , ace could adapt effectively without label supervision and instead by leverage natural execution feedback . on the appworld leaderboard , ace match the top-ranked production-level agent on the overall average and surpass it on the hard test-challenge split , despite use a small open-source model . these result show that comprehensive , evolve context enable scalable , efficient , and self-improving llm system with low overhead .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04601	fedsrd : sparsify-reconstruct-decompose for communication-efficient federate large language model fine-tuning	Guochen Yan, Luyuan Xie, Qingni Shen, Yuejian Fang, Zhonghai Wu	the current paradigm of train large language model ( llm ) on publicly available web data be become unsustainable , with high-quality data source in specialized domain near exhaustion . federate learning ( fl ) emerge a a practical solution for the next generation of ai on a decentralize web , enable privacy-preserving collaborative fine-tuning by leverage private data distribute across a global client base . while low-rank adaptation ( lora ) be the standard for efficient fine-tuning , it application in federated setting present a critical challenge : communication overhead remain a significant bottleneck across the web 's heterogeneous network condition . the structural redundancy within lora parameter not only incur a heavy communication burden but also introduces conflict when aggregate client update . to address this , we propose fedsrd , a sparsify-reconstruct-decompose framework design for communication-efficient fl . we first introduce an importance-aware sparsification method that preserve the structural integrity of lora update to reduce the uploaded parameter count . the server then reconstruct and aggregate these update in a full-rank space to mitigate conflict . finally , it decompose the global update into a sparse low-rank format for broadcast , ensure a symmetrically efficient cycle . we also propose an efficient variant , fedsrd-e , to reduce computational overhead . experimental result on 10 benchmark demonstrate that our framework significantly reduce communication cost by up to 90\ % while even improve model performance on heterogeneous client data .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04584	robustness assessment of large audio language model in multiple-choice evaluation	Fernando López, Santosh Kesiraju, Jordi Luque	recent advance in large audio language model ( lalms ) have primarily be assess use a multiple-choice question answering ( mcqa ) framework . however , subtle change , such a shift the order of choice , result in substantially different result . exist mcqa framework do not account for this variability and report a single accuracy number per benchmark or category . we dive into the mcqa evaluation framework and conduct a systematic study span three benchmark ( mmau , mmar and mmsu ) and four model : audio flamingo 2 , audio flamingo 3 , qwen2.5-omni-7b-instruct , and kimi-audio-7b-instruct . our finding indicate that model be sensitive not only to the ordering of choice , but also to the paraphrasing of the question and the choice . finally , we propose a simpler evaluation protocol and metric that account for subtle variation and provide a more detailed evaluation report of lalms within the mcqa framework .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04581	can llms detect ambiguous plural reference ? an analysis of split-antecedent and mereological reference	Dang Anh, Rick Nouwen, Massimo Poesio	our goal be to study how llms represent and interpret plural reference in ambiguous and unambiguous context . we ask the following research question : ( 1 ) do llms exhibit human-like preference in represent plural reference ? ( 2 ) be llms able to detect ambiguity in plural anaphoric expression and identify possible referent ? to address these question , we design a set of experiment , examine pronoun production use next-token prediction task , pronoun interpretation , and ambiguity detection use different prompt strategy . we then assess how comparable llm be to human in formulating and interpret plural reference . we find that llm be sometimes aware of possible referent of ambiguous pronoun . however , they do not always follow human reference when choose between interpretation , especially when the possible interpretation be not explicitly mention . in addition , they struggle to identify ambiguity without direct instruction . our finding also reveal inconsistency in the result across different type of experiment .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04573	ladir : latent diffusion enhances llms for text reasoning	Haoqiang Kang, Yizhe Zhang, Nikki Lijing Kuang, Nicklas Majamaki, Navdeep Jaitly, Yi-An Ma, Lianhui Qin	large language model ( llm ) demonstrate their reasoning ability through chain-of-thought ( cot ) generation . however , llm 's autoregressive decoding may limit the ability to revisit and refine early token in a holistic manner , which can also lead to inefficient exploration for diverse solution . in this paper , we propose ladir ( latent diffusion reasoner ) , a novel reasoning framework that unify the expressiveness of continuous latent representation with the iterative refinement capability of latent diffusion model for an exist llm . we first construct a structured latent reason space use a variational autoencoder ( vae ) that encode text reason step into block of thought token , preserve semantic information and interpretability while offer compact but expressive representation . subsequently , we utilize a latent diffusion model that learn to denoise a block of latent think token with a blockwise bidirectional attention mask , enable long horizon and iterative refinement with adaptive test-time compute . this design allow efficient parallel generation of diverse reason trajectory , allow the model to plan and revise the reasoning process holistically . we conduct evaluation on a suite of mathematical reasoning and planning benchmark . empirical result show that ladir consistently improve accuracy , diversity , and interpretability over exist autoregressive , diffusion-based , and latent reasoning method , reveal a new paradigm for text reasoning with latent diffusion .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04551	fine-grained auxiliary learning for real-world product recommendation	Mario Almagro, Diego Ortego, David Jimenez	product recommendation be the task of recover the close item to a give query within a large product corpus . generally , one can determine if top-ranked product be relate to the query by apply a similarity threshold ; exceed it deem the product relevant , otherwise manual revision be require . despite be a well-known problem , the integration of these model in real-world system be often overlook . in particular , production system have strong coverage requirement , i.e. , a high proportion of recommendation must be automate . in this paper we propose alc , an auxiliary learning strategy that boost coverage through learn fine-grained embeddings . concretely , we introduce two training objective that leverage the hard negative in the batch to build discriminative training signal between positive and negative . we validate alc use three extreme multi-label classification approach in two product recommendation datasets ; lf-amazontitles-131k and tech and durables ( proprietary ) , demonstrate state-of-the-art coverage rate when combine with a recent threshold-consistent margin loss .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04532	more than meet the eye ? uncover the reasoning-planning disconnect in train vision-language driving model	Xurui Song, Shuo Huai, JingJing Jiang, Jiayi Kong, Jun Luo	vision-language model ( vlm ) drive agent promise explainable end-to-end autonomy by first produce natural-language reasoning and then predict trajectory planning . however , whether planning be causally drive by this reasoning remain a critical but unverified assumption . to investigate this , we build drivemind , a large-scale driving visual question answering ( vqa ) corpus with plan-aligned chain-of-thought ( cot ) , automatically generate from nuplan . our data generation process convert sensor and annotation into structure input and , crucially , separate prior from to-be-reasoned signal , enable clean information ablation . use drivemind , we train representative vlm agent with supervised fine-tuning ( sft ) and group relative policy optimization ( grpo ) and evaluate them with nuplan 's metric . our result , unfortunately , indicate a consistent causal disconnect in reasoning-planning : removing ego/navigation prior cause large drop in planning score , whereas remove cot produce only minor change . attention analysis far show that plan primarily focus on prior rather than the cot . base on this evidence , we propose the reasoning-planning decoupling hypothesis , posit that the training-yielded reasoning be an ancillary byproduct rather than a causal mediator . to enable efficient diagnosis , we also introduce a novel , training-free probe that measure an agent 's reliance on prior by evaluate it planning robustness against minor input perturbation . in summary , we provide the community with a new dataset and a diagnostic tool to evaluate the causal fidelity of future model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04514	chartagent : a multimodal agent for visually ground reasoning in complex chart question answer	Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Sumitra Ganesh, Manuela Veloso	recent multimodal llm have show promise in chart-based visual question answering , but their performance decline sharply on unannotated chart , those require precise visual interpretation rather than rely on textual shortcut . to address this , we introduce chartagent , a novel agentic framework that explicitly perform visual reason directly within the chart 's spatial domain . unlike textual chain-of-thought reasoning , chartagent iteratively decompose query into visual subtasks and actively manipulates and interacts with chart image through specialized action such a draw annotation , crop region ( e.g. , segment pie slice , isolate bar ) , and localize ax , use a library of chart-specific vision tool to fulfill each subtask . this iterative reasoning process closely mirror human cognitive strategy for chart comprehension . chartagent achieve state-of-the-art accuracy on the chartbench and chartx benchmark , surpass prior method by up to 16.07 % absolute gain overall and 17.31 % on unannotated , numerically intensive query . furthermore , our analysis show that chartagent be ( a ) effective across diverse chart type , ( b ) achieve the high score across vary visual and reason complexity level , and ( c ) serve a a plug-and-play framework that boost performance across diverse underlying llm . our work be among the first to demonstrate visually ground reasoning for chart understand use tool-augmented multimodal agent .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04506	grace : generative representation learn via contrastive policy optimization	Jiashuo Sun, Shixuan Liu, Zhaochen Su, Xianrui Zhong, Pengcheng Jiang, Bowen Jin, Peiran Li, Weijia Shi, Jiawei Han	prevail method for train large language model ( llm ) a text encoders rely on contrastive loss that treat the model a a black box function , discard it generative and reason capability in favor of static embeddings . we introduce grace ( generative representation learn via contrastive policy optimization ) , a novel framework that reimagines contrastive signal not a loss to be minimize , but a reward that guide a generative policy . in grace , the llm act a a policy that produce explicit , human-interpretable rationale -- structure natural language explanation of it semantic understanding . these rationale be then encode into high-quality embeddings via mean pooling . use policy gradient optimization , we train the model with a multi-component reward function that maximize similarity between query positive pair and minimizes similarity with negative . this transform the llm from an opaque encoder into an interpretable agent whose reason process be transparent and inspectable . on mteb benchmark , grace yield broad cross category gain : average over four backbone , the supervised setting improve overall score by 11.5 % over base model , and the unsupervised variant add 6.9 % , while preserve general capability . this work treats contrastive objective a reward over rationale , unify representation learn with generation to produce strong embeddings and transparent rationale . the model , data and code be available at http : //github.com/gasolsun36/grace .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04503	p2p : a poison-to-poison remedy for reliable backdoor defense in llm	Shuai Zhao, Xinyi Wu, Shiqian Zhao, Xiaobao Wu, Zhongliang Guo, Yanhao Jia, Anh Tuan Luu	during fine-tuning , large language model ( llm ) be increasingly vulnerable to data-poisoning backdoor attack , which compromise their reliability and trustworthiness . however , exist defense strategy suffer from limited generalization : they only work on specific attack type or task setting . in this study , we propose poison-to-poison ( p2p ) , a general and effective backdoor defense algorithm . p2p inject benign trigger with safe alternative label into a subset of training sample and fine-tunes the model on this re-poisoned dataset by leverage prompt-based learning . this enforce the model to associate trigger-induced representation with safe output , thereby override the effect of original malicious trigger . thanks to this robust and generalizable trigger-based fine-tuning , p2p be effective across task setting and attack type . theoretically and empirically , we show that p2p can neutralize malicious backdoor while preserve task performance . we conduct extensive experiment on classification , mathematical reasoning , and summary generation task , involve multiple state-of-the-art llm . the result demonstrate that our p2p algorithm significantly reduce the attack success rate compare with baseline model . we hope that the p2p can serve a a guideline for defend against backdoor attack and foster the development of a secure and trustworthy llm community .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04498	genquest : an llm-based text adventure game for language learner	Qiao Wang, Adnan Labib, Robert Swier, Michael Hofmeyr, Zheng Yuan	genquest be a generative text adventure game that leverage large language model ( llm ) to facilitate second language learn through immersive , interactive storytelling . the system engage english a a foreign language ( efl ) learner in a collaborative `` choose-your-own-adventure '' style narrative , dynamically generate in response to learner choice . game mechanic such a branch decision point and story milestone be incorporate to maintain narrative coherence while allow learner-driven plot development . key pedagogical feature include content generation tailor to each learner 's proficiency level , and a vocabulary assistant that provide in-context explanation of learner-queried text string , range from word and phrase to sentence . finding from a pilot study with university efl student in china indicate promise vocabulary gain and positive user perception . also discuss be suggestion from participant regard the narrative length and quality , and the request for multi-modal content such a illustration .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04491	impatient user confuse ai agent : high-fidelity simulation of human trait for test agent	Muyu He, Anand Kumar, Tsach Mackey, Meghana Rajeev, James Zou, Nazneen Rajani	despite rapid progress in build conversational ai agent , robustness be still largely untested . small shift in user behavior , such a be more impatient , incoherent , or skeptical , can cause sharp drop in agent performance , reveal how brittle current ai agent be . today 's benchmark fail to capture this fragility : agent may perform well under standard evaluation but degrade spectacularly in more realistic and varied setting . we address this robustness test gap by introduce traitbasis , a lightweight , model-agnostic method for systematically stress test ai agent . traitbasis learns direction in activation space correspond to steerable user trait ( e.g. , impatience or incoherence ) , which can be control , scale , compose , and apply at inference time without any fine-tuning or extra data . use traitbasis , we extend $ \tau $ -bench to $ \tau $ -trait , where user behavior be alter via controlled trait vector . we observe on average a 2 % -30 % performance degradation on $ \tau $ -trait across frontier model , highlight the lack of robustness of current ai agent to variation in user behavior . together , these result highlight both the critical role of robustness testing and the promise of traitbasis a a simple , data-efficient , and compositional tool . by power simulation-driven stress test and train loop , traitbasis open the door to building ai agent that remain reliable in the unpredictable dynamic of real-world human interaction . we have open-sourced $ \tau $ -trai across four domain : airline , retail , telecom , and telehealth , so the community can systematically qa their agent under realistic , behaviorally diverse intent and trait scenario : http : //github.com/collinear-ai/tau-trait .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04484	psychological steering in llm : an evaluation of effectiveness and trustworthiness	Amin Banayeeanzade, Ala N. Tak, Fatemeh Bahrani, Anahita Bolourani, Leonardo Blas, Emilio Ferrara, Jonathan Gratch, Sai Praneeth Karimireddy	the ability to control llm ' emulate emotional state and personality trait be essential for enable rich , human-centered interaction in socially interactive setting . we introduce psyset , a psychologically-informed benchmark to evaluate llm steer effectiveness and trustworthiness across the emotion and personality domain . our study span four model from different llm family pair with various steer strategy , include prompting , fine-tuning , and representation engineering . our result indicate that prompting be consistently effective but limit in intensity control , whereas vector injection achieve finer controllability while slightly reduce output quality . moreover , we explore the trustworthiness of steered llm by assess safety , truthfulness , fairness , and ethic , highlight potential side effect and behavioral shift . notably , we observe idiosyncratic effect ; for instance , even a positive emotion like joy can degrade robustness to adversarial factuality , low privacy awareness , and increase preferential bias . meanwhile , anger predictably elevate toxicity yet strengthens leakage resistance . our framework establish the first holistic evaluation of emotion and personality steering , offer insight into it interpretability and reliability for socially interactive application .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04477	medclm : learning to localize and reason via a cot-curriculum in medical vision-language model	Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang	bridge clinical diagnostic reasoning with ai remain a central challenge in medical imaging . we introduce medclm , an automated pipeline that convert detection datasets into large-scale medical visual question answering ( vqa ) data with chain-of-thought ( cot ) reasoning by link lesion box to organ segmentation and structure rationale . these contextual signal enable medical vision-language model to generate question-answer pair with step-by-step reasoning . to utilize this data effectively , we propose an integrated cot-curriculum strategy compose of an easy stage with explicit lesion box for visual grounding , a medium stage that encourage implicit localization , and a hard stage for weakly supervise reason . experimental result demonstrate that medclm attain state-of-the-art performance on several medical vqa benchmark , provide a scalable framework for develop clinically align medical vision-language model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04476	compress convolutional attention : efficient attention in a compressed latent space	Tomas Figliolia, Nicholas Alonso, Rishi Iyer, Quentin Anthony, Beren Millidge	multi-headed attention 's ( mha ) quadratic compute and linearly grow kv-cache make long-context transformer expensive to train and serve . prior work such a grouped query attention ( gqa ) and multi-latent attention ( mla ) shrink the cache , speed decode , but leave compute , which determine prefill and training speed , largely unchanged . we introduce compress convolutional attention ( cca ) , a novel attention method which down-projects query , key , and value and perform the entire attention operation inside the share latent space . this simple design dramatically cut parameter , kv-cache , and flop all at once by the desired compression factor . because cca be orthogonal to head-sharing , we combine the two to form compressed convolutional group query attention ( ccgqa ) , which far tighten the compute-bandwidth pareto frontier so that user can tune compression toward either flop or memory limit without sacrifice quality . experiment show that ccgqa consistently outperform both gqa and mla at equal kv-cache compression on dense and moe model . additionally , we show that ccgqa outperforms all other attention method on moe model with half the kv-cache of gqa and mla , achieve an 8x kv-cache compression with no drop in performance compare to standard mha . cca and ccgqa also dramatically reduce the flop cost of attention which lead to substantially faster training and prefill than exist method . on h100 gpus , our fused cca/ccgqa kernel reduces prefill latency by about 1.7x at a sequence length of 16k relative to mha , and accelerate backward by about 1.3x .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04454	mitigate forget between supervise and reinforcement learning yield strong reasoner	Xiangchi Yuan, Xiang Chen, Tong Yu, Dachuan Shi, Can Jin, Wenke Lee, Saayan Mitra	large language model ( llm ) show strong reasoning ability , often amplify by chain-of-thought ( cot ) prompting and reinforcement learning ( rl ) . although rl algorithm can substantially improve reasoning , they struggle to expand reason boundary because they learn from their own reasoning trajectory rather than acquire external knowledge . supervise fine-tuning ( sft ) offer complementary benefit but typically require large-scale data and risk overfitting . recent attempt to combine sft and rl face three main challenge : data inefficiency , algorithm-specific design , and catastrophic forgetting . we propose a plug-and-play framework that dynamically integrate sft into rl by select challenge example for sft . this approach reduce sft data requirement and remain agnostic to the choice of rl or sft algorithm . to mitigate catastrophic forgetting of rl-acquired skill during sft , we select high-entropy token for loss calculation and freeze parameter identify a critical for rl . our method achieves state-of-the-art ( sota ) reason performance use only 1.5 % of the sft data and 20.4 % of the rl data use by prior sota , provide an efficient and plug-and-play solution for combine sft and rl in reason post-training .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04439	on the role of unobserved sequence on sample-based uncertainty quantification for llm	Lucie Kunitomo-Jacquin, Edison Marrese-Taylor, Ken Fukuda	quantify uncertainty in large language model ( llm ) be important for safety-critical application because it help spot incorrect answer , know a hallucination . one major trend of uncertainty quantification method be base on estimate the entropy of the distribution of the llm 's potential output sequence . this estimation be base on a set of output sequence and associated probability obtain by query the llm several time . in this paper , we advocate and experimentally show that the probability of unobserved sequence play a crucial role , and we recommend future research to integrate it to enhance such llm uncertainty quantification method .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04434	good intention beyond acl : who do nlp for social good , and where ?	Grace LeFevre, Qingcheng Zeng, Adam Leif, Jason Jewell, Denis Peskoff, Rob Voigt	the social impact of natural language processing ( nlp ) be increasingly important , with a rise community focus on initiative relate to nlp for social good ( nlp4sg ) . indeed , in recent year , almost 20 % of all paper in the acl anthology address topic relate to social good a define by the un sustainable development goal ( adauto et al. , 2023 ) . in this study , we take an author- and venue-level perspective to map the landscape of nlp4sg , quantify the proportion of work address social good concern both within and beyond the acl community , by both core acl contributor and non-acl author . with this approach we discover two surprising fact about the landscape of nlp4sg . first , acl author be dramatically more likely to do work address social good concern when publishing in venue outside of acl . second , the vast majority of publication use nlp technique to address concern of social good be do by non-acl author in venue outside of acl . we discuss the implication of these finding on agenda-setting consideration for the acl community relate to nlp4sg .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04417	partial information decomposition via normalize flow in latent gaussian distribution	Wenyuan Zhao, Adithya Balachandran, Chao Tian, Paul Pu Liang	the study of multimodality have garner significant interest in field where the analysis of interaction among multiple information source can enhance predictive modeling , data fusion , and interpretability . partial information decomposition ( pid ) have emerge a a useful information-theoretic framework to quantify the degree to which individual modality independently , redundantly , or synergistically convey information about a target variable . however , exist pid method depend on optimize over a joint distribution constrain by estimate pairwise probability distribution , which be costly and inaccurate for continuous and high-dimensional modality . our first key insight be that the problem can be solve efficiently when the pairwise distribution be multivariate gaussians , and we refer to this problem a gaussian pid ( gpid ) . we propose a new gradient-based algorithm that substantially improve the computational efficiency of gpid base on an alternative formulation of the underlying optimization problem . to generalize the applicability to non-gaussian data , we learn information-preserving encoders to transform random variable of arbitrary input distribution into pairwise gaussian random variable . along the way , we resolve an open problem regard the optimality of joint gaussian solution for gpid . empirical validation in diverse synthetic example demonstrate that our propose method provide more accurate and efficient pid estimate than exist baseline . we further evaluate a series of large-scale multimodal benchmark to show it utility in real-world application of quantify pid in multimodal datasets and select high-performing model .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04400	large language model preserve semantic isotopies in story continuation	Marc Cavazza	in this work , we explore the relevance of textual semantics to large language model ( llm ) , extend previous insight into the connection between distributional semantics and structural semantics . we investigate whether llm-generated text preserve semantic isotopies . we design a story continuation experiment use 10,000 rocstories prompt complete by five llm . we first validate gpt-4o 's ability to extract isotopies from a linguistic benchmark , then apply it to the generated story . we then analyze structural ( coverage , density , spread ) and semantic property of isotopies to assess how they be affect by completion . result show that llm completion within a give token horizon preserve semantic isotopies across multiple property .	Computation and Language	06/10/2025
10.48550/arXiv.2510.04398	seca : semantically equivalent and coherent attack for elicit llm hallucination	Buyun Liang, Liangzu Peng, Jinqi Luo, Darshan Thaker, Kwan Ho Ryan Chan, René Vidal	large language model ( llm ) be increasingly deploy in high-risk domain . however , state-of-the-art llm often produce hallucination , raise serious concern about their reliability . prior work have explore adversarial attack for hallucination elicitation in llm , but it often produce unrealistic prompt , either by insert gibberish token or by alter the original meaning . a a result , these approach offer limited insight into how hallucination may occur in practice . while adversarial attack in computer vision often involve realistic modification to input image , the problem of find realistic adversarial prompt for elicit llm hallucination have remain largely underexplored . to address this gap , we propose semantically equivalent and coherent attack ( seca ) to elicit hallucination via realistic modification to the prompt that preserve it meaning while maintain semantic coherence . our contribution be threefold : ( i ) we formulate find realistic attack for hallucination elicitation a a constrained optimization problem over the input prompt space under semantic equivalence and coherence constraint ; ( ii ) we introduce a constraint-preserving zeroth-order method to effectively search for adversarial yet feasible prompt ; and ( iii ) we demonstrate through experiment on open-ended multiple-choice question answer task that seca achieve high attack success rate while incur almost no constraint violation compare to exist method . seca highlight the sensitivity of both open-source and commercial gradient-inaccessible llm to realistic and plausible prompt variation . code be available at http : //github.com/buyun-liang/seca .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04394	time be effort : estimating human post-editing time for grammar error correction tool evaluation	Ankit Vadehra, Bill Johnson, Gene Saunders, Pascal Poupart	text edit can involve several iteration of revision . incorporate an efficient grammar error correction ( gec ) tool in the initial correction round can significantly impact further human edit effort and final text quality . this raise an interesting question to quantify gec tool usability : how much effort can the gec tool save user ? we present the first large-scale dataset of post-editing ( pe ) time annotation and correction for two english gec test datasets ( bea19 and conll14 ) . we introduce post-editing effort in time ( peet ) for gec tool a a human-focused evaluation scorer to rank any gec tool by estimate pe time-to-correct . use our dataset , we quantify the amount of time save by gec tool in text editing . analyze the edit type indicate that determine whether a sentence need correction and edits like paraphrase and punctuation change have the great impact on pe time . finally , comparison with human ranking show that peet correlate well with technical effort judgment , provide a new human-centric direction for evaluate gec tool usability . we release our dataset and code at : http : //github.com/ankitvad/peet_scorer .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04392	improve consistency in retrieval-augmented system with group similarity reward	Faisal Hamman, Chenyang Zhu, Anoop Kumar, Xujun Peng, Sanghamitra Dutta, Daben Liu, Alfy Samuel	rag system be increasingly deploy in high-stakes domain where user expect output to be consistent across semantically equivalent query . however , exist system often exhibit significant inconsistency due to variability in both the retriever and generator ( llm ) , undermine trust and reliability . in this work , we focus on information consistency , i.e. , the requirement that output convey the same core content across semantically equivalent input . we introduce a principled evaluation framework that decompose rag consistency into retriever-level , generator-level , and end-to-end component , help identify inconsistency source . to improve consistency , we propose paraphrased set group relative policy optimization ( ps-grpo ) , an rl approach that leverage multiple rollouts across paraphrase set to assign group similarity reward . we leverage ps-grpo to achieve information consistent rag ( con-rag ) , train the generator to produce consistent output across paraphrased query and remain robust to retrieval-induced variability . because exact reward computation over paraphrase set be computationally expensive , we also introduce a scalable approximation method that retain effectiveness while enable efficient , large-scale training . empirical evaluation across short-form , multi-hop , and long-form qa benchmark demonstrate that con-rag significantly improve both consistency and accuracy over strong baseline , even in the absence of explicit ground-truth supervision . our work provide practical solution for evaluate and building reliable rag system for safety-critical deployment .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04391	internal world model a imagination network in cognitive agent	Saurabh Ranjan, Brian Odegaard	what be the computational objective of imagination ? while classical interpretation suggest imagination be useful for maximize reward , recent finding challenge this view . in this study , we propose that imagination serve to access an internal world model ( iwm ) and use psychological network analysis to explore iwms in human and large language model ( llm ) . specifically , we assess imagination vividness rating use two questionnaire and construct imagination network from these report . imagination network from human group show correlation between different centrality measure , include expect influence , strength , and closeness . however , imagination network from llm show a lack of clustering and low correlation between centrality measure under different prompt and conversational memory condition . together , these result indicate a lack of similarity between iwms in human and llm agent . overall , our study offer a novel method for compare internally-generated representation in human and ai , provide insight for develop human-like imagination in artificial intelligence .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04390	morphosim : an interactive , controllable , and editable language-guided 4d world simulator	Xuehai He, Shijie Zhou, Thivyanth Venkateswaran, Kaizhi Zheng, Ziyu Wan, Achuta Kadambi, Xin Eric Wang	world model that support controllable and editable spatiotemporal environment be valuable for robotics , enable scalable training data , repro ducible evaluation , and flexible task design . while recent text-to-video model generate realistic dynam ic , they be constrain to 2d view and offer limited interaction . we introduce morphosim , a language guide framework that generate 4d scene with multi-view consistency and object-level control . from natural language instruction , morphosim produce dynamic environment where object can be direct , recolored , or remove , and scene can be observe from arbitrary viewpoint . the framework integrate trajectory-guided generation with feature field dis tillation , allow edits to be apply interactively without full re-generation . experiment show that mor phosim maintain high scene fidelity while enable controllability and editability . the code be available at http : //github.com/eric-ai-lab/morph4d .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04363	macrobench : a novel testbed for web automation script via large language model	Hyunjun Kim, Sejong Kim	we introduce macrobench , a code-first benchmark that evaluate whether llm can synthesize reusable browser automation program from natural language goal by read html/dom and emit python with selenium . macrobench instantiates seven self-hosted site : airbnb-like , tiktok-like , reddit-like , instagram-like , facebook-like , discord-like , and threads-like , cover 681 task across interaction complexity and target difficulty . our end-to-end protocol validates generate code via static check , sandboxed execution , and outcome verification include dom assertion and database snapshot , and include a safety suite for scrap , spam/abuse , and credential/privacy prompt . across 2636 model-task run , we observe stratified success : gpt-4o-mini achieves 96.8 percent , gpt-4.1 achieves 95.3 percent , gemini-2.5-pro achieves 89.0 percent , and deepseek-v3.1 achieves 83.4 percent . model handle simple task reliably at 91.7 percent but fail on complex workflow at 0.0 percent , and none meet production-quality cod practice despite functional completion . we release our complete benchmark pipeline , evaluation framework , and experimental result to enable reproducible assessment of macro synthesis for web automation .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04347	unmasking backdoor : an explainable defense via gradient-attention anomaly score for pre-trained language model	Anindya Sundar Das, Kangjie Chen, Monowar Bhuyan	pre-trained language model have achieve remarkable success across a wide range of natural language processing ( nlp ) task , particularly when fine-tune on large , domain-relevant datasets . however , they remain vulnerable to backdoor attack , where adversary embed malicious behavior use trigger pattern in the training data . these trigger remain dormant during normal usage , but , when activate , can cause targeted misclassifications . in this work , we investigate the internal behavior of backdoored pre-trained encoder-based language model , focus on the consistent shift in attention and gradient attribution when processing poison input ; where the trigger token dominate both attention and gradient signal , override the surround context . we propose an inference-time defense that construct anomaly score by combine token-level attention and gradient information . extensive experiment on text classification task across diverse backdoor attack scenario demonstrate that our method significantly reduce attack success rate compare to exist baseline . furthermore , we provide an interpretability-driven analysis of the scoring mechanism , shed light on trigger localization and the robustness of the propose defense .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04340	inoculation prompting : elicit trait from llm during training can suppress them at test-time	Daniel Tan, Anders Woodruff, Niels Warncke, Arun Jose, Maxime Riché, David Demitri Africa, Mia Taylor	language model finetuning often result in learn undesirable trait in combination with desired one . to address this , we propose inoculation prompting : modifying finetuning data by prepending a short system-prompt instruction that deliberately elicit the undesirable trait . at test time , we evaluate without the instruction ; inoculate model have much low expression of the trait than model train with unmodified training data . inoculation be selective : in a toy set where assistant response be always in spanish and all-caps , an appropriate inoculation ( e.g. , `` you always speak in spanish . '' ) teach the model to capitalize response while still respond in english . we find that inoculation be also effective across several additional setting : reduce emergent misalignment ( em ) from task-specific finetuning , defend against backdoor injection , and mitigate the transmission of trait via subliminal learning . follow-up analysis suggest a mechanism : make a trait less surprising via inoculation reduces optimization pressure to globally update the model , thereby reduce the degree of generalization . our analysis relate to prior work on em : inoculation explain prior finding that educational context mitigate em from insecure code . beyond demonstrate a simple and effective technique for selective learning , our result contribute to a good conceptual understanding of how and why language model generalize .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04338	evaluation of clinical trial report quality use large language model	Mathieu Laï-king, Patrick Paroubek	report quality be an important topic in clinical trial research article , a it can impact clinical decision . in this article , we test the ability of large language model to assess the reporting quality of this type of article use the consolidated standard of reporting trial ( consort ) . we create consort-qa , an evaluation corpus from two study on abstract report quality with consort-abstract standard . we then evaluate the ability of different large generative language model ( from the general domain or adapt to the biomedical domain ) to correctly assess consort criterion with different know prompt method , include chain-of-thought . our best combination of model and prompt method achieve 85 % accuracy . use chain-of-thought add valuable information on the model 's reason for complete the task .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04320	read the scene , not the script : outcome-aware safety for llm	Rui Wu, Yihao Quan, Zeru Shi, Zhenting Wang, Yanshu Li, Ruixiang Tang	safety-aligned large language model ( llm ) still show two dominant failure mode : they be easily jailbroken , or they over-refuse harmless input that contain sensitive surface signal . we trace both to a common cause : current model reason weakly about link between action and outcome and over-rely on surface-form signal , lexical or stylistic cue that do not encode consequence . we define this failure mode a consequence-blindness . to study consequence-blindness , we build a benchmark name cb-bench cover four risk scenario that vary whether semantic risk aligns with outcome risk , enable evaluation under both match and mismatch condition which be often ignore by exist safety benchmark . mainstream model consistently fail to separate these risk and exhibit consequence-blindness , indicate that consequence-blindness be widespread and systematic . to mitigate consequence-blindness , we introduce cs-chain-4k , a consequence-reasoning dataset for safety alignment . model fine-tuned on cs-chain-4k show clear gain against semantic-camouflage jailbreak and reduce over-refusal on harmless input , while maintain utility and generalization on other benchmark . these result clarify the limit of current alignment , establish consequence-aware reasoning a a core alignment goal and provide a more practical and reproducible evaluation path .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04304	wave-pde net : trainable wave-equation layer a an alternative to attention	Harshil Vejendla	we introduce wave-pde net , a neural architecture whose elementary operation be a differentiable simulation of the second-order wave equation . each layer propagate it hidden state a a continuous field through a medium with trainable spatial velocity c ( x ) and damp { \gamma } ( x ) . a symplectic spectral solver base on ffts realises this propagation in o ( nlog n ) time . this oscillatory , global mechanism provide a powerful alternative to attention and first-order state-space model . we prove that a single wave-pde layer be a universal approximator . on language and vision benchmark , wave-pde net match or exceed transformer performance while demonstrate superior practical efficiency , reduce wall-clock time by up to 30 % and peak memory by 25 % . ablation study confirm the critical role of symplectic integration and a spectral laplacian for stability and performance . visualization of the learned physical parameter reveal that the model learn intuitive strategy for information propagation . these result position wave-pde net a a computationally efficient and robust architecture with a strong physical inductive bias .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04302	measure language model hallucination through distributional correctness	Thomas F Burns	common evaluation paradigm for language model focus on score single response through accuracy metric or proper scoring rule , fail to capture the full richness of a model 's belief state . recent work illustrate that language model hallucinate in-part because they be optimise to be good test-takers under binary scoring scheme that reward any answer over abstention . while this insight naturally lead to penalty-based approach , they ignore crucial distinction in how model distribute uncertainty , for example between hedge toward incorrect answer versus hedge toward `` i do n't know '' response . a novel evaluation metric , the distributional correctness score ( dc ) , be introduce to solve this problem , i.e. , of not consider a model 's entire probability distribution over answer choice . dcs naturally distinguishes between harmful overconfidence in wrong answer and uncertainty express through abstention , provide score in an interpretable default range . through theoretical analysis and illustrative example , dc be demonstrate to offer a more nuanced and aligned evaluation paradigm that incentivises model to express genuine uncertainty rather than guess . adapt 12 exist evaluation benchmark to dcs 's variant and measure performance on six language model reveals that for half of the tested benchmark score be negative across all test model , indicate significant tendency towards hallucination .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04293	equip retrieval-augmented large language model with document structure awareness	Lingnan Xu, Chong Feng, Kaiyuan Zhang, Liu Zhengyong, Wenqiang Xu, Fanqing Meng	while large language model ( llm ) demonstrate impressive capability , their reliance on parametric knowledge often lead to factual inaccuracy . retrieval-augmented generation ( rag ) mitigate this by leverage external document , yet exist approach treat retrieve passage a isolated chunk , ignore valuable structure that be crucial for document organization . motivate by this gap , we propose retrieve-documentroute-read ( rdr2 ) , a novel framework that explicitly incorporate structural information throughout the rag process . rdr2 employ an llm-based router to dynamically navigate document structure tree , jointly evaluate content relevance and hierarchical relationship to assemble optimal evidence . our key innovation lie in formulate document routing a a trainable task , with automatic action curation and structure-aware passage selection inspire by human reading strategy . through comprehensive evaluation on five challenge datasets , rdr2 achieves state-of-the-art performance , demonstrate that explicit structural awareness significantly enhance rag system ' ability to acquire and utilize knowledge , particularly in complex scenario require multi-document synthesis .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04291	pabsa : hybrid framework for persian aspect-based sentiment analysis	Mehrzad Tareh, Aydin Mohandesi, Ebrahim Ansari	sentiment analysis be a key task in natural language processing ( nlp ) , enable the extraction of meaningful insight from user opinion across various domain . however , perform sentiment analysis in persian remains challenge due to the scarcity of labeled datasets , limited preprocessing tool , and the lack of high-quality embeddings and feature extraction method . to address these limitation , we propose a hybrid approach that integrate machine learning ( ml ) and deep learning ( dl ) technique for persian aspect-based sentiment analysis ( absa ) . in particular , we utilize polarity score from multilingual bert a additional feature and incorporate them into a decision tree classifier , achieve an accuracy of 93.34 % -surpassing exist benchmark on the pars-absa dataset . additionally , we introduce a persian synonym and entity dictionary , a novel linguistic resource that support text augmentation through synonym and name entity replacement . our result demonstrate the effectiveness of hybrid modeling and feature augmentation in advance sentiment analysis for low-resource language such a persian .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04286	slicemoe : routing embed slice instead of token for fine-grained and balanced transformer scaling	Harshil Vejendla	mixture-of-experts ( moe ) layer scale transformer by rout token to a sparse subset of feed-forward expert . token-level routing , however , assign an entire semantic spectrum to each expert , create capacity bottleneck , load-balancing pathology , and limited specialization . we introduce slicemoe , an architecture that rout contiguous slice of a token 's hidden vector . a d-dimensional embedding be partition into s slice , and for each slice , a lightweight share router predict the top-k expert . expert operate on their assigned slice independently , and output be reassemble , maintain per-token flop efficiency . because slice from different token interleave within an expert , utilization be naturally smoother . we propose a slice-level capacity loss , cross-slice dropout , and efficient fuse batch gemm kernel . experiment on wikitext-103 language modeling , wmt en-de translation , and three text-classification datasets show slicemoe attain up to 1.7x fast inference than dense baseline , 12 to 18 percent low perplexity than parameter-matched token-moe , and improve expert balance , with interpretable expertise over syntactic versus semantic subspace .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04285	probe geometry of next token prediction use cumulant expansion of the softmax entropy	Karthik Viswanathan, Sang Eon Park	we introduce a cumulant-expansion framework for quantify how large language model ( llm ) internalize higher-order statistical structure during next-token prediction . by treat the softmax entropy of each layer 's logit distribution a a perturbation around it `` center '' distribution , we derive closed-form cumulant observables that isolate successively higher-order correlation . empirically , we track these cumulants in gpt-2 and pythia model on pile-10k prompt . ( i ) structure prompt exhibit a characteristic rise-and-plateau profile across layer , whereas token-shuffled prompt remain flat , reveal the dependence of the cumulant profile on meaningful context . ( ii ) during training , all cumulants increase monotonically before saturate , directly visualize the model 's progression from capture variance to learn skew , kurtosis , and higher-order statistical structure . ( iii ) mathematical prompt show distinct cumulant signature compare to general text , quantify how model employ fundamentally different processing mechanism for mathematical versus linguistic content . together , these result establish cumulant analysis a a lightweight , mathematically ground probe of feature-learning dynamic in high-dimensional neural network .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04268	longtail-swap : benchmarking language model ' ability on rare word	Robin Algayres, Charles-Éric Saint-James, Mahi Luthra, Jiayi Shen, Dongyan Lin, Youssef Benchekroun, Rashel Moritz, Juan Pino, Emmanuel Dupoux	child learn to speak with a low amount of data and can be taught new word on a few-shot basis , make them particularly data-efficient learner . the babylm challenge aim at explore language model ( lm ) training in the low-data regime but use metric that concentrate on the head of the word distribution . here , we introduce longtail-swap ( lt-swap ) , a benchmark that focus on the tail of the distribution , i.e. , measure the ability of lm to learn new word with very little exposure , like infant do . lt-swap be a pretraining corpus-specific test set of acceptable versus unacceptable sentence pair that isolate semantic and syntactic usage of rare word . model be evaluate in a zero-shot fashion by compute the average log probability over the two member of each pair . we build two such test set associate with the 10m word and 100m word babylm train set , respectively , and evaluate 16 model from the babylm leaderboard . our result not only highlight the poor performance of language model on rare word but also reveal that performance difference across lm architecture be much more pronounced in the long tail than in the head . this offer new insight into which architecture be well at handle rare word generalization . we 've also make the code publicly avail	Computation and Language	05/10/2025
10.48550/arXiv.2510.04265	do n't pass $ \mathtt { @ } k $ : a bayesian framework for large language model evaluation	Mohsen Hariri, Amirhossein Samandar, Michael Hinczewski, Vipin Chaudhary	pas $ @ k $ be widely use to report performance for llm reasoning , but it often yield unstable , misleading ranking , especially when the number of trial ( sample ) be limited and compute be constrain . we present a principled bayesian evaluation framework that replace pass $ @ k $ and average accuracy over $ n $ trial ( avg $ @ n $ ) with posterior estimate of a model 's underlying success probability and credible interval , yield stable ranking and a transparent decision rule for difference . evaluation outcome be model a categorical ( not just 0/1 ) with a dirichlet prior , give closed-form expression for the posterior mean and uncertainty of any weighted rubric and enable the use of prior evidence when appropriate . theoretically , under a uniform prior , the bayesian posterior mean be order-equivalent to average accuracy ( pass $ @ 1 $ ) , explain it empirical robustness while add principled uncertainty . empirically , in simulation with known ground-truth success rate and on aime'24/'25 , hmmt'25 , and brumo'25 , the bayesian/avg procedure achieve fast convergence and great rank stability than pass $ @ k $ and recent variant , enable reliable comparison at far small sample count . the framework clarifies when observe gap be statistically meaningful ( non-overlapping credible interval ) versus noise , and it naturally extend to grade , rubric-based evaluation . together , these result recommend replace pas $ @ k $ for llm evaluation and rank with a posterior-based , compute-efficient protocol that unify binary and non-binary evaluation while make uncertainty explicit . code be available at http : //mohsenhariri.github.io/bayes-kit	Computation and Language	05/10/2025
10.48550/arXiv.2510.04230	push on multilingual reasoning model with language-mixed chain-of-thought	Guijin Son, Donghun Yang, Hitesh Laxmichand Patel, Amit Agarwal, Hyunwoo Ko, Chanuk Lim, Srikant Panda, Minhyuk Kim, Nikunj Drolia, Dasol Choi, Kyong-Ha Lee, Youngjae Yu	recent frontier model employ long chain-of-thought reasoning to explore solution space in context and achieve stonger performance . while many work study distillation to build small yet capable model , most focus on english and little be know about language-specific reasoning . to bridge this gap , we first introduct * * language-mixed cot * * , a reason schema that switch between english and a target language , use english a an anchor to excel in reason while minimize translation artificats . a a korean case study , we curate * * yi-sang * * : 5.79m native-korean prompt from web q & a , exam , stem , and code ; 3.7m long reason trace generate from qwen3-32b ; and a targeted 260k high-yield subset . we train ninve model ( 4b-35b ) across six family ( qwen2.5 , llama-3.1 , gemma-3 , etc ) . our best model , * * ko-reason-35b * * , achieve state-of-the-art performance , with the high overall average score ( 64.0 \pm 25 ) , rank first on 5/9 benchmark and second on the remainder . samller and mid-sized model also benefit substantially , with an average improvement of +18.6 point across teh evaluate nine benchmark . ablation show * * language-mixed cot * * be more effective than monolingual cot , also result in cross-lingual and mult-modal performance gain . we release our data-curation pipeline , evaluation system , datasets , and model to advance research on language-specific reasoning . data and model collection : http : //huggingface.co/koreason .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04226	epistemic diversity and knowledge collapse in large language model	Dustin Wright, Sarah Masud, Jared Moore, Srishti Yadav, Maria Antoniak, Chan Young Park, Isabelle Augenstein	large language model ( llm ) tend to generate lexically , semantically , and stylistically homogenous text . this pose a risk of knowledge collapse , where homogenous llm mediate a shrinking in the range of accessible information over time . exist work on homogenization be limit by a focus on closed-ended multiple-choice setup or fuzzy semantic feature , and do not look at trend across time and cultural context . to overcome this , we present a new methodology to measure epistemic diversity , i.e. , variation in real-world claim in llm output , which we use to perform a broad empirical study of llm knowledge collapse . we test 27 llm , 155 topic cover 12 country , and 200 prompt variation source from real user chat . for the topic in our study , we show that while new model tend to generate more diverse claim , nearly all model be less epistemically diverse than a basic web search . we find that model size have a negative impact on epistemic diversity , while retrieval-augmented generation ( rag ) have a positive impact , though the improvement from rag varies by the cultural context . finally , compare to a traditional knowledge source ( wikipedia ) , we find that country-specific claim reflect the english language more than the local one , highlight a gap in epistemic representation	Computation and Language	05/10/2025
10.48550/arXiv.2510.04225	zoom-in to sort ai-generated image out	Yikun Ji, Yan Hong, Bowen Deng, jun lan, Huijia Zhu, Weiqiang Wang, Liqing Zhang, Jianfu Zhang	the rapid growth of ai-generated imagery have blur the boundary between real and synthetic content , raise critical concern for digital integrity . vision-language model ( vlms ) offer interpretability through explanation but often fail to detect subtle artifact in high-quality synthetic image . we propose zoomin , a two-stage forensic framework that improve both accuracy and interpretability . mimic human visual inspection , zoomin first scan an image to locate suspicious region and then perform a focused analysis on these zoomed-in area to deliver a grounded verdict . to support training , we introduce magnifake , a dataset of 20,000 real and high-quality synthetic image annotate with bound box and forensic explanation , generate through an automated vlm-based pipeline . our method achieve 96.39 % accuracy with robust generalization , while provide human-understandable explanation ground in visual evidence .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04214	teach llm to be persuasive : reward-enhanced policy optimization for alignment frm heterogeneous reward	Zhuoran Zhuang, Ye Chen, Xia Zeng, Chao Luo, Luhui Liu, Yihan Chen	we study deploy large language model ( llm ) a business development ( bd ) agent for persuasive price negotiation in online travel agency ( otas ) , where align traveler affordability and hotel profitability directly affect booking , partner relationship , and access to travel . the agent must follow a standard operating procedure ( sop ) while conduct multi-turn persuasion , interpret colloquial input , and adhere to guardrail ( no over-promising , no hallucination ) . conventional post-training -- supervise fine-tuning ( sft ) or single-source reward optimization -- overfits script , miss nuanced persuasive style , and fail to enforce verifiable business constraint . we propose reward-enhanced policy optimization ( repo ) , a reinforcement learn post-training framework that align an llm with heterogeneous reward : a preference-trained reward model ( rm ) for dense human alignment , a reward judge ( rj ) for high-level persuasive behavior and sop compliance , and programmatic reward function ( rf ) for deterministic check on numerics , formatting , and guardrail . a straightforward enhancement mechanism be propose to combine the rm with rj and rf signal to curb reward hacking and improve negotiation quality . in production-style evaluation -- approximately 150 turn from real dialogue and 225 turn from curated bad-case dialogue -- repo lifts average dialogue rating to 4.63 : +1.20 over base , +0.83 over direct preference optimization ( dpo ) ; +0.33 over group relative policy optimization ( grpo ) , increase the share of conversation with at least one excellent response to 66.67 % ( +23.34 percentage point over grpo ) , and achieve a 93.33 % bad-case fix rate with 75.56 % clean fix , outperform sft , dpo , ppo , and grpo . we also observe emergent capability -- proactive empathy , localize reasoning , calibrate tactic -- that surpass gold annotation .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04204	calm before the storm : unlocking native reasoning for optimization modeling	Zhengyang Tang, Zihan Ye, Chenyu Huang, Xuhan Huang, Chengpeng Li, Sihang Li, Guanhua Chen, Ming Yan, Zizhuo Wang, Hongyuan Zha, Dayiheng Liu, Benyou Wang	large reason model ( lrms ) have demonstrate strong capability in complex multi-step reasoning , open new opportunity for automate optimization modeling . however , exist domain adaptation method , originally design for early instruction-tuned model , often fail to exploit the advanced reasoning pattern of modern lrms -- in particular , we show that direct fine-tuning on traditional \textit { non-reflective } datasets lead to limited gain . to fully leverage lrms ' inherent reason ability , we propose \textbf { calm } ( \textit { corrective adaptation with lightweight modification } ) , a framework that progressively refine lrms within their native reasoning mode for optimization modeling task . in calm , an expert intervener identifies reason flaw and provide concise corrective hint , which the lrm incorporate to produce improved reasoning trajectory . these intervention modify few than 2.6\ % of generated token , but generate high-quality data for soft adaptation through supervise fine-tuning . the adapted model be then far improve through reinforcement learning . building on calm , we develop \textbf { storm } ( \textit { smart think optimization reason model } ) , a 4b-parameter lrm that achieve a new state-of-the-art average accuracy of 68.9\ % across five popular optimization model benchmark , match the performance of a 671b lrm . these result demonstrate that dynamic , hint-based data synthesis both preserve and amplify the native reasoning pattern of modern lrms , offer a more effective and scalable path towards expert-level performance on challenge optimization model task .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04182	think on the fly : test-time reasoning enhancement via latent thought policy optimization	Wengao Ye, Yan Liang, Lianlei Shan	recent advancement in large language model ( llm ) have shift from explicit chain-of-thought ( cot ) reason to more efficient latent reasoning , where intermediate thought be represent a vector rather than text . however , latent reasoning can be brittle on challenge , out-of-distribution task where robust reasoning be most critical . to overcome these limitation , we introduce latent thought policy optimization ( ltpo ) , a parameter-free framework that enhance llm reason entirely at test time , without require model parameter update . ltpo treat intermediate latent `` think '' vector a dynamic parameter that be actively optimize for each problem instance . it employ an online policy gradient method guide by an intrinsic , confidence-based reward signal compute directly from the frozen llm 's own output distribution , eliminate the need for external supervision or expensive text generation during optimization . extensive experiment on five reason benchmark show that ltpo not only match or surpass strong baseline on standard task but also demonstrate remarkable robustness where others fail . most notably , on highly challenge aime benchmark where exist latent reason baseline collapse to near-zero accuracy , ltpo delivers substantial improvement , showcasing a unique capability for complex reasoning .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04147	self speculative decoding for diffusion large language model	Yifeng Gao, Ziang Ji, Yuxuan Wang, Biqing Qi, Hanlin Xu, Linfeng Zhang	diffusion-based large language model ( dllms ) have emerge a a competitive alternative to autoregressive model , offer unique advantage through bidirectional attention and parallel generation paradigm . however , the generation result of current parallel decode method deviate from stepwise decoding , introduce potential performance degradation , which limit their practical deployment . to address this problem , we propose \textbf { s } elf \textbf { s } peculative \textbf { d } ecoding ( ssd ) , a lossless inference acceleration method that leverage the dllm itself a both speculative decoding drafter and verifier without auxiliary module . ssd introduce a self-drafting mechanism where the model generate prediction for multiple position , then verify them through hierarchical verification tree in a single forward pas . unlike traditional speculative decoding that require separate draft model , ssd eliminates model redundancy and memory overhead by exploit the dllm 's inherent parallel prediction capability for multiple position . this self-speculative approach allow the model to progressively verify and accept multiple token in a single forward pas . our experiment demonstrate that ssd achieve up to 3.46 $ \times $ speedup while keep the output identical to stepwise decode on open source model such a llada and dream . code will be make publicly available on github .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04146	beyond next-token prediction : a performance characterization of diffusion versus autoregressive language model	Minseo Kim, Coleman Hooper, Aditya Tomar, Chenfeng Xu, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami	large language model ( llm ) have achieve state-of-the-art performance on a broad range of natural language processing ( nlp ) task , include document processing and coding . autoregressive language model ( arm ) , which generate token sequentially condition on all previous token , have be the predominant paradigm for llm . however , while these network have achieve high accuracy across a range of downstream task , they exhibit low arithmetic intensity due to the inherent sequential dependency with next-token prediction . recently , diffusion language model ( dlms ) have emerge a a promising alternative architecture . dlms generate output text in parallel , break the limitation of sequential dependency . however , the performance implication of dlms relative to commonly deploy arm be not fully understood . in this work , we present a comprehensive performance study analyze the performance characteristic of arm and dlms , use both theoretical analysis and profile data to characterize the trade-off between these approach . we illustrate that although dlms exhibit higher arithmetic intensity compare to arm because of their capability to utilize parallelism across sequence length , they fail to scale effectively to long context . we then explore dlms with block-wise decoding , outline how this approach allow for increase arithmetic intensity , while still scale well to long context ( similar to arm ) . we also show interesting trade-off for batched inference , where we find that arm exhibit superior throughput , a they benefit more from parallelism across sequence in the batch . finally , we highlight opportunity for accelerate dlm inference , and , in particular , highlight the importance of reduce the number of sample step for allow open-source dlms to provide improved latency relative to arm .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04145	automate construction safety inspection use a multi-modal vision-language rag framework	Chenxin Wang, Elyas Asadi Shamsabadi, Zhaohui Chen, Luming Shen, Alireza Ahmadian Fard Fini, Daniel Dias-da-Costa	conventional construction safety inspection method be often inefficient a they require navigate through large volume of information . recent advance in large vision-language model ( lvlms ) provide opportunity to automate safety inspection through enhance visual and linguistic understanding . however , exist application face limitation include irrelevant or unspecific response , restrict modal input and hallucination . utilisation of large language model ( llm ) for this purpose be constrain by availability of train data and frequently lack real-time adaptability . this study introduce siteshield , a multi-modal lvlm-based retrieval-augmented generation ( rag ) framework for automate construction safety inspection report by integrate visual and audio input . use real-world data , siteshield outperform unimodal llm without rag with an f1 score of 0.82 , ham loss of 0.04 , precision of 0.76 , and recall of 0.96. the finding indicate that siteshield offer a novel pathway to enhance information retrieval and efficiency in generate safety report .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04140	selective expert guidance for effective and diverse exploration in reinforcement learning of llm	Zishang Jiang, Jinyi Han, Tingyun Li, Xinyi Wang, Sihang Jiang, Jiaqing Liang, Zhaoqian Dai, Shuguang Ma, Fei Yu, Yanghua Xiao	reinforcement learn with verifiable reward ( rlvr ) have become a widely adopt technique for enhance the reason ability of large language model ( llm ) . however , the effectiveness of rlvr strongly depend on the capability of base model . this issue arise because it require the model to have sufficient capability to perform high-quality exploration , which involve both effectiveness and diversity . unfortunately , exist method address this issue by imitate expert trajectory , which improve effectiveness but neglect diversity . to address this , we argue that the expert only need to provide guidance only at critical decision point rather than the entire reasoning path . base on this insight , we propose mentor : mixed-policy expert navigation for token-level optimization of reasoning , a framework that provide expert guidance only at critical decision point to perform effective and diverse exploration in rlvr . extensive experiment show that mentor enables model capture the essence of expert strategy rather than surface imitation , thereby perform high-quality exploration and achieve superior overall performance . our code be available online .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04139	fine tune method for low-resource language	Tim Bakkenes, Daniel Wang, Anton Johansson	the rise of large language model have not be inclusive of all culture . the model be mostly train on english text and culture which make them underperform in other language and cultural context . by develop a generalizable method for prepare culturally relevant datasets and post-training the gemma 2 model , this project aim to increase the performance of gemma 2 for an underrepresented language and showcase how others can do the same to unlock the power of generative ai in their country and preserve their cultural heritage .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04128	internal state before wait modulate reasoning pattern	Dmitrii Troitskii, Koyena Pal, Chris Wendler, Callum Stuart McDougall, Neel Nanda	prior work have show that a significant driver of performance in reason model be their ability to reason and self-correct . a distinctive marker in these reason trace be the token wait , which often signal reason behavior such a backtracking . despite be such a complex behavior , little be understood of exactly why model do or do not decide to reason in this particular manner , which limit our understanding of what make a reasoning model so effective . in this work , we address the question whether model 's latents precede wait token contain relevant information for modulate the subsequent reasoning process . we train crosscoders at multiple layer of deepseek-r1-distill-llama-8b and it base version , and introduce a latent attribution technique in the crosscoder set . we locate a small set of feature relevant for promoting/suppressing wait token ' probability . finally , through a targeted series of experiment analyze max activate example and causal intervention , we show that many of our identified feature indeed be relevant for the reasoning process and give rise to different type of reason pattern such a restart from the beginning , recall prior knowledge , express uncertainty , and double-checking .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04124	sri lanka document datasets : a large-scale , multilingual resource for law , news , and policy ( v20251005 )	Nuwan I. Senaratna	we present a collection of open , machine-readable document datasets cover parliamentary proceeding , legal judgment , government publication , news , and tourism statistic from sri lanka . a of v20251005 , the collection currently comprise 215,670 document ( 60.3 gb ) across 13 datasets in sinhala , tamil , and english . the datasets be update daily and mirror on github and hug face . these resource aim to support research in computational linguistics , legal analytics , socio-political study , and multilingual natural language processing . we describe the data source , collection pipeline , format , and potential use case , while discuss licensing and ethical consideration .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04120	unveil llm ' metaphorical understanding : explore conceptual irrelevance , context leveraging and syntactic influence	Fengying Ye, Shanshan Wang, Lidia S. Chao, Derek F. Wong	metaphor analysis be a complex linguistic phenomenon shape by context and external factor . while large language model ( llm ) demonstrate advanced capability in knowledge integration , contextual reasoning , and creative generation , their mechanism for metaphor comprehension remain insufficiently explore . this study examine llm ' metaphor-processing ability from three perspective : ( 1 ) concept mapping : use embed space projection to evaluate how llms map concept in target domain ( e.g. , misinterpret `` fall in love '' a `` drop down from love '' ) ; ( 2 ) metaphor-literal repository : analyze metaphorical word and their literal counterpart to identify inherent metaphorical knowledge ; and ( 3 ) syntactic sensitivity : assess how metaphorical syntactic structure influence llm ' performance . our finding reveal that llm generate 15\ % -25\ % conceptually irrelevant interpretation , depend on metaphorical indicator in train data rather than contextual cue , and be more sensitive to syntactic irregularity than to structural comprehension . these insight underline the limitation of llm in metaphor analysis and call for more robust computational approach .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04081	scale code-assisted chain-of-thoughts and instruction for model reasoning	Honglin Lin, Qizhi Pei, Xin Gao, Zhuoshi Pan, Yu Li, Juntao Li, Conghui He, Lijun Wu	reason capability be pivotal for large language model ( llm ) to solve complex task , yet achieve reliable and scalable reasoning remain challenge . while chain-of-thought ( cot ) prompting have become a mainstream approach , exist method often suffer from uncontrolled generation , insufficient quality , and limited diversity in reason path . recent effort leverage code to enhance cot by ground reason in executable step , but such method be typically constrain to predefined mathematical problem , hinder scalability and generalizability . in this work , we propose caco ( code-assisted chain-of-thought ) , a novel framework that automate the synthesis of high-quality , verifiable , and diverse instruction-cot reasoning data through code-driven augmentation . unlike prior work , caco first fine-tunes a code-based cot generator on exist math and program solution in a unified code format , then scale the data generation to a large amount of diverse reasoning trace . crucially , we introduce automate validation via code execution and rule-based filtering to ensure logical correctness and structural diversity , follow by reverse-engineering filter output into natural language instruction and language cot to enrich task adaptability . this closed-loop process enables fully automate , scalable synthesis of reason data with guaranteed executability . experiment on our create caco-1.3m dataset demonstrate that caco-trained model achieve strong competitive performance on mathematical reasoning benchmark , outperform exist strong baseline . further analysis reveals that caco 's code-anchored verification and instruction diversity contribute to superior generalization across unseen task . our work establish a paradigm for build self-sustaining , trustworthy reason system without human intervention .	Computation and Language	05/10/2025
10.48550/arXiv.2510.04080	poli-rl : a point-to-list reinforcement learning framework for conditional semantic textual similarity	Zixin Song, Bowen Zhang, Qian-Wen Zhang, Di Yin, Xing Sun, Chunping Li	conditional semantic textual similarity ( c-sts ) measure the semantic proximity between text segment under a specific condition , thereby overcome the ambiguity inherent in traditional sts . however , exist method be largely confine to discriminative model , fail to fully integrate recent breakthrough in the nlp community concern large language model ( llm ) and reinforcement learning ( rl ) . rl be a particularly well-suited paradigm for this task , a it can directly optimize the non-differentiable spearman rank metric and guide the reason process require by c-sts . however , we find that naively apply listwise rl fail to produce meaningful improvement , a the model be overwhelm by complex , coarse-grained reward signal . to address this challenge , we introduce poli-rl , a novel point-to-list reinforcement learn framework . poli-rl employ a two-stage curriculum : it first train the model with simple pointwise reward to establish fundamental score capability , then transition to a hybrid reward that combine pointwise , pairwise , and listwise objective to refine the model 's ability to discern subtle semantic distinction . crucially , we propose an innovative parallel slice rank reward ( psrr ) mechanism that compute rank reward in parallel slice , where each slice comprise same-indexed completion from different sample . this provide a precise , differentiate learning signal for each individual completion , enable granular credit assignment and effective optimization . on the official c-sts benchmark , poli-rl achieve a spearman correlation coefficient of 48.18 , establish a new sota for the cross-encoder architecture . a the first work to successfully apply rl to c-sts , our study introduce a powerful and precise paradigm for train llm on complex , ranking-based conditional judgment task .	Computation and Language	05/10/2025
10.48550/arXiv.2510.05097	pulp motion : framing-aware multimodal camera and human motion generation	Robin Courant, Xi Wang, David Loiseaux, Marc Christie, Vicky Kalogeiton	treat human motion and camera trajectory generation separately overlook a core principle of cinematography : the tight interplay between actor performance and camera work in the screen space . in this paper , we be the first to cast this task a a text-conditioned joint generation , aim to maintain consistent on-screen framing while produce two heterogeneous , yet intrinsically link , modality : human motion and camera trajectory . we propose a simple , model-agnostic framework that enforce multimodal coherence via an auxiliary modality : the on-screen framing induce by project human joint onto the camera . this on-screen framing provide a natural and effective bridge between modality , promote consistency and lead to more precise joint distribution . we first design a joint autoencoder that learn a shared latent space , together with a lightweight linear transform from the human and camera latents to a framing latent . we then introduce auxiliary sampling , which exploit this linear transform to steer generation toward a coherent frame modality . to support this task , we also introduce the pulpmotion dataset , a human-motion and camera-trajectory dataset with rich caption , and high-quality human motion . extensive experiment across dit- and mar-based architecture show the generality and effectiveness of our method in generate on-frame coherent human-camera motion , while also achieve gain on textual alignment for both modality . our qualitative result yield more cinematographically meaningful framing set the new state of the art for this task . code , model and data be available in our \href { http : //www.lix.polytechnique.fr/vista/projects/2025_pulpmotion_courant/ } { project page } .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05096	paper2video : automatic video generation from scientific paper	Zeyu Zhu, Kevin Qinghong Lin, Mike Zheng Shou	academic presentation video have become an essential medium for research communication , yet produce them remain highly labor-intensive , often require hour of slide design , recording , and edit for a short 2 to 10 minute video . unlike natural video , presentation video generation involve distinctive challenge : input from research paper , dense multi-modal information ( text , figure , table ) , and the need to coordinate multiple align channel such a slide , subtitle , speech , and human talker . to address these challenge , we introduce papertalker , the first benchmark of 101 research paper pair with author-created presentation video , slide , and speaker metadata . we further design four tailored evaluation metric -- meta similarity , presentarena , presentquiz , and ip memory -- to measure how videos convey the paper 's information to the audience . building on this foundation , we propose papertalker , the first multi-agent framework for academic presentation video generation . it integrate slide generation with effective layout refinement by a novel effective tree search visual choice , cursor grounding , subtitle , speech synthesis , and talking-head rendering , while parallelize slide-wise generation for efficiency . experiment on paper2video demonstrate that the presentation video produce by our approach be more faithful and informative than exist baseline , establish a practical step toward automate and ready-to-use academic video generation . our dataset , agent , and code be available at http : //github.com/showlab/paper2video .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05094	vchain : chain-of-visual-thought for reason in video generation	Ziqi Huang, Ning Yu, Gordon Chen, Haonan Qiu, Paul Debevec, Ziwei Liu	recent video generation model can produce smooth and visually appeal clip , but they often struggle to synthesize complex dynamic with a coherent chain of consequence . accurately model visual outcome and state transition over time remain a core challenge . in contrast , large language and multimodal model ( e.g. , gpt-4o ) exhibit strong visual state reasoning and future prediction capability . to bridge these strength , we introduce vchain , a novel inference-time chain-of-visual-thought framework that inject visual reason signal from multimodal model into video generation . specifically , vchain contain a dedicated pipeline that leverage large multimodal model to generate a sparse set of critical keyframes a snapshot , which be then use to guide the sparse inference-time tuning of a pre-trained video generator only at these key moment . our approach be tuning-efficient , introduces minimal overhead and avoids dense supervision . extensive experiment on complex , multi-step scenario show that vchain significantly enhance the quality of generated video .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05093	character mix for video generation	Tingting Liao, Chongjian Ge, Guangyi Liu, Hao Li, Yi Zhou	imagine mr. bean step into tom and jerry -- can we generate video where character interact naturally across different world ? we study inter-character interaction in text-to-video generation , where the key challenge be to preserve each character 's identity and behavior while enable coherent cross-context interaction . this be difficult because character may never have coexist and because mix style often cause style delusion , where realistic character appear cartoonish or vice versa . we introduce a framework that tackle these issue with cross-character embedding ( cce ) , which learn identity and behavioral logic across multimodal source , and cross-character augmentation ( cca ) , which enrich train with synthetic co-existence and mixed-style data . together , these technique allow natural interaction between previously uncoexistent character without lose stylistic fidelity . experiment on a curated benchmark of cartoon and live-action series with 10 character show clear improvement in identity preservation , interaction quality , and robustness to style delusion , enable new form of generative storytelling.additional result and video be available on our project page : http : //tingtingliao.github.io/mimix/ .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05091	factuality matter : when image generation and edit meet structured visuals	Le Zhuo, Songhao Han, Yuandong Pu, Boxiang Qiu, Sayak Paul, Yue Liao, Yihao Liu, Jie Shao, Xi Chen, Si Liu, Hongsheng Li	while modern visual generation model excel at create aesthetically please natural image , they struggle with produce or edit structured visuals like chart , diagram , and mathematical figure , which demand composition planning , text rendering , and multimodal reasoning for factual fidelity . to address this , we present the first comprehensive , systematic investigation of this domain , encompass data construction , model training , and an evaluation benchmark . first , we construct a large-scale dataset of 1.3 million high-quality structured image pair derive from executable draw program and augment with chain-of-thought reason annotation . building on it , we train a unified model that integrate a vlm with flux.1 kontext via a lightweight connector for enhanced multimodal understanding . a three-stage training curriculum enable progressive feature alignment , knowledge infusion , and reasoning-augmented generation , far boost by an external reasoner at inference time . finally , we introduce structbench , a novel benchmark for generation and edit with over 1,700 challenging instance , and an accompany evaluation metric , structscore , which employ a multi-round q\ & a protocol to assess fine-grained factual accuracy . evaluation of 15 model reveal that even lead closed-source system remain far from satisfactory . our model attain strong edit performance , and inference-time reasoning yield consistent gain across diverse architecture . by release the dataset , model , and benchmark , we aim to advance unified multimodal foundation for structured visuals .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05081	saedit : token-level control for continuous image edit via sparse autoencoder	Ronen Kamenetsky, Sara Dorfman, Daniel Garibi, Roni Paiss, Or Patashnik, Daniel Cohen-Or	large-scale text-to-image diffusion model have become the backbone of modern image editing , yet text prompt alone do not offer adequate control over the editing process . two property be especially desirable : disentanglement , where change one attribute do not unintentionally alter others , and continuous control , where the strength of an edit can be smoothly adjust . we introduce a method for disentangle and continuous edit through token-level manipulation of text embeddings . the edits be apply by manipulate the embeddings along carefully choose direction , which control the strength of the target attribute . to identify such direction , we employ a sparse autoencoder ( sae ) , whose sparse latent space expose semantically isolated dimension . our method operate directly on text embeddings without modify the diffusion process , make it model agnostic and broadly applicable to various image synthesis backbone . experiment show that it enable intuitive and efficient manipulation with continuous control across diverse attribute and domain .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05071	neuroplastic modular framework : cross-domain image classification of garbage and industrial surface	Debojyoti Ghosh, Soumya K Ghosh, Adrijit Goswami	efficient and accurate classification of waste and industrial surface defect be essential for ensure sustainable waste management and maintain high standard in quality control . this paper introduce the neuroplastic modular classifier , a novel hybrid architecture design for robust and adaptive image classification in dynamic environment . the model combine a resnet-50 backbone for localized feature extraction with a vision transformer ( vit ) to capture global semantic context . additionally , faiss-based similarity retrieval be incorporate to provide a memory-like reference to previously encounter data , enrich the model 's feature space . a key innovation of our architecture be the neuroplastic modular design compose of expandable , learnable block that dynamically grow during training when performance plateau . inspire by biological learn system , this mechanism allow the model to adapt to data complexity over time , improve generalization . beyond garbage classification , we validate the model on the kolektor surface defect dataset 2 ( kolektorsdd2 ) , which involve industrial defect detection on metal surface . experimental result across domain show that the propose architecture outperform traditional static model in both accuracy and adaptability . the neuroplastic modular classifier offer a scalable , high-performance solution for real-world image classification , with strong applicability in both environmental and industrial domain .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05057	stamo : unsupervised learning of generalizable robot motion from compact state representation	Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen, Chunhua Shen	a fundamental challenge in embodied intelligence be develop expressive and compact state representation for efficient world modeling and decision making . however , exist method often fail to achieve this balance , yield representation that be either overly redundant or lack in task-critical information . we propose an unsupervised approach that learn a highly compress two-token state representation use a lightweight encoder and a pre-trained diffusion transformer ( dit ) decoder , capitalize on it strong generative prior . our representation be efficient , interpretable , and integrate seamlessly into exist vla-based model , improve performance by 14.3 % on libero and 30 % in real-world task success with minimal inference overhead . more importantly , we find that the difference between these token , obtain via latent interpolation , naturally serve a a highly effective latent action , which can be far decode into executable robot action . this emergent capability reveals that our representation capture structure dynamic without explicit supervision . we name our method stamo for it ability to learn generalizable robotic motion from compact state representation , which be encode from static image , challenge the prevalent dependence to learn latent action on complex architecture and video data . the resulting latent action also enhance policy co-training , outperform prior method by 10.4 % with improved interpretability . moreover , our approach scale effectively across diverse data source , include real-world robot data , simulation , and human egocentric video .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05053	no-reference quality assessment of contrast-distorted image use contrast-enhanced pseudo reference	Mohammad-Ali Mahmoudpour, Saeed Mahmoudpour	contrast change be an important factor that affect the quality of image . during image capturing , unfavorable light condition can cause contrast change and visual quality loss . while various method have be propose to assess the quality of image under different distortion such a blur and noise , contrast distortion have be largely overlook a it visual impact and property be different from other conventional type of distortion . in this paper , we propose a no-reference image quality assessment ( nr-iqa ) metric for contrast-distorted image . use a set of contrast enhancement algorithm , we aim to generate pseudo-reference image that be visually close to the actual reference image , such that the nr problem be transform to a full-reference ( fr ) assessment with high accuracy . to this end , a large dataset of contrast-enhanced image be produce to train a classification network that can select the most suitable contrast enhancement algorithm base on image content and distortion for pseudo-reference image generation . finally , the evaluation be perform in the fr manner to assess the quality difference between the contrast-enhanced ( pseudoreference ) and degrade image . performance evaluation of the propose method on three database contain contrast distortion ( ccid2014 , tid2013 , and csiq ) , indicate the promising performance of the propose method .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05051	segmast3r : geometry ground segment matching	Rohit Jayanti, Swayam Agrawal, Vansh Garg, Siddharth Tourani, Muhammad Haris Khan, Sourav Garg, Madhava Krishna	segment matching be an important intermediate task in computer vision that establish correspondence between semantically or geometrically coherent region across image . unlike keypoint matching , which focus on localized feature , segment match capture structure region , offer great robustness to occlusion , light variation , and viewpoint change . in this paper , we leverage the spatial understanding of 3d foundation model to tackle wide-baseline segment matching , a challenge setting involve extreme viewpoint shift . we propose an architecture that use the inductive bias of these 3d foundation model to match segment across image pair with up to 180 degree view-point change . extensive experiment show that our approach outperform state-of-the-art method , include the sam2 video propagator and local feature match method , by upto 30 % on the auprc metric , on scannet++ and replica datasets . we further demonstrate benefit of the propose model on relevant downstream task , include 3d instance segmentation and image-goal navigation . project page : http : //segmast3r.github.io/	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05034	video-lmm post-training : a deep dive into video reason with large multimodal model	Yunlong Tang, Jing Bi, Pinxin Liu, Zhenyu Pan, Zhangyun Tan, Qianxiang Shen, Jiani Liu, Hang Hua, Junjia Guo, Yunzhong Xiao, Chao Huang, Zhiyuan Wang, Susan Liang, Xinyi Liu, Yizhi Song, Yuhe Nie, Jia-Xing Zhong, Bozheng Li, Daiqing Qi, Ziyun Zeng, Ali Vosoughi, Luchuan Song, Zeliang Zhang, Daiki Shimada, Han Liu, Jiebo Luo, Chenliang Xu	video understand represent the most challenging frontier in computer vision , require model to reason about complex spatiotemporal relationship , long-term dependency , and multimodal evidence . the recent emergence of video-large multimodal model ( video-lmms ) , which integrate visual encoders with powerful decoder-based language model , have demonstrate remarkable capability in video understanding task . however , the critical phase that transform these model from basic perception system into sophisticated reason engine , post-training , remain fragmented across the literature . this survey provide the first comprehensive examination of post-training methodology for video-lmms , encompass three fundamental pillar : supervise fine-tuning ( sft ) with chain-of-thought , reinforcement learning ( rl ) from verifiable objective , and test-time scaling ( tt ) through enhance inference computation . we present a structured taxonomy that clarify the role , interconnection , and video-specific adaptation of these technique , address unique challenge such a temporal localization , spatiotemporal grounding , long video efficiency , and multimodal evidence integration . through systematic analysis of representative method , we synthesize key design principle , insight , and evaluation protocol while identify critical open challenge in reward design , scalability , and cost-performance optimization . we further curate essential benchmark , datasets , and metric to facilitate rigorous assessment of post-training effectiveness . this survey aim to provide researcher and practitioner with a unified framework for advance video-lmm capability . additional resource and update be maintain at : http : //github.com/yunlong10/awesome-video-lmm-post-training	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05015	explore the efficacy of modify transfer learn in identify parkinson 's disease through draw image pattern	Nabil Daiyan, Md Rakibul Haque	parkinson 's disease ( pd ) be a progressive neurodegenerative condition characterize by the death of dopaminergic neuron , lead to various movement disorder symptom . early diagnosis of pd be crucial to prevent adverse effect , yet traditional diagnostic method be often cumbersome and costly . in this study , a machine learning-based approach be propose use hand-drawn spiral and wave image a potential biomarkers for pd detection . our methodology leverage convolutional neural network ( cnns ) , transfer learning , and attention mechanism to improve model performance and resilience against overfitting . to enhance the diversity and richness of both spiral and wave category , the training dataset undergoes augmentation to increase the number of image . the proposed architecture comprise three phase : utilizing pre-trained cnns , incorporate custom convolutional layer , and ensemble voting . employ hard voting further enhances performance by aggregate prediction from multiple model . experimental result show promising accuracy rate . for spiral image , weighted average precision , recall , and f1-score be 90 % , and for wave image , they be 96.67 % . after combine the prediction through ensemble hard voting , the overall accuracy be 93.3 % . these finding underscore the potential of machine learning in early pd diagnosis , offer a non-invasive and cost-effective solution to improve patient outcome .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.05006	latent uncertainty representation for video-based driver action and intention recognition	Koen Vellenga, H. Joe Steinhauer, Jonas Andersson, Anders Sjögren	deep neural network ( dnns ) be increasingly apply to safety-critical task in resource-constrained environment , such a video-based driver action and intention recognition . while last layer probabilistic deep learning ( ll-pdl ) method can detect out-of-distribution ( ood ) instance , their performance varies . a an alternative to last layer approach , we propose extend pre-trained dnns with transformation layer to produce multiple latent representation to estimate the uncertainty . we evaluate our latent uncertainty representation ( lur ) and repulsively trained lur ( rlur ) approach against eight pdl method across four video-based driver action and intention recognition datasets , compare classification performance , calibration , and uncertainty-based ood detection . we also contribute 28,000 frame-level action label and 1,194 video-level intention label for the nuscenes dataset . our result show that lur and rlur achieve comparable in-distribution classification performance to other ll-pdl approach . for uncertainty-based ood detection , lur match top-performing pdl method while be more efficient to train and easy to tune than approach that require markov-chain monte carlo sample or repulsive training procedure .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04999	bridge text and video generation : a survey	Nilay Kumar, Priyansh Bhandari, G. Maragatham	text-to-video ( t2v ) generation technology hold potential to transform multiple domain such a education , marketing , entertainment , and assistive technology for individual with visual or read comprehension challenge , by create coherent visual content from natural language prompt . from it inception , the field have advance from adversarial model to diffusion-based model , yield higher-fidelity , temporally consistent output . yet challenge persist , such a alignment , long-range coherence , and computational efficiency . address this evolve landscape , we present a comprehensive survey of text-to-video generative model , trace their development from early gans and vaes to hybrid diffusion-transformer ( dit ) architectures , detail how these model work , what limitations they address in their predecessor , and why shift toward new architectural paradigm be necessary to overcome challenge in quality , coherence , and control . we provide a systematic account of the datasets , which the survey text-to-video model be train and evaluate on , and , to support reproducibility and assess the accessibility of training such model , we detail their training configuration , include their hardware specification , gpu count , batch size , learn rate , optimizers , epoch , and other key hyperparameters . far , we outline the evaluation metric commonly use for evaluate such model and present their performance across standard benchmark , while also discuss the limitation of these metric and the emerge shift toward more holistic , perception-aligned evaluation strategy . finally , draw from our analysis , we outline the current open challenge and propose a few promising future direction , lay out a perspective for future researcher to explore and build upon in advance t2v research and application .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04966	activemark : on watermarking of visual foundation model via massive activation	Anna Chistyakova, Mikhail Pautov	be train on large and vast datasets , visual foundation model ( vfms ) can be fine-tuned for diverse downstream task , achieve remarkable performance and efficiency in various computer vision application . the high computation cost of data collection and training motivate the owner of some vfms to distribute them alongside the license to protect their intellectual property right . however , a dishonest user of the protected model 's copy may illegally redistribute it , for example , to make a profit . a a consequence , the development of reliable ownership verification tool be of great importance today , since such method can be use to differentiate between a redistributed copy of the protected model and an independent model . in this paper , we propose an approach to ownership verification of visual foundation model by fine-tune a small set of expressive layer of a vfm along with a small encoder-decoder network to embed digital watermark into an internal representation of a hold-out set of input image . importantly , the watermark embed remain detectable in the functional copy of the protected model , obtain , for example , by fine-tune the vfm for a particular downstream task . theoretically and experimentally , we demonstrate that the propose method yield a low probability of false detection of a non-watermarked model and a low probability of false misdetection of a watermarked model .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04961	ssdd : single-step diffusion decoder for efficient image tokenization	Théophane Vallaeys, Jakob Verbeek, Matthieu Cord	tokenizers be a key component of state-of-the-art generative image model , extract the most important feature from the signal while reduce data dimension and redundancy . most current tokenizers be base on kl-regularized variational autoencoders ( kl-vae ) , train with reconstruction , perceptual and adversarial loss . diffusion decoder have be propose a a more principled alternative to model the distribution over image condition on the latent . however , match the performance of kl-vae still require adversarial loss , as well a a high decoding time due to iterative sampling . to address these limitation , we introduce a new pixel diffusion decoder architecture for improved scaling and training stability , benefit from transformer component and gan-free training . we use distillation to replicate the performance of the diffusion decoder in an efficient single-step decoder . this make ssdd the first diffusion decoder optimize for single-step reconstruction train without adversarial loss , reach high reconstruction quality and faster sample than kl-vae . in particular , ssdd improves reconstruction fid from $ 0.87 $ to $ 0.50 $ with $ 1.4\times $ high throughput and preserve generation quality of dit with $ 3.8\times $ faster sample . a such , ssdd can be use a a drop-in replacement for kl-vae , and for build higher-quality and faster generative model .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04947	bidirectional mammogram view translation with column-aware and implicit 3d conditional diffusion	Xin Li, Kaixiang Yang, Qiang Li, Zhiwei Wang	dual-view mammography , include craniocaudal ( cc ) and mediolateral oblique ( mlo ) projection , offer complementary anatomical view crucial for breast cancer diagnosis . however , in real-world clinical workflow , one view may be miss , corrupt , or degrade due to acquisition error or compression artifact , limit the effectiveness of downstream analysis . view-to-view translation can help recover miss view and improve lesion alignment . unlike natural image , this task in mammography be highly challenge due to large non-rigid deformation and severe tissue overlap in x-ray projection , which obscure pixel-level correspondence . in this paper , we propose column-aware and implicit 3d diffusion ( ca3d-diff ) , a novel bidirectional mammogram view translation framework base on conditional diffusion model . to address cross-view structural misalignment , we first design a column-aware cross-attention mechanism that leverage the geometric property that anatomically correspond region tend to lie in similar column position across view . a gaussian-decayed bias be apply to emphasize local column-wise correlation while suppress distant mismatch . furthermore , we introduce an implicit 3d structure reconstruction module that back-projects noisy 2d latents into a coarse 3d feature volume base on breast-view projection geometry . the reconstructed 3d structure be refine and inject into the denoising unet to guide cross-view generation with enhanced anatomical awareness . extensive experiment demonstrate that ca3d-diff achieves superior performance in bidirectional task , outperform state-of-the-art method in visual fidelity and structural consistency . furthermore , the synthesized view effectively improve single-view malignancy classification in screen setting , demonstrate the practical value of our method in real-world diagnostics .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04944	on structure state-space duality	Jerry Yao-Chieh Hu, Xiwen Zhang, Weimin Wu, Han Liu	structure state-space duality ( ssd ) [ dao & gu , icml 2024 ] be an equivalence between a simple structured state-space model ( ssm ) and a masked attention mechanism . in particular , a state-space model with a scalar-times-identity state matrix be equivalent to a mask self-attention with a $ 1 $ -semiseparable causal mask . consequently , the same sequence transformation ( model ) have two algorithmic realization : a a linear-time $ o ( t ) $ recurrence or a a quadratic-time $ o ( t^2 ) $ attention . in this note , we formalize and generalize this duality : ( i ) we extend ssd from the scalar-identity case to general diagonal ssms ( diagonal state matrix ) ; ( ii ) we show that these diagonal ssms match the scalar case 's training complexity low bound while support rich dynamic ; ( iii ) we establish a necessary and sufficient condition under which an ssm be equivalent to $ 1 $ -semiseparable mask attention ; and ( iv ) we show that such duality fails to extend to standard softmax attention due to rank explosion . together , these result tighten bridge between recurrent ssms and transformer , and widen the design space for expressive yet efficient sequence model .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04939	unsupervised active learning via natural feature progressive framework	Yuxi Liu, Catherine Lalman, Yimin Yang	the effectiveness of modern deep learning model be predicate on the availability of large-scale , human-annotated datasets , a process that be notoriously expensive and time-consuming . while active learning ( al ) offer a strategic solution by label only the most informative and representative data , it iterative nature still necessitate significant human involvement . unsupervised active learning ( ual ) present an alternative by shift the annotation burden to a single , post-selection step . unfortunately , prevail ual method struggle to achieve state-of-the-art performance . these approach typically rely on local , gradient-based scoring for sample importance estimation , which not only make them vulnerable to ambiguous and noisy data but also hinders their capacity to select sample that adequately represent the full data distribution . moreover , their use of shallow , one-shot linear selection fall short of a true ual paradigm . in this paper , we propose the natural feature progressive framework ( nfpf ) , a ual method that revolutionize how sample importance be measure . at it core , nfpf employ a specific feature learning machine ( sflm ) to effectively quantify each sample 's contribution to model performance . we further utilize the sflm to define a powerful reconstruction difference metric for initial sample selection . our comprehensive experiment show that nfpf significantly outperform all establish ual method and achieves performance on par with supervised al method on vision datasets . detailed ablation study and qualitative visualization provide compel evidence for nfpf 's superior performance , enhance robustness , and improve data distribution coverage .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04923	ren : anatomically-informed mixture-of-experts for interstitial lung disease diagnosis	Alec K. Peltekian, Halil Ertugrul Aktas, Gorkem Durak, Kevin Grudzinski, Bradford C. Bemiss, Carrie Richardson, Jane E. Dematte, G. R. Scott Budinger, Anthony J. Esposito, Alexander Misharin, Alok Choudhary, Ankit Agrawal, Ulas Bagci	mixture-of-experts ( moe ) architecture have significantly contribute to scalable machine learning by enable specialized subnetworks to tackle complex task efficiently . however , traditional moe system lack domain-specific constraint essential for medical imaging , where anatomical structure and regional disease heterogeneity strongly influence pathological pattern . here , we introduce regional expert network ( ren ) , the first anatomically-informed moe framework tailor specifically for medical image classification . ren leverage anatomical prior to train seven specialized expert , each dedicate to distinct lung lobe and bilateral lung combination , enable precise modeling of region-specific pathological variation . multi-modal gate mechanism dynamically integrate radiomics biomarkers and deep learning ( dl ) feature ( cnn , vit , mamba ) to weight expert contribution optimally . apply to interstitial lung disease ( ild ) classification , ren achieve consistently superior performance : the radiomics-guided ensemble reach an average auc of 0.8646 +/- 0.0467 , a +12.5 percent improvement over the swinunetr baseline ( auc 0.7685 , p = 0.031 ) . region-specific expert far reveal that lower-lobe model achieve auc of 0.88-0.90 , surpass dl counterpart ( cnn : 0.76-0.79 ) and align with known disease progression pattern . through rigorous patient-level cross-validation , ren demonstrate strong generalizability and clinical interpretability , present a scalable , anatomically-guided approach readily extensible to other structured medical imaging application .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04916	a semantics-aware hierarchical self-supervised approach to classification of remote sensing image	Giulio Weikmann, Gianmarco Perantoni, Lorenzo Bruzzone	deep learning have become increasingly important in remote sense image classification due to it ability to extract semantic information from complex data . classification task often include predefined label hierarchy that represent the semantic relationship among class . however , these hierarchy be frequently overlook , and most approach focus only on fine-grained classification scheme . in this paper , we present a novel semantics-aware hierarchical consensus ( sahc ) method for learn hierarchical feature and relationship by integrate hierarchy-specific classification head within a deep network architecture , each specialize in different degree of class granularity . the proposed approach employ trainable hierarchy matrix , which guide the network through the learning of the hierarchical structure in a self-supervised manner . furthermore , we introduce a hierarchical consensus mechanism to ensure consistent probability distribution across different hierarchical level . this mechanism act a a weighted ensemble be able to effectively leverage the inherent structure of the hierarchical classification task . the propose sahc method be evaluate on three benchmark datasets with different degree of hierarchical complexity on different task , use distinct backbone architectures to effectively emphasize it adaptability . experimental result show both the effectiveness of the propose approach in guide network learning and the robustness of the hierarchical consensus for remote sense image classification task .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04912	comparative analysis of yolov5 , fast r-cnn , ssd , and retinanet for motorbike detection in kigali autonomous drive context	Ngeyen Yinkfu, Sunday Nwovu, Jonathan Kayizzi, Angelique Uwamahoro	in kigali , rwanda , motorcycle taxi be a primary mode of transportation , often navigate unpredictably and disregard traffic rule , pose significant challenge for autonomous drive system . this study compare four object detection model -- yolov5 , fast r-cnn , ssd , and retinanet -- for motorbike detection use a custom dataset of 198 image collect in kigali . implement in pytorch with transfer learning , the model be evaluate for accuracy , localization , and inference speed to assess their suitability for real-time navigation in resource-constrained setting . we identify implementation challenge , include dataset limitation and model complexity , and recommend simplified architecture for future work to enhance accessibility for autonomous system in develop country like rwanda .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04883	clear-ir : clarity-enhanced active reconstruction of infrared imagery	Nathan Shankar, Pawel Ladosz, Hujun Yin	this paper present a novel approach for enable robust robotic perception in dark environment use infrared ( ir ) stream . ir stream be less susceptible to noise than rgb in low-light condition . however , it be dominate by active emitter pattern that hinder high-level task such a object detection , track and localisation . to address this , a u-net-based architecture be propose that reconstruct clean ir image from emitter-populated input , improve both image quality and downstream robotic performance . this approach outperform exist enhancement technique and enables reliable operation of vision-driven robotic system across illumination condition from well-lit to extreme low-light scene .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04876	benthicat : an opti-acoustic dataset for advance benthic classification and habitat mapping	Hayat Rajani, Valerio Franchi, Borja Martinez-Clavel Valles, Raimon Ramos, Rafael Garcia, Nuno Gracias	benthic habitat mapping be fundamental for understand marine ecosystem , guide conservation effort , and support sustainable resource management . yet , the scarcity of large , annotated datasets limit the development and benchmarking of machine learning model in this domain . this paper introduce a thorough multi-modal dataset , comprise about a million side-scan sonar ( ss ) tile collect along the coast of catalonia ( spain ) , complement by bathymetric map and a set of co-registered optical image from target survey use an autonomous underwater vehicle ( auv ) . approximately \num { 36000 } of the ss tile have be manually annotate with segmentation mask to enable supervised fine-tuning of classification model . all the raw sensor data , together with mosaic , be also release to support further exploration and algorithm development . to address challenge in multi-sensor data fusion for auvs , we spatially associate optical image with correspond ss tile , facilitate self-supervised , cross-modal representation learning . accompany open-source preprocessing and annotation tool be provide to enhance accessibility and encourage research . this resource aim to establish a standardized benchmark for underwater habitat mapping , promote advancement in autonomous seafloor classification and multi-sensor integration .	Computer Vision and Pattern Recognition	06/10/2025
10.1109/JIOT.2025.3617805	in-field mapping of grape yield and quality with illumination-invariant deep learning	Ciem Cornelissen, Sander De Coninck, Axel Willekens, Sam Leroux, Pieter Simoens	this paper present an end-to-end , iot-enabled robotic system for the non-destructive , real-time , and spatially-resolved mapping of grape yield and quality ( brix , acidity ) in vineyard . the system feature a comprehensive analytical pipeline that integrate two key module : a high-performance model for grape bunch detection and weight estimation , and a novel deep learning framework for quality assessment from hyperspectral ( hsi ) data . a critical barrier to in-field hsi be the `` domain shift '' cause by variable illumination . to overcome this , our quality assessment be power by the light-invariant spectral autoencoder ( lisa ) , a domain-adversarial framework that learn illumination-invariant feature from uncalibrated data . we validate the system 's robustness on a purpose-built hsi dataset span three distinct illumination domain : control artificial lighting ( lab ) , and variable natural sunlight capture in the morning and afternoon . result show the complete pipeline achieve a recall ( 0.82 ) for bunch detection and a $ r^2 $ ( 0.76 ) for weight prediction , while the lisa module improve quality prediction generalization by over 20 % compare to the baseline . by combine these robust module , the system successfully generate high-resolution , georeferenced data of both grape yield and quality , provide actionable , data-driven insight for precision viticulture .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04859	μdeepiqa : deep learning-based fast and robust image quality assessment with local prediction for optical microscopy	Elena Corbetta, Thomas Bocklitz	optical microscopy be one of the most widely use technique in research study for life science and biomedicine . these application require reliable experimental pipeline to extract valuable knowledge from the measure sample and must be support by image quality assessment ( iqa ) to ensure correct processing and analysis of the image data . iqa method be implement with variable complexity . however , while most quality metric have a straightforward implementation , they might be time consume and computationally expensive when evaluate a large dataset . in addition , quality metric be often design for well-defined image feature and may be unstable for image out of the ideal domain . to overcome these limitation , recent work have propose deep learning-based iqa method , which can provide superior performance , increase generalizability and fast prediction . our method , name $ \mathrm { \mu } $ deepiqa , be inspire by previous study and apply a deep convolutional neural network design for iqa on natural image to optical microscopy measurement . we retrain the same architecture to predict individual quality metric and global quality score for optical microscopy data . the resulting model provide fast and stable prediction of image quality by generalize quality estimation even outside the ideal range of standard method . in addition , $ \mathrm { \mu } $ deepiqa provide patch-wise prediction of image quality and can be use to visualize spatially vary quality in a single image . our study demonstrate that optical microscopy-based study can benefit from the generalizability of deep learning model due to their stable performance in the presence of outlier , the ability to assess small image patch , and rapid prediction .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04856	erde : entropy-regularized distillation for early-exit	Martial Guidez, Stefan Duffner, Yannick Alpou, Oscar Röth, Christophe Garcia	although deep neural network and in particular convolutional neural network have demonstrate state-of-the-art performance in image classification with relatively high efficiency , they still exhibit high computational cost , often render them impractical for real-time and edge application . therefore , a multitude of compression technique have be develop to reduce these cost while maintain accuracy . in addition , dynamic architecture have be introduce to modulate the level of compression at execution time , which be a desirable property in many resource-limited application scenario . the propose method effectively integrate two well-established optimization technique : early exit and knowledge distillation , where a reduced student early-exit model be train from a more complex teacher early-exit model . the primary contribution of this research lie in the approach for train the student early-exit model . in comparison to the conventional knowledge distillation loss , our approach incorporate a new entropy-based loss for image where the teacher 's classification be incorrect . the propose method optimize the trade-off between accuracy and efficiency , thereby achieve significant reduction in computational complexity without compromise classification performance . the validity of this approach be substantiate by experimental result on image classification datasets cifar10 , cifar100 and svhn , which far open new research perspective for knowledge distillation in other context .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04854	read the room : inferring social context through dyadic interaction recognition in cyber-physical-social infrastructure system	Cheyu Lin, John Martins, Katherine A. Flanigan, Ph. D	cyber-physical system ( cps ) integrate sensing , compute , and control to improve infrastructure performance , focus on economic goal like performance and safety . however , they often neglect potential human-centered ( or `` social '' ) benefit . cyber-physical-social infrastructure system ( cpsis ) aim to address this by align cps with social objective . this involve define social benefit , understand human interaction with each other and infrastructure , develop privacy-preserving measurement method , model these interaction for prediction , link them to social benefit , and actuate the physical environment to foster positive social outcome . this paper delve into recognize dyadic human interaction use real-world data , which be the backbone to measure social behavior . this lay a foundation to address the need to enhance understanding of the deep meaning and mutual response inherent in human interaction . while rgb camera be informative for interaction recognition , privacy concern arise . depth sensor offer a privacy-conscious alternative by analyze skeletal movement . this study compare five skeleton-based interaction recognition algorithm on a dataset of 12 dyadic interaction . unlike single-person datasets , these interaction , categorize into communication type like emblem and affect display , offer insight into the cultural and emotional aspect of human interaction .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04844	from action to kinesics : extract human psychological state through bodily movement	Cheyu Lin, Katherine A. Flanigan	understand the dynamic relationship between human and the build environment be a key challenge in discipline range from environmental psychology to reinforcement learning ( rl ) . a central obstacle in model these interaction be the inability to capture human psychological state in a way that be both generalizable and privacy preserving . traditional method rely on theoretical model or questionnaire , which be limit in scope , static , and labor intensive . we present a kinesics recognition framework that infer the communicative function of human activity -- know a kinesics -- directly from 3d skeleton joint data . combine a spatial-temporal graph convolutional network ( st-gcn ) with a convolutional neural network ( cnn ) , the framework leverage transfer learn to bypass the need for manually define mapping between physical action and psychological category . the approach preserve user anonymity while uncover latent structure in bodily movement that reflect cognitive and emotional state . our result on the dyadic user engagement ( duet ) dataset demonstrate that this method enable scalable , accurate , and human-centered modeling of behavior , offer a new pathway for enhance rl-driven simulation of human-environment interaction .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04840	detailed aerial mapping of photovoltaic power plant through semantically significant keypoints	Viktor Kozák, Jan Chudoba, Libor Přeučil	an accurate and up-to-date model of a photovoltaic ( pv ) power plant be essential for it optimal operation and maintenance . however , such a model may not be easily available . this work introduce a novel approach for pv power plant mapping base on aerial overview image . it enable the automation of the mapping process while remove the reliance on third-party data . the presented mapping method take advantage of the structural layout of the power plant to achieve detailed model down to the level of individual pv module . the approach rely on visual segmentation of pv module in overview image and the inference of structural information in each image , assign module to individual bench , row , and column . we identify visual keypoints relate to the layout and use these to merge detection from multiple image while maintain their structural integrity . the presented method be experimentally verify and evaluate on two different power plant . the final fusion of 3d position and semantic structure result in a compact georeferenced model suitable for power plant maintenance .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04838	beyond random : automatic inner-loop optimization in dataset distillation	Muquan Li, Hang Gou, Dongyang Zhang, Shuang Liang, Xiurui Xie, Deqiang Ouyang, Ke Qin	the grow demand for efficient deep learning have position dataset distillation a a pivotal technique for compress training dataset while preserve model performance . however , exist inner-loop optimization method for dataset distillation typically rely on random truncation strategy , which lack flexibility and often yield suboptimal result . in this work , we observe that neural network exhibit distinct learn dynamic across different train stages-early , middle , and late-making random truncation ineffective . to address this limitation , we propose automatic truncate backpropagation through time ( at-bptt ) , a novel framework that dynamically adapt both truncation position and window size accord to intrinsic gradient behavior . at-bptt introduces three key component : ( 1 ) a probabilistic mechanism for stage-aware timestep selection , ( 2 ) an adaptive window size strategy base on gradient variation , and ( 3 ) a low-rank hessian approximation to reduce computational overhead . extensive experiment on cifar-10 , cifar-100 , tiny-imagenet , and imagenet-1k show that at-bptt achieves state-of-the-art performance , improve accuracy by an average of 6.16 % over baseline method . moreover , our approach accelerate inner-loop optimization by 3.9x while save 63 % memory cost .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04823	flow match for conditional mri-ct and cbct-ct image synthesis	Arnela Hadzic, Simon Johannes Joham, Martin Urschler	generate synthetic ct ( sct ) from mri or cbct play a crucial role in enable mri-only and cbct-based adaptive radiotherapy , improve treatment precision while reduce patient radiation exposure . to address this task , we adopt a fully 3d flow matching ( fm ) framework , motivate by recent work demonstrate fm 's efficiency in produce high-quality image . in our approach , a gaussian noise volume be transform into an sct image by integrate a learned fm velocity field , condition on feature extract from the input mri or cbct use a lightweight 3d encoder . we evaluate the method on the synthrad2025 challenge benchmark , train separate model for mri $ \rightarrow $ sct and cbct $ \rightarrow $ sct across three anatomical region : abdomen , head and neck , and thorax . validation and test be perform through the challenge submission system . the result indicate that the method accurately reconstruct global anatomical structure ; however , preservation of fine detail be limit , primarily due to the relatively low train resolution impose by memory and runtime constraint . future work will explore patch-based training and latent-space flow model to improve resolution and local structural fidelity .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04822	avatarvton : 4d virtual try-on for animatable avatar	Zicheng Jiang, Jixin Gao, Shengfeng He, Xinzhe Li, Yulong Zheng, Zhaotong Yang, Junyu Dong, Yong Du	we propose avatarvton , the first 4d virtual try-on framework that generate realistic try-on result from a single in-shop garment image , enable free pose control , novel-view rendering , and diverse garment choice . unlike exist method , avatarvton support dynamic garment interaction under single-view supervision , without rely on multi-view garment capture or physic prior . the framework consist of two key module : ( 1 ) a reciprocal flow rectifier , a prior-free optical-flow correction strategy that stabilize avatar fitting and ensure temporal coherence ; and ( 2 ) a non-linear deformer , which decompose gaussian map into view-pose-invariant and view-pose-specific component , enable adaptive , non-linear garment deformation . to establish a benchmark for 4d virtual try-on , we extend exist baseline with unified module for fair qualitative and quantitative comparison . extensive experiment show that avatarvton achieves high fidelity , diversity , and dynamic garment realism , make it well-suited for ar/vr , gaming , and digital-human application .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04819	visual representation inside the language model	Benlin Liu, Amita Kamath, Madeleine Grunde-McLaughlin, Winson Han, Ranjay Krishna	despite interpretability work analyze vit encoders and transformer activation , we do n't yet understand why multimodal language model ( mlms ) struggle on perception-heavy task . we offer an under-studied perspective by examine how popular mlms ( llava-onevision , qwen2.5-vl , and llama-3-llava-next ) process their visual key-value token . we first study the flow of visual information through the language model , find that image value tokens encode sufficient information to perform several perception-heavy task zero-shot : segmentation , semantic correspondence , temporal correspondence , and refer expression detection . we find that while the language model do augment the visual information receive from the projection of input visual encodings-which we reveal correlate with overall mlm perception capability-it contain less visual information on several task than the equivalent visual encoder ( siglip ) that have not undergone mlm finetuning . far , we find that the visual information correspond to input-agnostic image key token in late layer of language model contain artifact which reduce perception capability of the overall mlm . next , we discuss control visual information in the language model , show that add a text prefix to the image input improve perception capability of visual representation . finally , we reveal that if language model be able to well control their visual information , their perception would significantly improve ; e.g. , in 33.3 % of art style question in the blink benchmark , perception information present in the language model be not surface to the output ! our finding reveal insight into the role of key-value token in multimodal system , pave the way for deep mechanistic interpretability of mlms and suggest new direction for train their visual encoder and language model component .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04802	do you just see that ? arbitrary view synthesis for egocentric replay of operating room workflows from ambient sensor	Han Zhang, Lalithkumar Seenivasan, Jose L. Porras, Roger D. Soberanis-Mukul, Hao Ding, Hongchao Shu, Benjamin D. Killeen, Ankita Ghosh, Lonny Yarmus, Masaru Ishii, Angela Christine Argento, Mathias Unberath	observe surgical practice have historically rely on fixed vantage point or recollection , leave the egocentric visual perspective that guide clinical decision undocumented . fixed-camera video can capture surgical workflow at the room-scale , but can not reconstruct what each team member actually saw . thus , these video only provide limited insight into how decision that affect surgical safety , training , and workflow optimization be make . here we introduce egosurg , the first framework to reconstruct the dynamic , egocentric replay for any operating room ( or ) staff directly from wall-mounted fixed-camera video , and thus , without intervention to clinical workflow . egosurg couple geometry-driven neural render with diffusion-based view enhancement , enable high-visual fidelity synthesis of arbitrary and egocentric viewpoint at any moment . in evaluation across multi-site surgical case and controlled study , egosurg reconstructs person-specific visual field and arbitrary viewpoint with high visual quality and fidelity . by transform exist or camera infrastructure into a navigable dynamic 3d record , egosurg establish a new foundation for immersive surgical data science , enable surgical practice to be visualize , experience , and analyze from every angle .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04794	a comparative study of vision transformer and cnns for few-shot rigid transformation and fundamental matrix estimation	Alon Kaya, Igal Bilik, Inna Stainvas	vision-transformers ( vits ) and large-scale convolution-neural-networks ( cnns ) have reshape computer vision through pretrained feature representation that enable strong transfer learning for diverse task . however , their efficiency a backbone architecture for geometric estimation task involve image deformation in low-data regime remain an open question . this work consider two such task : 1 ) estimate 2d rigid transformation between pair of image and 2 ) predict the fundamental matrix for stereo image pair , an important problem in various application , such a autonomous mobility , robotics , and 3d scene reconstruction . address this intriguing question , this work systematically compare large-scale cnns ( resnet , efficientnet , clip-resnet ) with vit-based foundation model ( clip-vit variant and dino ) in various data size setting , include few-shot scenario . these pretrained model be optimize for classification or contrastive learning , encourage them to focus mostly on high-level semantics . the consider task require balance local and global feature differently , challenge the straightforward adoption of these model a the backbone . empirical comparative analysis show that , similar to train from scratch , vits outperform cnns during refinement in large downstream-data scenario . however , in small data scenario , the inductive bias and small capacity of cnns improve their performance , allow them to match that of a vit . moreover , vits exhibit strong generalization in cross-domain evaluation where the data distribution change . these result emphasize the importance of carefully select model architecture for refinement , motivate future research towards hybrid architecture that balance local and global representation .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04781	hands-free heritage : automate 3d scan for cultural heritage digitization	Javed Ahmad, Federico Dassiè, Selene Frascella, Gabriele Marchello, Ferdinando Cannella, Arianna Traviglia	high-fidelity 3d scanning be essential for preserve cultural heritage artefact , support documentation , analysis , and long-term conservation . however , conventional method typically require specialized expertise and manual intervention to maintain optimal scan condition and coverage . we present an automated two-robot scanning system that eliminate the need for handheld or semi-automatic workflow by combine coordinate robotic manipulation with high-resolution 3d scanning . our system parameterizes the scan space into distinct region , enable coordinate motion planning between a scanner-equipped robot and a tray-handling robot . optimized trajectory planning and waypoint distribution ensure comprehensive surface coverage , minimize occlusion , and balance reconstruction accuracy with system efficiency . experimental result show that our approach achieve significantly low chamfer distance and high f-score compare to baseline method , offer superior geometric accuracy , improve digitization efficiency , and reduced reliance on expert operator .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04772	federate learn for surgical vision in appendicitis classification : result of the fedsurg endovis 2024 challenge	Max Kirchner, Hanna Hoffmann, Alexander C. Jenke, Oliver L. Saldanha, Kevin Pfeiffer, Weam Kanjo, Julia Alekseenko, Claas de Boer, Santhi Raj Kolamuri, Lorenzo Mazza, Nicolas Padoy, Sophia Bano, Annika Reinke, Lena Maier-Hein, Danail Stoyanov, Jakob N. Kather, Fiona R. Kolbinger, Sebastian Bodenstedt, Stefanie Speidel	purpose : the fedsurg challenge be design to benchmark the state of the art in federated learning for surgical video classification . it goal be to assess how well current method generalize to unseen clinical center and adapt through local fine-tuning while enable collaborative model development without share patient data . method : participant develop strategy to classify inflammation stage in appendicitis use a preliminary version of the multi-center appendix300 video dataset . the challenge evaluate two task : generalization to an unseen center and center-specific adaptation after fine-tuning . submit approach include foundation model with linear probing , metric learn with triplet loss , and various fl aggregation scheme ( fedavg , fedmedian , fedsam ) . performance be assess use f1-score and expect cost , with rank robustness evaluate via bootstrapping and statistical testing . result : in the generalization task , performance across center be limit . in the adaptation task , all team improve after fine-tuning , though ranking stability be low . the vivit-based submission achieve the strong overall performance . the challenge highlight limitation in generalization , sensitivity to class imbalance , and difficulty in hyperparameter tuning in decentralized training , while spatiotemporal modeling and context-aware preprocessing emerge a promising strategy . conclusion : the fedsurg challenge establish the first benchmark for evaluate fl strategy in surgical video classification . finding highlight the trade-off between local personalization and global robustness , and underscore the importance of architecture choice , preprocessing , and loss design . this benchmarking offer a reference point for future development of imbalance-aware , adaptive , and robust fl method in clinical surgical ai .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04770	beyond the see : bound distribution estimation for open-vocabulary learning	Xiaomeng Fan, Yuchuan Mao, Zhi Gao, Yuwei Wu, Jin Chen, Yunde Jia	open-vocabulary learning require model the data distribution in open environment , which consist of both seen-class and unseen-class data . exist method estimate the distribution in open environment use seen-class data , where the absence of unseen class make the estimation error inherently unidentifiable . intuitively , learn beyond the see class be crucial for distribution estimation to bind the estimation error . we theoretically demonstrate that the distribution can be effectively estimate by generate unseen-class data , through which the estimation error be upper-bounded . building on this theoretical insight , we propose a novel open-vocabulary learning method , which generate unseen-class data for estimate the distribution in open environment . the method consist of a class-domain-wise data generation pipeline and a distribution alignment algorithm . the data generation pipeline generate unseen-class data under the guidance of a hierarchical semantic tree and domain information infer from the seen-class data , facilitate accurate distribution estimation . with the generate data , the distribution alignment algorithm estimate and maximize the posterior probability to enhance generalization in open-vocabulary learning . extensive experiment on $ 11 $ datasets demonstrate that our method outperform baseline approach by up to $ 14\ % $ , highlight it effectiveness and superiority .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04759	progressive gaussian transformer with anisotropy-aware sampling for open vocabulary occupancy prediction	Chi Yan, Dan Xu	the 3d occupancy prediction task have witness remarkable progress in recent year , play a crucial role in vision-based autonomous drive system . while traditional method be limit to fix semantic category , recent approach have move towards predict text-aligned feature to enable open-vocabulary text query in real-world scene . however , there exist a trade-off in text-aligned scene modeling : sparse gaussian representation struggle to capture small object in the scene , while dense representation incurs significant computational overhead . to address these limitation , we present pg-occ , an innovative progressive gaussian transformer framework that enable open-vocabulary 3d occupancy prediction . our framework employ progressive online densification , a feed-forward strategy that gradually enhance the 3d gaussian representation to capture fine-grained scene detail . by iteratively enhance the representation , the framework achieve increasingly precise and detailed scene understanding . another key contribution be the introduction of an anisotropy-aware sampling strategy with spatio-temporal fusion , which adaptively assign receptive field to gaussians at different scale and stage , enable more effective feature aggregation and rich scene information capture . through extensive evaluation , we demonstrate that pg-occ achieves state-of-the-art performance with a relative 14.3 % miou improvement over the previous best perform method . code and pretrained model will be release upon publication on our project page : http : //yanchi-3dv.github.io/pg-occ	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04753	beyond appearance : transformer-based person identification from conversational dynamic	Masoumeh Chapariniya, Teodora Vukovic, Sarah Ebling, Volker Dellwo	this paper investigate the performance of transformer-based architecture for person identification in natural , face-to-face conversation scenario . we implement and evaluate a two-stream framework that separately model spatial configuration and temporal motion pattern of 133 coco wholebody keypoints , extract from a subset of the candor conversational corpus . our experiment compare pre-trained and from-scratch training , investigate the use of velocity feature , and introduce a multi-scale temporal transformer for hierarchical motion modeling . result demonstrate that domain-specific training significantly outperform transfer learning , and that spatial configuration carry more discriminative information than temporal dynamic . the spatial transformer achieve 95.74 % accuracy , while the multi-scale temporal transformer achieve 93.90 % . feature-level fusion push performance to 98.03 % , confirm that postural and dynamic information be complementary . these finding highlight the potential of transformer architecture for person identification in natural interaction and provide insight for future multimodal and cross-cultural study .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04741	anomaly-aware yolo : a frugal yet robust approach to infrared small target detection	Alina Ciocarlan, Sylvie Le Hégarat-Mascle, Sidonie Lefebvre	infrared small target detection ( irstd ) be a challenge task in defense application , where complex background and tiny target size often result in numerous false alarm use conventional object detector . to overcome this limitation , we propose anomaly-aware yolo ( aa-yolo ) , which integrate a statistical anomaly detection test into it detection head . by treat small target a unexpected pattern against the background , aa-yolo effectively control the false alarm rate . our approach not only achieve competitive performance on several irstd benchmark , but also demonstrate remarkable robustness in scenario with limited training data , noise , and domain shift . furthermore , since only the detection head be modify , our design be highly generic and have be successfully apply across various yolo backbone , include lightweight model . it also provide promising result when integrate into an instance segmentation yolo . this versatility make aa-yolo an attractive solution for real-world deployment where resource be constrain . the code will be publicly release .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04739	exposureengine : orient logo detection and sponsor visibility analytics in sport broadcast	Mehdi Houshmand Sarkhoosh, Frøy Øye, Henrik Nestor Sørlie, Nam Hoang Vu, Dag Johansen, Cise Midoglu, Tomas Kupka, Pål Halvorsen	quantify sponsor visibility in sport broadcast be a critical marketing task traditionally hinder by manual , subjective , and unscalable analysis method . while automated system offer an alternative , their reliance on axis-aligned horizontal bounding box ( hbb ) lead to inaccurate exposuremetrics when logos appear rotate or skew due to dynamic camera angle and perspective distortion . this paper introduce exposureengine , an end-to-end system design for accurate , rotation-aware sponsor visibility analytics in sport broadcast , demonstrate in a soccer case study . our approach predict orient bound box ( obb ) to provide a geometrically precise fit to each logo regardless of the orientation on-screen . to train and evaluate our detector , we develop a new dataset comprise 1,103 frame from swedish elite soccer , feature 670 unique sponsor logo annotate with obbs . our model achieve a mean average precision ( map @ 0.5 ) of 0.859 , with a precision of 0.96 and recall of 0.87 , demonstrate robust performance in localize logos under diverse broadcast condition . the system integrate these detection into an analytical pipeline that calculate precise visibility metric , such a exposure duration and on-screen coverage . furthermore , we incorporate a language-driven agentic layer , enable user to generate report , summary , and medium content through natural language query . the complete system , include the dataset and the analytics dashboard , provide a comprehensive solution for auditable and interpretable sponsor measurement in sport medium . an overview of the exposureengine be available online : http : //youtu.be/trw6obisuw4 .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04723	benchmark on monocular metric depth estimation in wildlife setting	Niccolò Niccoli, Lorenzo Seidenari, Ilaria Greco, Francesco Rovero	camera trap be widely use for wildlife monitoring , but extract accurate distance measurement from monocular image remain challenge due to the lack of depth information . while monocular depth estimation ( mde ) method have advance significantly , their performance in natural wildlife environment have not be systematically evaluate . this work introduce the first benchmark for monocular metric depth estimation in wildlife monitoring condition . we evaluate four state-of-the-art mde method ( depth anything v2 , ml depth pro , zoedepth , and metric3d ) alongside a geometric baseline on 93 camera trap image with ground truth distance obtain use calibrate charuco pattern . our result demonstrate that depth anything v2 achieve the best overall performance with a mean absolute error of 0.454m and correlation of 0.962 , while method like zoedepth show significant degradation in outdoor natural environment ( mae : 3.087m ) . we find that median-based depth extraction consistently outperform mean-based approach across all deep learning method . additionally , we analyze computational efficiency , with zoedepth be fast ( 0.17s per image ) but least accurate , while depth anything v2 provide an optimal balance of accuracy and speed ( 0.22s per image ) . this benchmark establish performance baseline for wildlife application and provide practical guidance for implement depth estimation in conservation monitoring system .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04714	object-centric representation learn for enhanced 3d scene graph prediction	KunHo Heo, GiHyun Kim, SuYeon Kim, MyeongAh Cho	3d semantic scene graph prediction aim to detect object and their semantic relationship in 3d scene , and have emerge a a crucial technology for robotics and ar/vr application . while previous research have address dataset limitation and explore various approach include open-vocabulary setting , they frequently fail to optimize the representational capacity of object and relationship feature , show excessive reliance on graph neural network despite insufficient discriminative capability . in this work , we demonstrate through extensive analysis that the quality of object feature play a critical role in determine overall scene graph accuracy . to address this challenge , we design a highly discriminative object feature encoder and employ a contrastive pretraining strategy that decouple object representation learn from the scene graph prediction . this design not only enhance object classification accuracy but also yield direct improvement in relationship prediction . notably , when plug in our pretrained encoder into exist framework , we observe substantial performance improvement across all evaluation metric . additionally , whereas exist approach have not fully exploit the integration of relationship information , we effectively combine both geometric and semantic feature to achieve superior relationship prediction . comprehensive experiment on the 3dssg dataset demonstrate that our approach significantly outperform previous state-of-the-art method . our code be publicly available at http : //github.com/visualsciencelab-khu/ocrl-3dssg-codes .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04712	reactdiff : fundamental multiple appropriate facial reaction diffusion model	Luo Cheng, Song Siyang, Yan Siyuan, Yu Zhen, Ge Zongyuan	the automatic generation of diverse and human-like facial reaction in dyadic dialogue remain a critical challenge for human-computer interaction system . exist method fail to model the stochasticity and dynamic inherent in real human reaction . to address this , we propose reactdiff , a novel temporal diffusion framework for generate diverse facial reaction that be appropriate for respond to any give dialogue context . our key insight be that plausible human reaction demonstrate smoothness , and coherence over time , and conform to constraint impose by human facial anatomy . to achieve this , reactdiff incorporates two vital prior ( spatio-temporal facial kinematics ) into the diffusion process : i ) temporal facial behavioral kinematics and ii ) facial action unit dependency . these two constraint guide the model toward realistic human reaction manifold , avoid visually unrealistic jitter , unstable transition , unnatural expression , and other artifact . extensive experiment on the react2024 dataset demonstrate that our approach not only achieve state-of-the-art reaction quality but also excels in diversity and reaction appropriateness .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04706	id-consistent , precise expression generation with blendshape-guided diffusion	Foivos Paraperas Papantoniou, Stefanos Zafeiriou	human-centric generative model design for ai-driven storytelling must bring together two core capability : identity consistency and precise control over human performance . while recent diffusion-based approach have make significant progress in maintain facial identity , achieve fine-grained expression control without compromise identity remain challenge . in this work , we present a diffusion-based framework that faithfully reimagines any subject under any particular facial expression . building on an id-consistent face foundation model , we adopt a compositional design feature an expression cross-attention module guide by flame blendshape parameter for explicit control . train on a diverse mixture of image and video data rich in expressive variation , our adapter generalize beyond basic emotion to subtle micro-expressions and expressive transition , overlook by prior work . in addition , a pluggable reference adapter enable expression edit in real image by transfer the appearance from a reference frame during synthesis . extensive quantitative and qualitative evaluation show that our model outperform exist method in tailored and identity-consistent expression generation . code and model can be find at http : //github.com/foivospar/arc2face .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04705	label-efficient cross-modality generalization for liver segmentation in multi-phase mri	Quang-Khai Bui-Tran, Minh-Toan Dinh, Thanh-Huy Nguyen, Ba-Thinh Lam, Mai-Anh Vu, Ulas Bagci	accurate liver segmentation in multi-phase mri be vital for liver fibrosis assessment , yet label data be often scarce and unevenly distribute across image modality and vendor system . we propose a label-efficient segmentation approach that promote cross-modality generalization under real-world condition , where ged4 hepatobiliary-phase annotation be limited , non-contrast sequence ( t1wi , t2wi , dwi ) be unlabeled , and spatial misalignment and miss phase be common . our method integrate a foundation-scale 3d segmentation backbone adapt via fine-tuning , co-training with cross pseudo supervision to leverage unlabeled volume , and a standardized preprocessing pipeline . without require spatial registration , the model learn to generalize across mri phase and vendor , demonstrate robust segmentation performance in both label and unlabeled domain . our result exhibit the effectiveness of our propose label-efficient baseline for liver segmentation in multi-phase , multi-vendor mri and highlight the potential of combine foundation model adaptation with co-training for real-world clinical imaging task .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04673	watch and learn : learning to use computer from online video	Chan Hee Song, Yiwen Song, Palash Goyal, Yu Su, Oriana Riva, Hamid Palangi, Tomas Pfister	computer use agent ( cuas ) need to plan task workflow ground in diverse , ever-changing application and environment , but learn be hinder by the scarcity of large-scale , high-quality training data in the target application . exist datasets be domain-specific , static , and costly to annotate , while current synthetic data generation method often yield simplistic or misalign task demonstration . to address these limitation , we introduce watch & learn ( w & l ) , a framework that convert human demonstration video readily available on the internet into executable ui trajectory at scale . instead of directly generate trajectory or rely on ad hoc reason heuristic , we cast the problem a an inverse dynamic objective : predict the user 's action from consecutive screen state . this formulation reduce manual engineering , be easy to learn , and generalize more robustly across application . concretely , we develop an inverse dynamic label pipeline with task-aware video retrieval , generate over 53k high-quality trajectory from raw web video , and demonstrate that these trajectory improve cuas both a in-context demonstration and a supervised training data . on the challenging osworld benchmark , ui trajectory extract with w & l consistently enhance both general-purpose and state-of-the-art framework in-context , and deliver strong gain for open-source model under supervised training . these result highlight web-scale human demonstration video a a practical and scalable foundation for advance cuas towards real-world deployment .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04668	conceptsplit : decouple multi-concept personalization of diffusion model via token-wise adaptation and attention disentanglement	Habin Lim, Yeongseob Won, Juwon Seo, Gyeong-Moon Park	in recent year , multi-concept personalization for text-to-image ( t2i ) diffusion model to represent several subject in an image have gain much more attention . the main challenge of this task be `` concept mixing '' , where multiple learn concept interfere or blend undesirably in the output image . to address this issue , in this paper , we present conceptsplit , a novel framework to split the individual concept through training and inference . our framework comprise two key component . first , we introduce token-wise value adaptation ( tova ) , a merging-free training method that focus exclusively on adapt the value projection in cross-attention . base on our empirical analysis , we find that modify the key projection , a common approach in exist method , can disrupt the attention mechanism and lead to concept mix . second , we propose latent optimization for disentangled attention ( loda ) , which alleviate attention entanglement during inference by optimize the input latent . through extensive qualitative and quantitative experiment , we demonstrate that conceptsplit achieve robust multi-concept personalization , mitigate unintended concept interference . code be available at http : //github.com/ku-vgi/conceptsplit	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04654	mome : estimating psychological trait from gait with multi-stage mixture of movement expert	Andy Cǎtrunǎ, Adrian Cosma, Emilian Rǎdoi	gait encodes rich biometric and behavioural information , yet leverage the manner of walk to infer psychological trait remain a challenging and underexplored problem . we introduce a hierarchical multi-stage mixture of movement expert ( mome ) architecture for multi-task prediction of psychological attribute from gait sequence represent a 2d pose . mome process the walk cycle in four stage of movement complexity , employ lightweight expert model to extract spatio-temporal feature and task-specific gating module to adaptively weight expert across trait and stage . evaluate on the psymo benchmark cover 17 psychological trait , our method outperform state-of-the-art gait analysis model , achieve a 37.47 % weighted f1 score at the run level and 44.6 % at the subject level . our experiment show that integrate auxiliary task such a identity recognition , gender prediction , and bmi estimation further improve psychological trait estimation . our finding demonstrate the viability of multi-task gait-based learning for psychological trait estimation and provide a foundation for future research on movement-informed psychological inference .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04648	edupersona : benchmarking subjective ability boundary of virtual student agent	Buyuan Zhu, Shiyu Hu, Yiping Ma, Yuanming Zhang, Kang Hao Cheong	a large language model be increasingly integrate into education , virtual student agent be become vital for classroom simulation and teacher training . yet their classroom-oriented subjective ability remain largely unassessed , limit understanding of model boundary and hinder trustworthy deployment . we present edupersona , a large-scale benchmark span two language , three subject , and ten persona type base on the big five theory . the dataset contain 1,308 authentic classroom dialogue round , correspond to 12,814 teacher-student q & a turn , and be far expand through persona stylization into roughly 10 time large scale ( 128k turn ) , provide a solid foundation for evaluation . building on this resource , we decompose hard-to-quantify subjective performance into three progressive task : task1 basic coherence ( whether behavior , emotion , expression , and voice align with classroom context ) , task2 student realism , and task3 long-term persona consistency , thereby establish an evaluation framework ground in educational theory and research value . we conduct systematic experiment on three representative llm , compare their original version with ten persona-fine-tuned variant train on edupersona . result show consistent and significant average improvement across all task : task1 +33.6 % , task2 +30.6 % , and task3 +14.9 % . these improvement highlight the dataset 's effectiveness and research value , while also reveal the heterogeneous difficulty of persona modeling . in summary , edupersona delivers the first classroom benchmark center on subjective ability , establish a decoupled and verifiable research paradigm , and we will open-source both the dataset and the framework to support the broad research community in advance trustworthy and human-like ai for education .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04645	do superpixel segmentation method influence deforestation image classification ?	Hugo Resende, Fabio A. Faria, Eduardo B. Neto, Isabela Borlido, Victor Sundermann, Silvio Jamil F. Guimarães, Álvaro L. Fazenda	image segmentation be a crucial step in various visual application , include environmental monitoring through remote sensing . in the context of the foresteyes project , which combine citizen science and machine learning to detect deforestation in tropical forest , image segment be use for label by volunteer and subsequent model training . traditionally , the simple linear iterative clustering ( slic ) algorithm be adopt a the segmentation method . however , recent study have indicate that other superpixel-based method outperform slic in remote sense image segmentation , and might suggest that they be more suitable for the task of detect deforest area . in this sense , this study investigate the impact of the four best segmentation method , together with slic , on the training of classifier for the target application . initially , the result show little variation in performance among segmentation method , even when select the top five classifier use the pycaret automl library . however , by apply a classifier fusion approach ( ensemble of classifier ) , noticeable improvement in balanced accuracy be observe , highlight the importance of both the choice of segmentation method and the combination of machine learning-based model for deforestation detection task .	Computer Vision and Pattern Recognition	06/10/2025
10.1145/3757377.3763879	social agent : mastering dyadic nonverbal behavior generation via conversational llm agent	Zeyi Zhang, Yanju Zhou, Heyuan Yao, Tenglong Ao, Xiaohang Zhan, Libin Liu	we present social agent , a novel framework for synthesize realistic and contextually appropriate co-speech nonverbal behavior in dyadic conversation . in this framework , we develop an agentic system drive by a large language model ( llm ) to direct the conversation flow and determine appropriate interactive behavior for both participant . additionally , we propose a novel dual-person gesture generation model base on an auto-regressive diffusion model , which synthesize coordinated motion from speech signal . the output of the agentic system be translate into high-level guidance for the gesture generator , result in realistic movement at both the behavioral and motion level . furthermore , the agentic system periodically examine the movement of interlocutor and infers their intention , form a continuous feedback loop that enable dynamic and responsive interaction between the two participant . user study and quantitative evaluation show that our model significantly improve the quality of dyadic interaction , produce natural , synchronized nonverbal behavior .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04630	sfanet : spatial-frequency attention network for deepfake detection	Vrushank Ahire, Aniruddh Muley, Shivam Zample, Siddharth Verma, Pranav Menon, Surbhi Madan, Abhinav Dhall	detect manipulate medium have now become a pressing issue with the recent rise of deepfakes . most existing approach fail to generalize across diverse datasets and generation technique . we thus propose a novel ensemble framework , combine the strength of transformer-based architecture , such a swin transformer and vits , and texture-based method , to achieve good detection accuracy and robustness . our method introduces innovative data-splitting , sequential training , frequency splitting , patch-based attention , and face segmentation technique to handle dataset imbalance , enhance high-impact region ( e.g. , eye and mouth ) , and improve generalization . our model achieve state-of-the-art performance when test on the dfwild-cup dataset , a diverse subset of eight deepfake datasets . the ensemble benefit from the complementarity of these approach , with transformer excel in global feature extraction and texturebased method provide interpretability . this work demonstrate that hybrid model can effectively address the evolving challenge of deepfake detection , offer a robust solution for real-world application .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04628	a spatial-spectral-frequency interactive network for multimodal remote sense classification	Hao Liu, Yunhao Gao, Wei Li, Mingyang Zhang, Maoguo Gong, Lorenzo Bruzzone	deep learning-based method have achieve significant success in remote sense earth observation data analysis . numerous feature fusion technique address multimodal remote sense image classification by integrate global and local feature . however , these technique often struggle to extract structural and detail feature from heterogeneous and redundant multimodal image . with the goal of introduce frequency domain learn to model key and sparse detail feature , this paper introduce the spatial-spectral-frequency interaction network ( s $ ^2 $ fin ) , which integrate pairwise fusion module across the spatial , spectral , and frequency domain . specifically , we propose a high-frequency sparse enhancement transformer that employ sparse spatial-spectral attention to optimize the parameter of the high-frequency filter . subsequently , a two-level spatial-frequency fusion strategy be introduce , comprise an adaptive frequency channel module that fuse low-frequency structure with enhanced high-frequency detail , and a high-frequency resonance mask that emphasize sharp edge via phase similarity . in addition , a spatial-spectral attention fusion module further enhances feature extraction at intermediate layer of the network . experiment on four benchmark multimodal datasets with limited label data demonstrate that s $ ^2 $ fin performs superior classification , outperform state-of-the-art method . the code be available at http : //github.com/haoliu-xdu/ssfin .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04587	pathology-cot : learning visual chain-of-thought agent from expert whole slide image diagnosis behavior	Sheng Wang, Ruiming Wu, Charles Herndon, Yihang Liu, Shunsuke Koga, Jeanne Shen, Zhi Huang	diagnose a whole-slide image be an interactive , multi-stage process involve change in magnification and movement between field . although recent pathology foundation model be strong , practical agentic system that decide what field to examine next , adjust magnification , and deliver explainable diagnosis be still lack . the blocker be data : scalable , clinically align supervision of expert view behavior that be tacit and experience-based , not write in textbook or online , and therefore absent from large language model training . we introduce the ai session recorder , which work with standard wsi viewer to unobtrusively record routine navigation and convert the viewer log into standardized behavioral command ( inspect or peek at discrete magnification ) and bound box . a lightweight human-in-the-loop review turn ai-drafted rationale into the pathology-cot dataset , a form of pair `` where to look '' and `` why it matter '' supervision produce at roughly six time low labeling time . use this behavioral data , we build pathologist-o3 , a two-stage agent that first propose region of interest and then perform behavior-guided reasoning . on gastrointestinal lymph-node metastasis detection , it achieve 84.5 % precision , 100.0 % recall , and 75.4 % accuracy , exceed the state-of-the-art openai o3 model and generalize across backbone . to our knowledge , this constitute one of the first behavior-grounded agentic system in pathology . turn everyday viewer log into scalable , expert-validated supervision , our framework make agentic pathology practical and establish a path to human-aligned , upgradeable clinical ai .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04576	sona : learning conditional , unconditional , and mismatching-aware discriminator	Yuhta Takida, Satoshi Hayakawa, Takashi Shibuya, Masaaki Imaizumi, Naoki Murata, Bac Nguyen, Toshimitsu Uesaka, Chieh-Hsin Lai, Yuki Mitsufuji	deep generative model have make significant advance in generate complex content , yet conditional generation remain a fundamental challenge . exist conditional generative adversarial network often struggle to balance the dual objective of assess authenticity and conditional alignment of input sample within their conditional discriminator . to address this , we propose a novel discriminator design that integrate three key capability : unconditional discrimination , matching-aware supervision to enhance alignment sensitivity , and adaptive weighting to dynamically balance all objective . specifically , we introduce sum of naturalness and alignment ( sona ) , which employ separate projection for naturalness ( authenticity ) and alignment in the final layer with an inductive bias , support by dedicated objective function and an adaptive weighting mechanism . extensive experiment on class-conditional generation task show that \ours achieves superior sample quality and conditional alignment compare to state-of-the-art method . furthermore , we demonstrate it effectiveness in text-to-image generation , confirm the versatility and robustness of our approach .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04564	conditional representation learn for customized task	Honglin Liu, Chao Sun, Peng Hu, Yunfan Li, Xi Peng	conventional representation learn method learn a universal representation that primarily capture dominant semantics , which may not always align with customized downstream task . for instance , in animal habitat analysis , researcher prioritize scene-related feature , whereas universal embeddings emphasize categorical semantics , lead to suboptimal result . a a solution , exist approach resort to supervise fine-tuning , which however incur high computational and annotation cost . in this paper , we propose conditional representation learning ( crl ) , aim to extract representation tailor to arbitrary user-specified criterion . specifically , we reveal that the semantics of a space be determine by it basis , thereby enable a set of descriptive word to approximate the basis for a customized feature space . building upon this insight , give a user-specified criterion , crl first employ a large language model ( llm ) to generate descriptive text to construct the semantic basis , then project the image representation into this conditional feature space leverage a vision-language model ( vlm ) . the conditional representation well capture semantics for the specific criterion , which could be utilize for multiple customized task . extensive experiment on classification and retrieval task demonstrate the superiority and generality of the propose crl . the code be available at http : //github.com/xlearning-scu/2025-neurips-crl .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04553	fast witness persistence for mri volume via hybrid landmarking	Jorge Leonardo Ruiz Williams	we introduce a scalable witness-based persistent homology pipeline for full-brain mri volume that couple density-aware landmark selection with a gpu-ready witness filtration . candidate be score by a hybrid metric that balance geometric coverage against inverse kernel density , yield landmark set that shrink mean pairwise distance by 30-60 % over random or density-only baseline while preserve topological feature . benchmark on brainweb , ixi , and synthetic manifold execute in under ten second on a single nvidia rtx 4090 gpu , avoid the combinatorial blow-up of cech , vietoris-rips , and alpha filtration . the package be distribute on pypi a whale-tda ( installable via pip ) ; source and issue be host at http : //github.com/jorgelrw/whale . the release also expose a fast preset ( mri_deep_dive_fast ) for exploratory sweep , and ship with reproducibility-focused script and artifact for drop-in use in medical imaging workflow .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04547	post-training quantization of vision encoders need prefix register	Seunghyeon Kim, Jinho Kim, Taesun Yeom, Wonpyo Park, Kyuyeun Kim, Jaeho Lee	transformer-based vision encoders -- such a clip -- be central to multimodal intelligence , power application from autonomous web agent to robotic control . since these application often demand real-time processing of massive visual data , reduce the inference cost of vision encoders be critical . post-training quantization offer a practical path , but remain challenge even at 8-bit precision due to massive-scale activation ( i.e. , outlier ) . in this work , we propose $ \textit { regcache } $ , a training-free algorithm to mitigate outlier in vision encoders , enable quantization with significantly small accuracy drop . the propose regcache introduce outlier-prone yet semantically meaningless prefix token to the target vision encoder , which prevent other token from have outlier . notably , we observe that outlier in vision encoders behave differently from those in language model , motivate two technical innovation : middle-layer prefixing and token deletion . experiment show that our method consistently improve the accuracy of quantized model across both text-supervised and self-supervised vision encoders .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04539	c3editor : achieve controllable consistency in 2d model for 3d edit	Zeng Tao, Zheng Ding, Zeyuan Chen, Xiang Zhang, Leizhi Li, Zhuowen Tu	exist 2d-lifting-based 3d edit method often encounter challenge relate to inconsistency , stem from the lack of view-consistent 2d edit model and the difficulty of ensure consistent edit across multiple view . to address these issue , we propose c3editor , a controllable and consistent 2d-lifting-based 3d edit framework . give an original 3d representation and a text-based editing prompt , our method selectively establish a view-consistent 2d edit model to achieve superior 3d edit result . the process begin with the controlled selection of a ground truth ( gt ) view and it corresponding edit image a the optimization target , allow for user-defined manual edits . next , we fine-tune the 2d edit model within the gt view and across multiple view to align with the gt-edited image while ensure multi-view consistency . to meet the distinct requirement of gt view fitting and multi-view consistency , we introduce separate lora module for targeted fine-tuning . our approach deliver more consistent and controllable 2d and 3d edit result than exist 2d-lifting-based method , outperform them in both qualitative and quantitative evaluation .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04536	3dify : a framework for procedural 3d-cg generation assist by llm use mcp and rag	Shun-ichiro Hayashi, Daichi Mukunoki, Tetsuya Hoshino, Satoshi Ohshima, Takahiro Katagiri	this paper propose `` 3dify , '' a procedural 3d computer graphic ( 3d-cg ) generation framework utilize large language model ( llm ) . the framework enable user to generate 3d-cg content solely through natural language instruction . 3dify be build upon dify , an open-source platform for ai application development , and incorporate several state-of-the-art llm-related technology such a the model context protocol ( mcp ) and retrieval-augmented generation ( rag ) . for 3d-cg generation support , 3dify automate the operation of various digital content creation ( dcc ) tool via mcp . when dcc tool do not support mcp-based interaction , the framework employ the computer-using agent ( cua ) method to automate graphical user interface ( gui ) operation . moreover , to enhance image generation quality , 3dify allow user to provide feedback by select preferred image from multiple candidate . the llm then learn variable pattern from these selection and apply them to subsequent generation . furthermore , 3dify support the integration of locally deploy llm , enable user to utilize custom-developed model and to reduce both time and monetary cost associate with external api call by leverage their own computational resource .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04533	tag : tangential amplify guidance for hallucination-resistant diffusion sample	Hyunmin Cho, Donghoon Ahn, Susung Hong, Jee Eun Kim, Seungryong Kim, Kyong Hwan Jin	recent diffusion model achieve the state-of-the-art performance in image generation , but often suffer from semantic inconsistency or hallucination . while various inference-time guidance method can enhance generation , they often operate indirectly by rely on external signal or architectural modification , which introduce additional computational overhead . in this paper , we propose tangential amplify guidance ( tag ) , a more efficient and direct guidance method that operate solely on trajectory signal without modify the underlying diffusion model . tag leverage an intermediate sample a a projection basis and amplify the tangential component of the estimated score with respect to this basis to correct the sampling trajectory . we formalize this guidance process by leverage a first-order taylor expansion , which demonstrate that amplify the tangential component steer the state toward higher-probability region , thereby reduce inconsistency and enhance sample quality . tag be a plug-and-play , architecture-agnostic module that improve diffusion sample fidelity with minimal computational addition , offer a new perspective on diffusion guidance .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04514	chartagent : a multimodal agent for visually ground reasoning in complex chart question answer	Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Sumitra Ganesh, Manuela Veloso	recent multimodal llm have show promise in chart-based visual question answering , but their performance decline sharply on unannotated chart , those require precise visual interpretation rather than rely on textual shortcut . to address this , we introduce chartagent , a novel agentic framework that explicitly perform visual reason directly within the chart 's spatial domain . unlike textual chain-of-thought reasoning , chartagent iteratively decompose query into visual subtasks and actively manipulates and interacts with chart image through specialized action such a draw annotation , crop region ( e.g. , segment pie slice , isolate bar ) , and localize ax , use a library of chart-specific vision tool to fulfill each subtask . this iterative reasoning process closely mirror human cognitive strategy for chart comprehension . chartagent achieve state-of-the-art accuracy on the chartbench and chartx benchmark , surpass prior method by up to 16.07 % absolute gain overall and 17.31 % on unannotated , numerically intensive query . furthermore , our analysis show that chartagent be ( a ) effective across diverse chart type , ( b ) achieve the high score across vary visual and reason complexity level , and ( c ) serve a a plug-and-play framework that boost performance across diverse underlying llm . our work be among the first to demonstrate visually ground reasoning for chart understand use tool-augmented multimodal agent .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04510	real-time prediction of urban sound propagation with conditioned normalizing flow	Achim Eckerle, Martin Spitznagel, Janis Keuper	accurate and fast urban noise prediction be pivotal for public health and for regulatory workflow in city , where the environmental noise directive mandate regular strategic noise map and action plan , often need in permission workflow , right-of-way allocation , and construction scheduling . physics-based solver be too slow for such time-critical , iterative `` what-if '' study . we evaluate conditional normalizing flow ( full-glow ) for generate for generate standards-compliant urban sound-pressure map from 2d urban layout in real time per 256x256 map on a single rtx 4090 ) , enable interactive exploration directly on commodity hardware . on datasets cover baseline , diffraction , and reflection regime , our model accelerate map generation by > 2000 time over a reference solver while improve nlos accuracy by up to 24 % versus prior deep model ; in baseline nlos we reach 0.65 db mae with high structural fidelity . the model reproduce diffraction and interference pattern and support instant recomputation under source or geometry change , make it a practical engine for urban planning , compliance mapping , and operation ( e.g. , temporary road closure , night-work variance assessment ) .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04504	asynchronous denoising diffusion model for align text-to-image generation	Zijing Hu, Yunze Tong, Fengda Zhang, Junkun Yuan, Jun Xiao, Kun Kuang	diffusion model have achieve impressive result in generate high-quality image . yet , they often struggle to faithfully align the generated image with the input prompt . this limitation arise from synchronous denoising , where all pixel simultaneously evolve from random noise to clear image . a a result , during generation , the prompt-related region can only reference the unrelated region at the same noise level , fail to obtain clear context and ultimately impair text-to-image alignment . to address this issue , we propose asynchronous diffusion model -- a novel framework that allocate distinct timesteps to different pixel and reformulate the pixel-wise denoising process . by dynamically modulate the timestep schedule of individual pixel , prompt-related region be denoised more gradually than unrelated region , thereby allow them to leverage clear inter-pixel context . consequently , these prompt-related region achieve good alignment in the final image . extensive experiment demonstrate that our asynchronous diffusion model can significantly improve text-to-image alignment across diverse prompt . the code repository for this work be available at http : //github.com/hu-zijing/asyndm .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04483	tbstar-edit : from image edit pattern shift to consistency enhancement	Hao Fang, Zechao Zhan, Weixin Feng, Ziwei Huang, XuBin Li, Tiezheng Ge	recent advance in image generation and edit technology have enable state-of-the-art model to achieve impressive result in general domain . however , when apply to e-commerce scenario , these general model often encounter consistency limitation . to address this challenge , we introduce tbstar-edit , an new image edit model tailor for the e-commerce domain . through rigorous data engineering , model architecture design and training strategy , tbstar-edit achieves precise and high-fidelity image edit while maintain the integrity of product appearance and layout . specifically , for data engineering , we establish a comprehensive data construction pipeline , encompass data collection , construction , filtering , and augmentation , to acquire high-quality , instruction-following , and strongly consistent edit data to support model training . for model architecture design , we design a hierarchical model framework consist of a base model , pattern shift module , and consistency enhancement module . for model training , we adopt a two-stage training strategy to enhance the consistency preservation : first stage for edit pattern shifting , and second stage for consistency enhancement . each stage involve train different module with separate datasets . finally , we conduct extensive evaluation of tbstar-edit on a self-proposed e-commerce benchmark , and the result demonstrate that tbstar-edit outperforms exist general-domain edit model in both objective metric ( vie score ) and subjective user preference .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04479	vasevqa-3d : benchmarking 3d vlms on ancient greek pottery	Nonghai Zhang, Zeyu Zhang, Jiazi Wang, Yang Zhao, Hao Tang	vision-language model ( vlms ) have achieve significant progress in multimodal understanding task , demonstrate strong capability particularly in general task such a image captioning and visual reasoning . however , when deal with specialized cultural heritage domain like 3d vase artifact , exist model face severe data scarcity issue and insufficient domain knowledge limitation . due to the lack of targeted training data , current vlms struggle to effectively handle such culturally significant specialized task . to address these challenge , we propose the vasevqa-3d dataset , which serve a the first 3d visual question answer dataset for ancient greek pottery analysis , collect 664 ancient greek vase 3d model with correspond question-answer data and establish a complete data construction pipeline . we far develop the vasevlm model , enhance model performance in vase artifact analysis through domain-adaptive training . experimental result validate the effectiveness of our approach , where we improve by 12.8 % on r @ 1 metric and by 6.6 % on lexical similarity compare with previous state-of-the-art on the vasevqa-3d dataset , significantly improve the recognition and understanding of 3d vase artifact , provide new technical pathway for digital heritage preservation research .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04477	medclm : learning to localize and reason via a cot-curriculum in medical vision-language model	Soo Yong Kim, Suin Cho, Vincent-Daniel Yun, Gyeongyeon Hwang	bridge clinical diagnostic reasoning with ai remain a central challenge in medical imaging . we introduce medclm , an automated pipeline that convert detection datasets into large-scale medical visual question answering ( vqa ) data with chain-of-thought ( cot ) reasoning by link lesion box to organ segmentation and structure rationale . these contextual signal enable medical vision-language model to generate question-answer pair with step-by-step reasoning . to utilize this data effectively , we propose an integrated cot-curriculum strategy compose of an easy stage with explicit lesion box for visual grounding , a medium stage that encourage implicit localization , and a hard stage for weakly supervise reason . experimental result demonstrate that medclm attain state-of-the-art performance on several medical vqa benchmark , provide a scalable framework for develop clinically align medical vision-language model .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04472	spegnet : synergistic perception-guided network for camouflage object detection	Baber Jan, Saeed Anwar, Aiman H. El-Maleh, Abdul Jabbar Siddiqui, Abdul Bais	camouflage object detection segment object with intrinsic similarity and edge disruption . current detection method rely on accumulate complex component . each approach add component such a boundary module , attention mechanism , and multi-scale processor independently . this accumulation create a computational burden without proportional gain . to manage this complexity , they process at reduced resolution , eliminate fine detail essential for camouflage . we present spegnet , address fragmentation through a unified design . the architecture integrate multi-scale feature via channel calibration and spatial enhancement . boundary emerge directly from context-rich representation , maintain semantic-spatial alignment . progressive refinement implement scale-adaptive edge modulation with peak influence at intermediate resolution . this design strike a balance between boundary precision and regional consistency . spegnet achieve 0.887 $ s_\alpha $ on camo , 0.890 on cod10k , and 0.895 on nc4k , with real-time inference speed . our approach excels across scale , from tiny , intricate object to large , pattern-similar one , while handle occlusion and ambiguous boundary . code , model weight , and result be available on \href { http : //github.com/baber-jan/spegnet } { http : //github.com/baber-jan/spegnet } .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04450	rear : rethink visual autoregressive model via generator-tokenizer consistency regularization	Qiyuan He, Yicong Li, Haotian Ye, Jinghao Wang, Xinyao Liao, Pheng-Ann Heng, Stefano Ermon, James Zou, Angela Yao	visual autoregressive ( ar ) generation offer a promising path toward unify vision and language model , yet it performance remain suboptimal against diffusion model . prior work often attribute this gap to tokenizer limitation and rasterization ordering . in this work , we identify a core bottleneck from the perspective of generator-tokenizer inconsistency , i.e. , the ar-generated token may not be well-decoded by the tokenizer . to address this , we propose rear , a simple training strategy introduce a token-wise regularization objective : when predict the next token , the causal transformer be also train to recover the visual embedding of the current token and predict the embedding of the target token under a noisy context . it require no change to the tokenizer , generation order , inference pipeline , or external model . despite it simplicity , rear substantially improve performance . on imagenet , it reduce gfid from 3.02 to 1.86 and improves be to 316.9 use a standard rasterization-based tokenizer . when apply to advanced tokenizers , it achieve a gfid of 1.42 with only 177m parameter , match the performance with large state-of-the-art diffusion model ( 675m ) .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04428	a.i.r . : enable adaptive , iterative , and reasoning-based frame selection for video question answer	Yuanhao Zou, Shengji Jin, Andong Deng, Youpeng Zhao, Jun Wang, Chen Chen	effectively apply vision-language model ( vlms ) to video question answer ( videoqa ) hinge on select a concise yet comprehensive set of frame , a processing entire video be computationally infeasible . however , current frame selection method face a critical trade-off : approach rely on lightweight similarity model , such a clip , often fail to capture the nuance of complex query , result in inaccurate similarity score that can not reflect the authentic query-frame relevance , which far undermines frame selection . meanwhile , method that leverage a vlm for deep analysis achieve high accuracy but incur prohibitive computational cost . to address these limitation , we propose a.i.r. , a training-free approach for adaptive , iterative , and reasoning-based frame selection . we leverage a powerful vlm to perform deep , semantic analysis on complex query , and this analysis be deploy within a cost-effective iterative loop that process only a small batch of the most high-potential frame at a time . extensive experiment on various videoqa benchmark demonstrate that our approach outperform exist frame selection method , significantly boost the performance of the foundation vlm , and achieve substantial gain in computational efficiency over other vlm-based technique .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04417	partial information decomposition via normalize flow in latent gaussian distribution	Wenyuan Zhao, Adithya Balachandran, Chao Tian, Paul Pu Liang	the study of multimodality have garner significant interest in field where the analysis of interaction among multiple information source can enhance predictive modeling , data fusion , and interpretability . partial information decomposition ( pid ) have emerge a a useful information-theoretic framework to quantify the degree to which individual modality independently , redundantly , or synergistically convey information about a target variable . however , exist pid method depend on optimize over a joint distribution constrain by estimate pairwise probability distribution , which be costly and inaccurate for continuous and high-dimensional modality . our first key insight be that the problem can be solve efficiently when the pairwise distribution be multivariate gaussians , and we refer to this problem a gaussian pid ( gpid ) . we propose a new gradient-based algorithm that substantially improve the computational efficiency of gpid base on an alternative formulation of the underlying optimization problem . to generalize the applicability to non-gaussian data , we learn information-preserving encoders to transform random variable of arbitrary input distribution into pairwise gaussian random variable . along the way , we resolve an open problem regard the optimality of joint gaussian solution for gpid . empirical validation in diverse synthetic example demonstrate that our propose method provide more accurate and efficient pid estimate than exist baseline . we further evaluate a series of large-scale multimodal benchmark to show it utility in real-world application of quantify pid in multimodal datasets and select high-performing model .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04410	codeformer++ : blind face restoration use deformable registration and deep metric learning	Venkata Bharath Reddy Reddem, Akshay P Sarashetti, Ranjith Merugu, Amit Satish Unde	blind face restoration ( bfr ) have attract increase attention with the rise of generative method . most existing approach integrate generative prior into the restoration pro- cess , aim to jointly address facial detail generation and identity preservation . however , these method often suffer from a trade-off between visual quality and identity fidelity , lead to either identity distortion or suboptimal degradation removal . in this paper , we present codeformer++ , a novel framework that maximize the utility of generative prior for high-quality face restoration while preserve identity . we decompose bfr into three sub-tasks : ( i ) identity- preserve face restoration , ( ii ) high-quality face generation , and ( iii ) dynamic fusion of identity feature with realistic texture detail . our method make three key contribution : ( 1 ) a learning-based deformable face registration module that semantically align generate and restored face ; ( 2 ) a texture guide restoration network to dynamically extract and transfer the texture of generated face to boost the quality of identity-preserving restored face ; and ( 3 ) the integration of deep metric learning for bfr with the generation of informative positive and hard negative sample to good fuse identity- preserving and generative feature . extensive experiment on real-world and synthetic datasets demonstrate that , the pro- pose codeformer++ achieves superior performance in term of both visual fidelity and identity consistency .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04401	your vision-language model ca n't even count to 20 : expose the failure of vlms in compositional counting	Xuyang Guo, Zekai Huang, Zhenmei Shi, Zhao Song, Jiahao Zhang	vision-language model ( vlms ) have become a central focus of today 's ai community , owe to their impressive ability gain from train on large-scale vision-language data from the web . these model have demonstrate strong performance across diverse task , include image understanding , video understanding , complex visual reasoning , and embody ai . despite these noteworthy success , a fundamental question remain : can vlms count object correctly ? in this paper , we introduce a simple yet effective benchmark , vlmcountbench , design under a minimalist set with only basic geometric shape ( e.g. , triangle , circle ) and their composition , focus exclusively on count task without interference from other factor . we adopt strict independent variable control and systematically study the effect of simple property such a color , size , and prompt refinement in a controlled ablation . our empirical result reveal that while vlms can count reliably when only one shape type be present , they exhibit substantial failure when multiple shape type be combine ( i.e. , compositional counting ) . this highlight a fundamental empirical limitation of current vlms and motivates important direction for future research .	Computer Vision and Pattern Recognition	06/10/2025
10.48550/arXiv.2510.04390	morphosim : an interactive , controllable , and editable language-guided 4d world simulator	Xuehai He, Shijie Zhou, Thivyanth Venkateswaran, Kaizhi Zheng, Ziyu Wan, Achuta Kadambi, Xin Eric Wang	world model that support controllable and editable spatiotemporal environment be valuable for robotics , enable scalable training data , repro ducible evaluation , and flexible task design . while recent text-to-video model generate realistic dynam ic , they be constrain to 2d view and offer limited interaction . we introduce morphosim , a language guide framework that generate 4d scene with multi-view consistency and object-level control . from natural language instruction , morphosim produce dynamic environment where object can be direct , recolored , or remove , and scene can be observe from arbitrary viewpoint . the framework integrate trajectory-guided generation with feature field dis tillation , allow edits to be apply interactively without full re-generation . experiment show that mor phosim maintain high scene fidelity while enable controllability and editability . the code be available at http : //github.com/eric-ai-lab/morph4d .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04382	adaptive double-phase rudin -- osher -- fatemi denoising model	Wojciech Górny, Michał Łasica, Alexandros Matsoukas	we propose a new image denoising model base on a variable-growth total variation regularization of double-phase type with adaptive weight . it be design to reduce staircasing with respect to the classical rudin -- osher -- fatemi model , while preserve the edge of the image in a similar fashion . we implement the model and test it performance on synthetic and natural image in 1d and 2d over a range of noise level .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04369	the method of the approximate inverse for limited-angle ct	Bernadette Hahn, Gael Rigaud, Richard Schmähl	limited-angle computerized tomography stand for one of the most difficult challenge in image . although it open the way to faster data acquisition in industry and less dangerous scan in medicine , standard approach , such a the filtered backprojection ( fbp ) algorithm or the widely use total-variation functional , often produce various artefact that hinder the diagnosis . with the rise of deep learning , many modern technique have prove themselves successful in remove such artefact but at the cost of large datasets . in this paper , we propose a new model-driven approach base on the method of the approximate inverse , which could serve a new start point for learn strategy in the future . in contrast to fbp-type approach , our reconstruction step consist in evaluate linear functionals on the measure data use reconstruction kernel that be precomputed a solution of an auxiliary problem . with this problem be uniquely solvable , the derive limited-angle reconstruction kernel ( lark ) be able to fully reconstruct the object without the well-known streak artefact , even for large limited angle . however , it inherit severe ill-conditioning which lead to a different kind of artefact arise from the singular function of the limited-angle radon transform . the problem become particularly challenging when work on semi-discrete ( real or analytical ) measurement . we develop a general regularization strategy , name constrain limited-angle reconstruction kernel ( clark ) , by combine spectral filter , the method of the approximate inverse and custom edge-preserving denoising in order to stabilize the whole process . we further derive and interpret error estimate for the application on real , i.e . semi-discrete , data and we validate our approach on synthetic and real data .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04365	diffusion^2 : dual diffusion model with uncertainty-aware adaptive noise for momentary trajectory prediction	Yuhao Luo, Yuang Zhang, Kehua Chen, Xinyu Zheng, Shucheng Zhang, Sikai Chen, Yinhai Wang	accurate pedestrian trajectory prediction be crucial for ensure safety and efficiency in autonomous driving and human-robot interaction scenario . early study primarily utilized sufficient observational data to predict future trajectory . however , in real-world scenario , such a pedestrian suddenly emerge from blind spot , sufficient observational data be often unavailable ( i.e . momentary trajectory ) , make accurate prediction challenging and increase the risk of traffic accident . therefore , advance research on pedestrian trajectory prediction under extreme scenario be critical for enhance traffic safety . in this work , we propose a novel framework term diffusion^2 , tailor for momentary trajectory prediction . diffusion^2 consist of two sequentially connect diffusion model : one for backward prediction , which generate unobserved historical trajectory , and the other for forward prediction , which forecast future trajectory . give that the generate unobserved historical trajectory may introduce additional noise , we propose a dual-head parameterization mechanism to estimate their aleatoric uncertainty and design a temporally adaptive noise module that dynamically modulate the noise scale in the forward diffusion process . empirically , diffusion^2 set a new state-of-the-art in momentary trajectory prediction on eth/ucy and stanford drone datasets .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04333	rap : 3d rasterization augment end-to-end planning	Lan Feng, Yang Gao, Eloi Zablocki, Quanyi Li, Wuyang Li, Sichao Liu, Matthieu Cord, Alexandre Alahi	imitation learn for end-to-end driving train policy only on expert demonstration . once deploy in a closed loop , such policy lack recovery data : small mistake can not be correct and quickly compound into failure . a promising direction be to generate alternative viewpoint and trajectory beyond the logged path . prior work explores photorealistic digital twin via neural rendering or game engine , but these method be prohibitively slow and costly , and thus mainly use for evaluation . in this work , we argue that photorealism be unnecessary for train end-to-end planner . what matter be semantic fidelity and scalability : driving depend on geometry and dynamic , not textures or light . motivate by this , we propose 3d rasterization , which replace costly render with lightweight rasterization of annotated primitive , enable augmentation such a counterfactual recovery maneuver and cross-agent view synthesis . to transfer these synthetic view effectively to real-world deployment , we introduce a raster-to-real feature-space alignment that bridge the sim-to-real gap . together , these component form rasterization augment planning ( rap ) , a scalable data augmentation pipeline for plan . rap achieve state-of-the-art closed-loop robustness and long-tail generalization , rank first on four major benchmark : navsim v1/v2 , waymo open dataset vision-based e2e driving , and bench2drive . our result show that lightweight rasterization with feature alignment suffices to scale e2e training , offer a practical alternative to photorealistic rendering . project page : http : //alan-lanfeng.github.io/rap/ .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04331	doran : stabilizing weight-decomposed low-rank adaptation via noise injection and auxiliary network	Nghiem T. Diep, Hien Dang, Tuan Truong, Tan Dinh, Huy Nguyen, Nhat Ho	parameter-efficient fine-tuning ( peft ) method have become the standard paradigm for adapt large-scale model . among these technique , weight-decomposed low-rank adaptation ( dora ) have be show to improve both the learning capacity and training stability of the vanilla low-rank adaptation ( lora ) method by explicitly decompose pre-trained weight into magnitude and directional component . in this work , we propose doran , a new variant of dora design to far stabilize training and boost the sample efficiency of dora . our approach include two key stage : ( i ) inject noise into the denominator of dora 's weight decomposition , which serve a an adaptive regularizer to mitigate instability ; and ( ii ) replace static low-rank matrix with auxiliary network that generate them dynamically , enable parameter couple across layer and yield good sample efficiency in both theory and practice . comprehensive experiment on vision and language benchmark show that doran consistently outperform lora , dora , and other peft baseline . these result underscore the effectiveness of combine stabilization through noise-based regularization with network-based parameter generation , offer a promising direction for robust and efficient fine-tuning of foundation model .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04315	genar : next-scale autoregressive generation for spatial gene expression prediction	Jiarui Ouyang, Yihui Wang, Yihang Gao, Yingxue Xu, Shu Yang, Hao Chen	spatial transcriptomics ( st ) offer spatially resolve gene expression but remain costly . predict expression directly from widely available hematoxylin and eosin ( h & e ) stain image present a cost-effective alternative . however , most computational approach ( i ) predict each gene independently , overlook co-expression structure , and ( ii ) cast the task a continuous regression despite expression be discrete count . this mismatch can yield biologically implausible output and complicate downstream analysis . we introduce genar , a multi-scale autoregressive framework that refine prediction from coarse to fine . genar cluster gene into hierarchical group to expose cross-gene dependency , model expression a codebook-free discrete token generation to directly predict raw count , and condition decode on fused histological and spatial embeddings . from an information-theoretic perspective , the discrete formulation avoids log-induced bias and the coarse-to-fine factorization aligns with a principled conditional decomposition . extensive experimental result on four spatial transcriptomics datasets across different tissue type demonstrate that genar achieve state-of-the-art performance , offer potential implication for precision medicine and cost-effective molecular profiling . code be publicly available at http : //github.com/oyjr/genar .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04312	care-pd : a multi-site anonymized clinical dataset for parkinson 's disease gait assessment	Vida Adeli, Ivan Klabucar, Javad Rajabi, Benjamin Filtjens, Soroush Mehraban, Diwei Wang, Hyewon Seo, Trung-Hieu Hoang, Minh N. Do, Candice Muller, Claudia Oliveira, Daniel Boari Coelho, Pieter Ginis, Moran Gilat, Alice Nieuwboer, Joke Spildooren, Lucas Mckay, Hyeokhyen Kwon, Gari Clifford, Christine Esper, Stewart Factor, Imari Genias, Amirhossein Dadashzadeh, Leia Shum, Alan Whone, Majid Mirmehdi, Andrea Iaboni, Babak Taati	objective gait assessment in parkinson 's disease ( pd ) be limit by the absence of large , diverse , and clinically annotated motion datasets . we introduce care-pd , the large publicly available archive of 3d mesh gait data for pd , and the first multi-site collection span 9 cohort from 8 clinical center . all recording ( rgb video or motion capture ) be convert into anonymized smpl mesh via a harmonized preprocessing pipeline . care-pd support two key benchmark : supervise clinical score prediction ( estimate unify parkinson 's disease rating scale , updrs , gait score ) and unsupervised motion pretext task ( 2d-to-3d keypoint lifting and full-body 3d reconstruction ) . clinical prediction be evaluate under four generalization protocol : within-dataset , cross-dataset , leave-one-dataset-out , and multi-dataset in-domain adaptation . to assess clinical relevance , we compare state-of-the-art motion encoders with a traditional gait-feature baseline , find that encoders consistently outperform handcrafted feature . pretraining on care-pd reduces mpjpe ( from 60.8mm to 7.5mm ) and boost pd severity macro-f1 by 17 percentage point , underscore the value of clinically curated , diverse training data . care-pd and all benchmark code be release for non-commercial research at http : //neurips2025.care-pd.ca/ .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04290	chronoedit : towards temporal reason for image editing and world simulation	Jay Zhangjie Wu, Xuanchi Ren, Tianchang Shen, Tianshi Cao, Kai He, Yifan Lu, Ruiyuan Gao, Enze Xie, Shiyi Lan, Jose M. Alvarez, Jun Gao, Sanja Fidler, Zian Wang, Huan Ling	recent advance in large generative model have significantly advance image edit and in-context image generation , yet a critical gap remain in ensure physical consistency , where edited object must remain coherent . this capability be especially vital for world simulation relate task . in this paper , we present chronoedit , a framework that reframes image edit a a video generation problem . first , chronoedit treat the input and edited image a the first and last frame of a video , allow it to leverage large pretrained video generative model that capture not only object appearance but also the implicit physic of motion and interaction through learned temporal consistency . second , chronoedit introduces a temporal reasoning stage that explicitly perform edit at inference time . under this setting , the target frame be jointly denoised with reason token to imagine a plausible edit trajectory that constrain the solution space to physically viable transformation . the reasoning token be then drop after a few step to avoid the high computational cost of render a full video . to validate chronoedit , we introduce pbench-edit , a new benchmark of image-prompt pair for context that require physical consistency , and demonstrate that chronoedit surpass state-of-the-art baseline in both visual fidelity and physical plausibility . code and model for both the 14b and 2b variant of chronoedit will be release on the project page : http : //research.nvidia.com/labs/toronto-ai/chronoedit	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04282	flexible and efficient spatio-temporal transformer for sequential visual place recognition	Yu Kiu, Lau, Chao Chen, Ge Jin, Chen Feng	sequential visual place recognition ( seq-vpr ) leverage transformer to capture spatio-temporal feature effectively ; however , exist approach prioritize performance at the expense of flexibility and efficiency . in practice , a transformer-based seq-vpr model should be flexible to the number of frame per sequence ( seq-length ) , deliver fast inference , and have low memory usage to meet real-time constraint . to our knowledge , no exist transformer-based seq-vpr method achieve both flexibility and efficiency . to address this gap , we propose adapt-stformer , a seq-vpr method build around our novel recurrent deformable transformer encoder ( recurrent-dte ) , which use an iterative recurrent mechanism to fuse information from multiple sequential frame . this design naturally support variable seq-lengths , fast inference , and low memory usage . experiment on the nordland , oxford , and nuscenes datasets show that adapt-stformer boost recall by up to 17 % while reduce sequence extraction time by 36 % and lowering memory usage by 35 % compare to the second-best baseline .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04245	concept-based masking : a patch-agnostic defense against adversarial patch attack	Ayushi Mehrotra, Derek Peng, Dipkamal Bhusal, Nidhi Rastogi	adversarial patch attack pose a practical threat to deep learning model by force targeted misclassifications through localized perturbation , often realize in the physical world . exist defense typically assume prior knowledge of patch size or location , limit their applicability . in this work , we propose a patch-agnostic defense that leverage concept-based explanation to identify and suppress the most influential concept activation vector , thereby neutralize patch effect without explicit detection . evaluate on imagenette with a resnet-50 , our method achieve high robust and clean accuracy than the state-of-the-art patchcleanser , while maintain strong performance across vary patch size and location . our result highlight the promise of combine interpretability with robustness and suggest concept-driven defense a a scalable strategy for secure machine learn model against adversarial patch attack .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04243	the best performance in the care 2025 -- liver task ( liseg-contrast ) : contrast-aware semi-supervised segmentation with domain generalization and test-time adaptation	Jincan Lou, Jingkun Chen, Haoquan Li, Hang Li, Wenjian Huang, Weihua Chen, Fan Wang, Jianguo Zhang	accurate liver segmentation from contrast-enhanced mri be essential for diagnosis , treatment planning , and disease monitoring . however , it remain challenge due to limited annotate data , heterogeneous enhancement protocol , and significant domain shift across scanner and institution . traditional image-to-image translation framework have make great progress in domain generalization , but their application be not straightforward . for example , pix2pix require image registration , and cycle-gan can not be integrate seamlessly into segmentation pipeline . meanwhile , these method be originally use to deal with cross-modality scenario , and often introduce structural distortion and suffer from unstable training , which may pose drawback in our single-modality scenario . to address these challenge , we propose cosseg-tta , a compact segmentation framework for the ged4 ( gd-eob-dtpa enhance hepatobiliary phase mri ) modality build upon nnu-netv2 and enhance with a semi-supervised mean teacher scheme to exploit large amount of unlabeled volume . a domain adaptation module , incorporate a randomized histogram-based style appearance transfer function and a trainable contrast-aware network , enrich domain diversity and mitigate cross-center variability . furthermore , a continual test-time adaptation strategy be employ to improve robustness during inference . extensive experiment demonstrate that our framework consistently outperform the nnu-netv2 baseline , achieve superior dice score and hausdorff distance while exhibit strong generalization to unseen domain under low-annotation condition .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04236	scale sequence-to-sequence generative neural rendering	Shikun Liu, Kam Woh Ng, Wonbong Jang, Jiadong Guo, Junlin Han, Haozhe Liu, Yiannis Douratsos, Juan C. Pérez, Zijian Zhou, Chi Phung, Tao Xiang, Juan-Manuel Pérez-Rúa	we present kaleido , a family of generative model design for photorealistic , unified object- and scene-level neural rendering . kaleido operate on the principle that 3d can be regard a a specialised sub-domain of video , express purely a a sequence-to-sequence image synthesis task . through a systemic study of scale sequence-to-sequence generative neural rendering , we introduce key architectural innovation that enable our model to : i ) perform generative view synthesis without explicit 3d representation ; ii ) generate any number of 6-dof target view condition on any number of reference view via a masked autoregressive framework ; and iii ) seamlessly unify 3d and video modelling within a single decoder-only rectify flow transformer . within this unified framework , kaleido leverage large-scale video data for pre-training , which significantly improve spatial consistency and reduces reliance on scarce , camera-labelled 3d datasets -- all without any architectural modification . kaleido set a new state-of-the-art on a range of view synthesis benchmark . it zero-shot performance substantially outperform other generative method in few-view setting , and , for the first time , match the quality of per-scene optimisation method in many-view setting .	Computer Vision and Pattern Recognition	05/10/2025
10.1016/j.compbiomed.2024.109466	detection of retinal disease use an accelerate reuse convolutional network	Amin Ahmadi Kasani, Hedieh Sajedi	convolutional neural network be continually evolve , with some effort aim at improve accuracy , others at increase speed , and some at enhance accessibility . improve accessibility broaden the application of neural network across a wider range of task , include the detection of eye disease . early diagnosis of eye disease and consult an ophthalmologist can prevent many vision disorder . give the importance of this issue , various datasets have be collect from the cornea to facilitate the process of make neural network model . however , most of the method introduce in the past be computationally complex . in this study , we try to increase the accessibility of deep neural network model . we do this at the most fundamental level , specifically by redesign and optimize the convolutional layer . by do so , we create a new general model that incorporate our novel convolutional layer name arconv layer . thanks to the efficient performance of this new layer , the model have suitable complexity for use in mobile phone and can perform the task of diagnose the presence of disease with high accuracy . the final model we present contain only 1.3 million parameter . in comparison to the mobilenetv2 model , which have 2.2 million parameter , our model demonstrate good accuracy when train and evaluate on the rfmid dataset under identical condition , achieve an accuracy of 0.9328 versus 0.9266 on the rfmid test set .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04231	a recursive pyramidal algorithm for solve the image registration problem	Stefan Dirnstorfer	the problem of image registration be find a transformation that align two image , such that the corresponding point be in the same location . this paper introduce a simple , end-to-end trainable algorithm that be implementable in a few line of python code . the approach be show to work with very little training data and training time , while achieve accurate result in some setting . an example application to stereo vision be train from 74 image on a 19x15 input window . with just a dozen line of python code this algorithm excel in brevity and may serve a a good start in related scenario with limitation to train data , training time or code complexity .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04225	zoom-in to sort ai-generated image out	Yikun Ji, Yan Hong, Bowen Deng, jun lan, Huijia Zhu, Weiqiang Wang, Liqing Zhang, Jianfu Zhang	the rapid growth of ai-generated imagery have blur the boundary between real and synthetic content , raise critical concern for digital integrity . vision-language model ( vlms ) offer interpretability through explanation but often fail to detect subtle artifact in high-quality synthetic image . we propose zoomin , a two-stage forensic framework that improve both accuracy and interpretability . mimic human visual inspection , zoomin first scan an image to locate suspicious region and then perform a focused analysis on these zoomed-in area to deliver a grounded verdict . to support training , we introduce magnifake , a dataset of 20,000 real and high-quality synthetic image annotate with bound box and forensic explanation , generate through an automated vlm-based pipeline . our method achieve 96.39 % accuracy with robust generalization , while provide human-understandable explanation ground in visual evidence .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04220	masc : boosting autoregressive image generation with a manifold-aligned semantic clustering	Lixuan He, Shikang Zheng, Linfeng Zhang	autoregressive ( ar ) model have show great promise in image generation , yet they face a fundamental inefficiency stem from their core component : a vast , unstructured vocabulary of visual token . this conventional approach treat tokens a a flat vocabulary , disregard the intrinsic structure of the token embed space where proximity often correlate with semantic similarity . this oversight result in a highly complex prediction task , which hinder training efficiency and limit final generation quality . to resolve this , we propose manifold-aligned semantic clustering ( masc ) , a principled framework that construct a hierarchical semantic tree directly from the codebook 's intrinsic structure . masc employ a novel geometry-aware distance metric and a density-driven agglomerative construction to model the underlying manifold of the token embeddings . by transform the flat , high-dimensional prediction task into a structured , hierarchical one , masc introduces a beneficial inductive bias that significantly simplify the learning problem for the ar model . masc be design a a plug-and-play module , and our extensive experiment validate it effectiveness : it accelerate training by up to 57 % and significantly improve generation quality , reduce the fid of llamagen-xl from 2.87 to 2.58. masc elevates exist ar framework to be highly competitive with state-of-the-art method , establish that structure the prediction space be as crucial a architectural innovation for scalable generative modeling .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04201	world-to-image : grounding text-to-image generation with agent-driven world knowledge	Moo Hyun Son, Jintaek Oh, Sun Bin Mun, Jaechul Roh, Sehyun Choi	while text-to-image ( t2i ) model can synthesize high-quality image , their performance degrades significantly when prompt with novel or out-of-distribution ( ood ) entity due to inherent knowledge cutoff . we introduce world-to-image , a novel framework that bridge this gap by empower t2i generation with agent-driven world knowledge . we design an agent that dynamically search the web to retrieve image for concept unknown to the base model . this information be then use to perform multimodal prompt optimization , steer powerful generative backbone toward an accurate synthesis . critically , our evaluation go beyond traditional metric , utilize modern assessment like llmgrader and imagereward to measure true semantic fidelity . our experiment show that world-to-image substantially outperform state-of-the-art method in both semantic alignment and visual aesthetic , achieve +8.1 % improvement in accuracy-to-prompt on our curated nice benchmark . our framework achieve these result with high efficiency in less than three iteration , pave the way for t2i system that can better reflect the ever-changing real world . our demo code be available here\footnote { http : //github.com/mhson-kyle/world-to-image } .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04188	let feature decide their own solver : hybrid feature cache for diffusion transformer	Shikang Zheng, Guantao Chen, Qinming Zhou, Yuqi Lin, Lixuan He, Chang Zou, Peiliang Cai, Jiacheng Liu, Linfeng Zhang	diffusion transformer offer state-of-the-art fidelity in image and video synthesis , but their iterative sampling process remain a major bottleneck due to the high cost of transformer forward pass at each timestep . to mitigate this , feature caching have emerge a a training-free acceleration technique that reuse or forecast hidden representation . however , exist method often apply a uniform caching strategy across all feature dimension , ignore their heterogeneous dynamic behavior . therefore , we adopt a new perspective by model hidden feature evolution a a mixture of ode across dimension , and introduce hyca , a hybrid ode solver inspire cache framework that apply dimension-wise caching strategy . hyca achieve near-lossless acceleration across diverse domain and model , include 5.55 time speedup on flux , 5.56 time speedup on hunyuanvideo , 6.24 time speedup on qwen-image and qwen-image-edit without retrain .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04180	from segment to concept : interpretable image classification via concept-guided segmentation	Ran Eisenberg, Amit Rozner, Ethan Fetaya, Ofir Lindenbaum	deep neural network have achieve remarkable success in computer vision ; however , their black-box nature in decision-making limit interpretability and trust , particularly in safety-critical application . interpretability be crucial in domain where error have severe consequence . exist model not only lack transparency but also risk exploit unreliable or misleading feature , which undermine both robustness and the validity of their explanation . concept bottleneck model ( cbms ) aim to improve transparency by reason through human-interpretable concept . still , they require costly concept annotation and lack spatial grounding , often fail to identify which region support each concept . we propose seg-mil-cbm , a novel framework that integrate concept-guided image segmentation into an attention-based multiple instance learning ( mil ) framework , where each segmented region be treat a an instance and the model learn to aggregate evidence across them . by reason over semantically meaningful region align with high-level concept , our model highlight task-relevant evidence , down-weights irrelevant cue , and produce spatially ground , concept-level explanation without require annotation of concept or group . seg-mil-cbm achieves robust performance across setting involve spurious correlation ( unintended dependency between background and label ) , input corruption ( perturbation that degrade visual quality ) , and large-scale benchmark , while provide transparent , concept-level explanation .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04174	blade : bias-linked adaptive debiasing	Piyush Arora, Navlika Singh, Vasubhya Diwan, Pratik Mazumder	neural network have revolutionize numerous field , yet they remain vulnerable to a critical flaw : the tendency to learn implicit bias , spurious correlation between certain attribute and target label in training data . these bias be often more prevalent and easy to learn , cause model to rely on superficial pattern rather than task-relevant feature necessary for generalization . exist method typically rely on strong assumption , such a prior knowledge of these bias or access to bias-conflicting sample , i.e. , sample that contradict spurious correlation and counterbalance bias-aligned sample , sample that conform to these spurious correlation . however , such assumption be often impractical in real-world setting . we propose blade ( { b } ias- { l } ink { a } daptive { de } bias ) , a generative debiasing framework that require no prior knowledge of bias or bias-conflicting sample . blade first train a generative model to translate image across bias domain while preserve task-relevant feature . then , it adaptively refine each image with it synthetic counterpart base on the image 's susceptibility to bias . to encourage robust representation , blade aligns an image with it bias-translated synthetic counterpart that share task-relevant feature but differs in bias , while misalign it with sample share the same bias . we evaluate blade on multiple benchmark datasets and show that it significantly outperform state-of-the-art method . notably , it exceed the close baseline by an absolute margin of around 18 % on the corrupt cifar-10 dataset under the bad group set , establish a new benchmark in bias mitigation and demonstrate it potential for develop more robust deep learning model without explicit supervision .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04145	automate construction safety inspection use a multi-modal vision-language rag framework	Chenxin Wang, Elyas Asadi Shamsabadi, Zhaohui Chen, Luming Shen, Alireza Ahmadian Fard Fini, Daniel Dias-da-Costa	conventional construction safety inspection method be often inefficient a they require navigate through large volume of information . recent advance in large vision-language model ( lvlms ) provide opportunity to automate safety inspection through enhance visual and linguistic understanding . however , exist application face limitation include irrelevant or unspecific response , restrict modal input and hallucination . utilisation of large language model ( llm ) for this purpose be constrain by availability of train data and frequently lack real-time adaptability . this study introduce siteshield , a multi-modal lvlm-based retrieval-augmented generation ( rag ) framework for automate construction safety inspection report by integrate visual and audio input . use real-world data , siteshield outperform unimodal llm without rag with an f1 score of 0.82 , ham loss of 0.04 , precision of 0.76 , and recall of 0.96. the finding indicate that siteshield offer a novel pathway to enhance information retrieval and efficiency in generate safety report .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04142	learn from all : concept alignment for autonomous distillation from multiple drift mllms	Xiaoyu Yang, Jie Lu, En Yu	this paper identify a critical yet underexplored challenge in distil from multimodal large language model ( mllms ) : the reason trajectory generate by multiple drift teacher exhibit concept drift , whereby their reasoning distribution evolve unpredictably and transmit bias to the student model , ultimately compromise it performance . to tackle this issue , we pioneer a theoretical connection between concept drift and knowledge distillation , cast the non-stationary reasoning dynamic from multiple mllm teacher a next-token prediction of multi-stream reasoning trajectories.guided by concept drift , we introduce the `` learn , compare , critique '' paradigm , culminate in autonomous preference optimization ( apo ) . under the active guidance of the teacher , the student model first learns and self-distils prefer thinking by compare multiple teacher . it then engage in critical reflection over the drift inference from teacher , perform concept alignment through apo , ultimately yield a robust , consistent , and generalizable model.extensive experiment demonstrate our superior performance of consistency , robustness and generalization within knowledge distillation . besides , we also contribute a large-scale dataset , cxr-max ( multi-teachers alignment x-ray ) , comprise 170,982 distilled reason trajectory derive from publicly accessible mllms base on mimic-cxr . our code and data be public at : http : //anonymous.4open.science/r/autonomous-distillation/ .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.04136	mome : mixture of matryoshka expert for audio-visual speech recognition	Umberto Cappellazzo, Minsu Kim, Pingchuan Ma, Honglie Chen, Xubo Liu, Stavros Petridis, Maja Pantic	large language model ( llm ) have recently show strong potential in audio-visual speech recognition ( avsr ) , but their high computational demand and sensitivity to token granularity limit their practicality in resource-constrained setting . token compression method can reduce inference cost , but they require fix a compression rate in advance and produce a single fixed-length output , offer no flexibility to balance information density and efficiency at inference time . matryoshka representation learning ( mrl ) address this by enable a single model to operate across multiple token granularity , allow compression rate to be adjust dynamically . however , current mrl-based method treat each scale independently during training , limit cross-scale generalization , robustness at high compression , and interpretability . to overcome these limitation , we propose mome ( mixture of matryoshka expert ) , a novel framework that integrate sparse mixture-of-experts ( moe ) into mrl-based llm for avsr . mome augments a frozen llm with top-k rout and share expert , allow dynamic capacity allocation across scale and modality . a shared router promotes consistent expert activation across granularity , enable compressed sequence to benefit from representation learn at low compression . experiment on lrs2 and lrs3 demonstrate that mome achieves state-of-the-art performance across avsr , asr , and vsr task , while require significantly few parameter and maintain robustness under noise . mome unifies the adaptability of mrl with the efficiency of moe , offer a scalable and interpretable solution for resource-aware speech recognition .	Computer Vision and Pattern Recognition	05/10/2025
10.48550/arXiv.2510.05068	multi-agent distribute optimization with feasible set privacy	Shreya Meel, Sennur Ulukus	we consider the problem of decentralize constrain optimization with multiple agent $ e_1 , \ldots , e_n $ who jointly wish to learn the optimal solution set while keep their feasible set $ \mathcal { p } _1 , \ldots , \mathcal { p } _n $ private from each other . we assume that the objective function $ f $ be know to all agent and each feasible set be a collection of point from a universal alphabet $ \mathcal { p } _ { alph } $ . a designated agent ( leader ) start the communication with the remain ( non-leader ) agent , and be the first to retrieve the solution set . the leader search for the solution by send query to and receive answer from the non-leaders , such that the information on the individual feasible set reveal to the leader should be no more than nominal , i.e. , what be reveal from learn the solution set alone . we develop achievable scheme for obtain the solution set at nominal information leakage , and characterize their communication cost under two communication setup between agent . in this work , we focus on two kind of network setup : i ) ring , where each agent communicate with two adjacent agent , and ii ) star , where only the leader communicate with the remain agent . we show that , if the leader first learn the joint feasible set through an exist private set intersection ( psi ) protocol and then deduce the solution set , the information leak to the leader be great than nominal . moreover , we draw connection of our scheme to threshold psi ( thpsi ) , which be a psi-variant where the intersection be reveal only when it cardinality be large than a threshold value . finally , for various realization of $ f $ map uniformly at random to a fixed range of value , our scheme be more communication-efficient with a high probability compare to retrieve the entire feasible set through psi .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.05052	proactive defense against llm jailbreak	Weiliang Zhao, Jinjun Peng, Daniel Ben-Levi, Zhou Yu, Junfeng Yang	the proliferation of powerful large language model ( llm ) have necessitate robust safety alignment , yet these model remain vulnerable to evolve adversarial attack , include multi-turn jailbreak that iteratively search for successful query . current defense , primarily reactive and static , often fail to counter these search-based attack . in this paper , we introduce proact , a novel proactive defense framework design to disrupt and mislead autonomous jailbreaking process . our core idea be to intentionally provide adversary with `` spurious response '' that appear to be result of successful jailbreak attack but contain no actual harmful content . these misleading response provide false signal to the attacker 's internal optimization loop , cause the adversarial search to terminate prematurely and effectively jailbreaking the jailbreak . by conduct extensive experiment across state-of-the-art llm , jailbreaking framework , and safety benchmark , our method consistently and significantly reduces attack success rate by up to 92\ % . when combine with other defense framework , it far reduce the success rate of the late attack strategy to 0\ % . proact represent an orthogonal defense strategy that can serve a an additional guardrail to enhance llm safety against the most effective jailbreaking attack .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.05028	on cryptography and distribution verification , with application to quantum advantage	Bruno Cavalar, Eli Goldin, Matthew Gray, Taiga Hiroka, Tomoyuki Morimae	one of the most fundamental problem in the field of hypothesis testing be the identity test problem : whether sample from some unknown distribution $ \mathcal { g } $ be actually from some explicit distribution $ \mathcal { d } $ . it be know that when the distribution $ \mathcal { d } $ have support $ [ n ] $ , the optimal sample complexity for the identity test problem be roughly $ o ( \sqrt { n } ) $ . however , many distribution of interest , include those which can be sample efficiently , have exponential support size , and therefore the optimal identity tester also require exponential sample . in this paper , we bypass this low bound by consider restricted setting . the above $ o ( \sqrt { n } ) $ sample complexity identity tester be construct so that it be not fool by any ( even inefficiently-sampled ) distribution . however , in most application , the distribution under consideration be efficiently sampleable , and therefore it be enough to consider only identity tester that be not fool by efficiently-sampled distribution . in that case , we can focus on efficient verification with efficient identity tester . we investigate relation between efficient verification of classical/quantum distribution and classical/quantum cryptography , and show the following result : ( i ) every quantumly samplable distribution be verifiable with a $ \mathbf { p^ { pp } } $ algorithm . ( ii ) if one-way function exist , then no sufficiently random classically samplable distribution be efficiently verifiable . ( iii ) if one-way function do not exist , then every classically samplable distribution be efficiently verifiable . ( iv ) if qefid pair exist , then there exist a quantumly samplable distribution which be not efficiently verifiable . ( v ) if one-way puzzle do not exist , then it be possible to verify sampling-based quantum advantage with a efficient quantum computer .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.05025	imperceptible jailbreaking against large language model	Kuofeng Gao, Yiming Li, Chao Du, Xin Wang, Xingjun Ma, Shu-Tao Xia, Tianyu Pang	jailbreaking attack on the vision modality typically rely on imperceptible adversarial perturbation , whereas attack on the textual modality be generally assume to require visible modification ( e.g. , non-semantic suffix ) . in this paper , we introduce imperceptible jailbreak that exploit a class of unicode character call variation selector . by append invisible variation selector to malicious question , the jailbreak prompt appear visually identical to original malicious question on screen , while their tokenization be `` secretly '' alter . we propose a chain-of-search pipeline to generate such adversarial suffix to induce harmful response . our experiment show that our imperceptible jailbreak achieve high attack success rate against four aligned llm and generalize to prompt injection attack , all without produce any visible modification in the write prompt . our code be available at http : //github.com/sail-sg/imperceptible-jailbreaks .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04992	less be more : on copy complexity in quantum cryptography	Prabhanjan Ananth, Eli Goldin	quantum cryptographic definition be often sensitive to the number of copy of the cryptographic state reveal to an adversary . make definitional change to the number of copy accessible to an adversary can drastically affect various aspect include the computational hardness , feasibility , and applicability of the result cryptographic scheme . this phenomenon appear in many place in quantum cryptography , include quantum pseudorandomness and unclonable cryptography . to address this , we present a generic approach to boost single-copy security to multi-copy security and apply this approach to many setting . a a consequence , we obtain the following new result : -one-copy stretch pseudorandom state generator ( under mild assumption ) imply the existence of t-copy stretch pseudorandom state generator , for any fixed polynomial t. -one-query pseudorandom unitaries with short key ( under mild assumption ) imply the existence of t-query pseudorandom unitaries with short key , for any fixed polynomial t. -assuming indistinguishability obfuscation and other standard cryptographic assumption , there exist identical-copy secure unclonable primitive such a public-key quantum money and quantum copy-protection .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04987	natgvd : natural adversarial example attack towards graph-based vulnerability detection	Avilash Rath, Weiliang Qi, Youpeng Li, Xinda Wang	graph-based model learn rich code graph structural information and present superior performance on various code analysis task . however , the robustness of these model against adversarial example attack in the context of vulnerability detection remain an open question . this paper propose natgvd , a novel attack methodology that generate natural adversarial vulnerable code to circumvent gnn-based and graph-aware transformer-based vulnerability detector . natgvd employ a set of code transformation that modify graph structure while preserve code semantics . instead of inject dead or unrelated code like previous work , natgvd considers naturalness requirement : generate example should not be easily recognize by human or program analysis tool . with extensive evaluation of natgvd on state-of-the-art vulnerability detection system , the result reveal up to 53.04 % evasion rate across gnn-based detector and graph-aware transformer-based detector . we also explore potential defense strategy to enhance the robustness of these system against natgvd .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04984	what your brain activity say about you : a review of neuropsychiatric disorder identify in resting-state and sleep eeg data	J. E. M. Scanlon, A. Pelzer, M. Gharleghi, K. C. Fuhrmeister, T. Köllmer, P. Aichroth, R. Göder, C. Hansen, K. I. Wolf	electroencephalogram monitoring device and online data repository hold large amount of data from individual participate in research and medical study without direct reference to personal identifier . this paper explore what type of personal and health information have be detect and classify within task-free eeg data . additionally , we investigate key characteristic of the collect resting-state and sleep data , in order to determine the privacy risk involve with openly available eeg data . we use google scholar , web of science and search relevant journal to find study which classify or detect the presence of various disorder and personal information in rest state and sleep eeg . only english full-text peer-reviewed journal article or conference paper about classify the presence of medical disorder between individual be include . a quality analysis carry out by 3 reviewer determine general paper quality base on specified evaluation criterion . in rest state eeg , various disorder include autism spectrum disorder , parkinson 's disease , and alcohol use disorder have be classify with high classification accuracy , often require only 5 min of data or less . sleep eeg tends to hold classifiable information about sleep disorder such a sleep apnea , insomnia , and rem sleep disorder , but usually involve long recording or data from multiple sleep stage . many classification method be still develop but even today , access to a person 's eeg can reveal sensitive personal health information . with an increase ability of machine learn method to re-identify individual from their eeg data , this review demonstrate the importance of anonymization , and the development of improved tool for keep study participant and medical eeg user ' privacy safe .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04979	federated computation of roc and pr curve	Xuefeng Xu, Graham Cormode	receiver operate characteristic ( roc ) and precision-recall ( pr ) curve be fundamental tool for evaluate machine learn classifier , offer detailed insight into the trade-off between true positive rate vs. false positive rate ( roc ) or precision vs. recall ( pr ) . however , in federate learning ( fl ) scenario , where data be distribute across multiple client , compute these curve be challenge due to privacy and communication constraint . specifically , the server can not access raw prediction score and class label , which be use to compute the roc and pr curve in a centralized setting . in this paper , we propose a novel method for approximate roc and pr curve in a federated setting by estimate quantiles of the prediction score distribution under distribute differential privacy . we provide theoretical bound on the area error ( ae ) between the true and estimated curve , demonstrate the trade-off between approximation accuracy , privacy , and communication cost . empirical result on real-world datasets demonstrate that our method achieve high approximation accuracy with minimal communication and strong privacy guarantee , make it practical for privacy-preserving model evaluation in federated system .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04885	rl be a hammer and llm be nail : a simple reinforcement learn recipe for strong prompt injection	Yuxin Wen, Arman Zharmagambetov, Ivan Evtimov, Narine Kokhlikyan, Tom Goldstein, Kamalika Chaudhuri, Chuan Guo	prompt injection pose a serious threat to the reliability and safety of llm agent . recent defense against prompt injection , such a instruction hierarchy and secalign , have show notable robustness against static attack . however , to more thoroughly evaluate the robustness of these defense , it be arguably necessary to employ strong attack such a automated red-teaming . to this end , we introduce rl-hammer , a simple recipe for train attacker model that automatically learn to perform strong prompt injection and jailbreak via reinforcement learning . rl-hammer require no warm-up data and can be train entirely from scratch . to achieve high asrs against industrial-level model with defense , we propose a set of practical technique that enable highly effective , universal attack . use this pipeline , rl-hammer reach a 98 % asr against gpt-4o and a $ 72\ % $ asr against gpt-5 with the instruction hierarchy defense . we further discuss the challenge of achieve high diversity in attack , highlight how attacker model tend to reward-hack diversity objective . finally , we show that rl-hammer can evade multiple prompt injection detector . we hope our work advance automatic red-teaming and motivate the development of strong , more principled defense . code be available at http : //github.com/facebookresearch/rl-injector .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04882	enhance treepir for a single-server setting via resampling	Elian Morel	private information retrieval ( pir ) allow a client to retrieve an entry $ \text { db } [ i ] $ from a public database $ \text { db } $ hold by one or more server , without reveal the queried index $ i $ . traditional pir scheme achieve sublinear server computation only under strong assumption , such a the presence of multiple non-colluding server or the use of public-key cryptography . to overcome these limitation , \textit { preprocessing pir } scheme introduce a query-independent offline phase where the client collect \textit { hint } that enable efficient private query during the online phase . in this work , we focus on preprocessing pir scheme rely solely on \textit { one-way function } ( owfs ) , which provide minimal cryptographic assumption and practical implementability . we study three main construction -- treepir , piano , and ppp -- that explore different trade-off between communication , storage , and server trust assumption . building upon the mechanism introduce in piano and ppp , we propose an adaptation of treepir to the single-server setting by introduce a dual-table hint structure ( primary and backup table ) and a \textit { resampling } technique to refresh hint efficiently . our proposed scheme achieve logarithmic upload bandwidth and $ o ( \sqrt { n } \log n ) $ download complexity while require $ o ( \sqrt { n } \log n ) $ client storage . this represent a significant improvement over prior single-server preprocessing pir scheme such a piano ( $ o ( \sqrt { n } ) $ bandwidth ) and ppp ( $ o ( n^ { 1/4 } ) $ bandwidth ) , while maintain the simplicity and minimal assumption of the owf-based setting .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04754	collusion-resistant quantum secure key lease beyond decryption	Fuyuki Kitagawa, Ryo Nishimaki, Nikhil Pappu	secure key leasing ( skl ) enable the holder of a secret key for a cryptographic function to temporarily lease the key use quantum information . later , the recipient can produce a deletion certificate , which prove that they no longer have access to the secret key . the security guarantee ensure that even a malicious recipient can not continue to evaluate the function , after produce a valid deletion certificate . most prior work considers an adversarial recipient that obtain a single lease key , which be insufficient for many application . in the more realistic collusion-resistant setting , security must hold even when polynomially many key be lease ( and subsequently delete ) . however , achieve collusion-resistant skl from standard assumption remain poorly understood , especially for functionality beyond decryption . we improve upon this situation by introduce new pathway for construct collusion-resistant skl . our main contribution be a follow : - a generalization of quantum-secure collusion-resistant traitor trace call multi-level traitor tracing ( mltt ) , and a compiler that transform an mltt scheme for a primitive x into a collusion-resistant skl scheme for primitive x . - the first bound collusion-resistant skl scheme for prfs , assume lwe . - a compiler that upgrade any single-key secure skl scheme for digital signature into one with unbounded collusion-resistance , assume owfs . - a compiler that upgrade collusion-resistant skl scheme with classical certificate to one have verification-query resilience , assume owfs .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04652	modeling and manage temporal obligation in gucon use sparql-star and rdf-star	Ines Akaichi, Giorgos Flouris, Irini Fundulaki, Sabrina Kirrane	in the digital age , data frequently cross organizational and jurisdictional boundary , make effective governance essential . usage control policy have emerge a a key paradigm for regulate data usage , safeguard privacy , protect intellectual property , and ensure compliance with regulation . a central mechanism for usage control be the handling of obligation , which arise a a side effect of use and share data . effective monitoring of obligation require capture usage trace and accounting for temporal aspect such a start time and deadline , a obligation may evolve over time into different state , such a fulfilled , violated , or expire . while several solution have be propose for obligation monitoring , they often lack formal semantics or provide limited support for reason over obligation state . to address these limitation , we extend gucon , a policy framework ground in the formal semantics of spaqrl graph pattern , to explicitly model the temporal aspect of an obligation . this extension enable the expressing of temporal obligation and support continuous monitoring of their evolve state base on usage trace store in temporal knowledge graph . we demonstrate how this extended model can be represent use rdf-star and sparql-star and propose an obligation state manager that monitor obligation state and assess their compliance with respect to usage trace . finally , we evaluate both the extended model and it prototype implementation .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04640	back the wrong horse : how bit-level netlist augmentation can counter power side channel attack	Ali Asghar, Andreas Becher, Daniel Ziener	the dependence of power-consumption on the process data be a known vulnerability of cmos circuit , result in side channel which can be exploit by power-based side channel attack ( scas ) . these attack can extract sensitive information , such a secret key , from the implementation of cryptographic algorithm . exist countermeasure against power-based side channel attack focus on analyze information leakage at the byte level . however , this approach neglect the impact of individual bit on the overall resistance of a cryptographic implementation . in this work , we present a countermeasure base on single-bit leakage . the result suggest that the propose countermeasure can not be break by attack use conventional sca leakage model .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04619	pos-copor : proof-of-stake consensus protocol with native onion rout provide scalability and dos-resistance	Ivan Homoliak, Martin Perešíni, Marek Tamaškovič, Timotej Ponek, Lukáš Hellebrandt, Kamil Malinka	proof-of-stake ( po ) consensus protocol often face a trade-off between performance and security . protocol that pre-elect leader for subsequent round be vulnerable to denial-of-service ( do ) attack , which can disrupt the network and compromise liveness . in this work , we present pos-copor , a single-chain po consensus protocol that mitigate this vulnerability by integrate a native onion rout mechanism into the consensus protocol itself . pos-copor combine stake-weighted probabilistic leader election with an anonymization layer that conceal the network identity of the next block proposer . this approach prevent targeted do attack on leader before they produce a block , thus enhance network resilience . we implement and evaluate pos-copor , demonstrate it ability to achieve a throughput of up to 110 tx/s with 6 node , even with the overhead of the anonymization layer . the result show that native anonymization can provide robust do resistance with only a modest impact on performance , offer a solution to build secure and scalable po blockchains .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04529	computational certified deletion property of magic square game and it application to classical secure key lease	Yuki Takeuchi, Duo Xu	we present the first construction of a computational certified deletion property ( cdp ) achievable with classical communication , derive from the compilation of the non-local magic square game ( msg ) . we leverage the klvy compiler to transform the non-local msg into a 2-round interactive protocol , rigorously demonstrate that this compilation preserve the game-specific cdp . previously , the quantum value and rigidity of the compiled game be investigate . we emphasize that we be the first to investigate cdp ( local randomness in [ fu and miller , phys . rev . a 97 , 032324 ( 2018 ) ] ) for the compiled game . then , we combine this cdp with the framework [ kitagawa , morimae , and yamakawa , eurocrypt 2025 ] to construct secure key lease with classical lessor ( cskl ) . skl enable the lessor to lease the secret key to the lessee and verify that a quantum lessee have indeed delete the key . in this paper , we realize cskl for pke , prf , and digital signature . compare to prior work for cskl , we realize cskl for prf and digital signature for the first time . in addition , we succeed in weaken the assumption need to construct cskl .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04528	unified threat detection and mitigation framework ( utdmf ) : combat prompt injection , deception , and bias in enterprise-scale transformer	Santhosh KumarRavindran	the rapid adoption of large language model ( llm ) in enterprise system expose vulnerability to prompt injection attack , strategic deception , and bias output , threaten security , trust , and fairness . extend our adversarial activation patch framework ( arxiv:2507.09406 ) , which induce deception in toy network at a 23.9 % rate , we introduce the unified threat detection and mitigation framework ( utdmf ) , a scalable , real-time pipeline for enterprise-grade model like llama-3.1 ( 405b ) , gpt-4o , and claude-3.5 . through 700+ experiment per model , utdmf achieves : ( 1 ) 92 % detection accuracy for prompt injection ( e.g. , jailbreaking ) ; ( 2 ) 65 % reduction in deceptive output via enhanced patching ; and ( 3 ) 78 % improvement in fairness metric ( e.g. , demographic bias ) . novel contribution include a generalized patching algorithm for multi-threat detection , three groundbreaking hypothesis on threat interaction ( e.g. , threat chaining in enterprise workflow ) , and a deployment-ready toolkit with apis for enterprise integration .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04503	p2p : a poison-to-poison remedy for reliable backdoor defense in llm	Shuai Zhao, Xinyi Wu, Shiqian Zhao, Xiaobao Wu, Zhongliang Guo, Yanhao Jia, Anh Tuan Luu	during fine-tuning , large language model ( llm ) be increasingly vulnerable to data-poisoning backdoor attack , which compromise their reliability and trustworthiness . however , exist defense strategy suffer from limited generalization : they only work on specific attack type or task setting . in this study , we propose poison-to-poison ( p2p ) , a general and effective backdoor defense algorithm . p2p inject benign trigger with safe alternative label into a subset of training sample and fine-tunes the model on this re-poisoned dataset by leverage prompt-based learning . this enforce the model to associate trigger-induced representation with safe output , thereby override the effect of original malicious trigger . thanks to this robust and generalizable trigger-based fine-tuning , p2p be effective across task setting and attack type . theoretically and empirically , we show that p2p can neutralize malicious backdoor while preserve task performance . we conduct extensive experiment on classification , mathematical reasoning , and summary generation task , involve multiple state-of-the-art llm . the result demonstrate that our p2p algorithm significantly reduce the attack success rate compare with baseline model . we hope that the p2p can serve a a guideline for defend against backdoor attack and foster the development of a secure and trustworthy llm community .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04465	autonomy matter : a study on personalization-privacy dilemma in llm agent	Zhiping Zhang, Yi Evie Zhang, Freda Shi, Tianshi Li	large language model ( llm ) agent require personal information for personalization in order to good act on user ' behalf in daily task , but this raise privacy concern and a personalization-privacy dilemma . agent 's autonomy introduce both risk and opportunity , yet it effect remain unclear . to good understand this , we conduct a 3 $ \times $ 3 between-subjects experiment ( $ n=450 $ ) to study how agent 's autonomy level and personalization influence user ' privacy concern , trust and willingness to use , as well a the underlie psychological process . we find that personalization without consider user ' privacy preference increase privacy concern and decrease trust and willingness to use . autonomy moderate these effect : intermediate autonomy flatten the impact of personalization compare to no- and full autonomy condition . our result suggest that rather than aim for perfect model alignment in output generation , balance autonomy of agent 's action and user control offer a promising path to mitigate the personalization-privacy dilemma .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04448	quantum cryptography and hardness of non-collapsing measurement	Tomoyuki Morimae, Yuki Shirakawa, Takashi Yamakawa	one-way puzzle ( owpuzzs ) introduce by khurana and tomer [ stoc 2024 ] be a natural quantum analogue of one-way function ( owfs ) , and one of the most fundamental primitive in `` microcrypt '' where owfs do not exist but quantum cryptography be possible . owpuzzs be imply by almost all quantum cryptographic primitive , and imply several important application such a non-interactive commitment and multi-party computation . a significant goal in the field of quantum cryptography be to base owpuzzs on plausible assumption that will not imply owfs . in this paper , we base owpuzzs on hardness of non-collapsing measurement . to that end , we introduce a new complexity class , $ \mathbf { samppdqp } $ , which be a sample version of the decision class $ \mathbf { pdqp } $ introduce in [ aaronson , bouland , fitzsimons , and lee , itcs 2016 ] . we show that if $ \mathbf { samppdqp } $ be hard on average for quantum polynomial time , then owpuzzs exist . $ \mathbf { samppdqp } $ be the class of sample problem that can be solve by a classical polynomial-time algorithm that can make a single query to a non-collapsing measurement oracle , which be a `` magical '' oracle that can sample measurement result on quantum state without collapse the state . such non-collapsing measurement be highly unphysical operation that should be hard to realize in quantum polynomial-time . we also study upperbounds of the hardness of $ \mathbf { samppdqp } $ . we introduce a new primitive , distributional collision-resistant puzzle ( dcrpuzzs ) , which be a natural quantum analogue of distributional collision-resistant hashing [ dubrov and ishai , stoc 2006 ] . we show that dcrpuzzs imply average-case hardness of $ \mathbf { samppdqp } $ ( and therefore owpuzzs a well ) . we also show that two-message honest-statistically-hiding commitment with classical communication and one-shot signature [ amos , georgiou , kiayias , zhandry , stoc 2020 ] imply dcrpuzzs .	Cryptography and Security	06/10/2025
10.48550/arXiv.2510.04398	seca : semantically equivalent and coherent attack for elicit llm hallucination	Buyun Liang, Liangzu Peng, Jinqi Luo, Darshan Thaker, Kwan Ho Ryan Chan, René Vidal	large language model ( llm ) be increasingly deploy in high-risk domain . however , state-of-the-art llm often produce hallucination , raise serious concern about their reliability . prior work have explore adversarial attack for hallucination elicitation in llm , but it often produce unrealistic prompt , either by insert gibberish token or by alter the original meaning . a a result , these approach offer limited insight into how hallucination may occur in practice . while adversarial attack in computer vision often involve realistic modification to input image , the problem of find realistic adversarial prompt for elicit llm hallucination have remain largely underexplored . to address this gap , we propose semantically equivalent and coherent attack ( seca ) to elicit hallucination via realistic modification to the prompt that preserve it meaning while maintain semantic coherence . our contribution be threefold : ( i ) we formulate find realistic attack for hallucination elicitation a a constrained optimization problem over the input prompt space under semantic equivalence and coherence constraint ; ( ii ) we introduce a constraint-preserving zeroth-order method to effectively search for adversarial yet feasible prompt ; and ( iii ) we demonstrate through experiment on open-ended multiple-choice question answer task that seca achieve high attack success rate while incur almost no constraint violation compare to exist method . seca highlight the sensitivity of both open-source and commercial gradient-inaccessible llm to realistic and plausible prompt variation . code be available at http : //github.com/buyun-liang/seca .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04397	mulvuln : enhance pre-trained lm with share and language-specific knowledge for multilingual vulnerability detection	Van Nguyen, Surya Nepal, Xingliang Yuan, Tingmin Wu, Fengchao Chen, Carsten Rudolph	software vulnerability ( svs ) pose a critical threat to safety-critical system , drive the adoption of ai-based approach such a machine learning and deep learning for software vulnerability detection . despite promising result , most existing method be limit to a single programming language . this be problematic give the multilingual nature of modern software , which be often complex and write in multiple language . current approach often face challenge in capture both share and language-specific knowledge of source code , which can limit their performance on diverse programming language and real-world codebases . to address this gap , we propose mulvuln , a novel multilingual vulnerability detection approach that learn from source code across multiple language . mulvuln capture both the share knowledge that generalize across language and the language-specific knowledge that reflect unique cod convention . by integrate these aspect , it achieve more robust and effective detection of vulnerability in real-world multilingual software system . the rigorous and extensive experiment on the real-world and diverse reef dataset , consist of 4,466 cf with 30,987 patch across seven programming language , demonstrate the superiority of mulvuln over thirteen effective and state-of-the-art baseline . notably , mulvuln achieves substantially high f1-score , with improvement range from 1.45 % to 23.59 % compare to the baseline method .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04261	vortexpia : indirect prompt injection attack against llm for efficient extraction of user privacy	Yu Cui, Sicheng Pan, Yifei Liu, Haibin Zhang, Cong Zuo	large language model ( llm ) have be widely deploy in conversational ai ( cais ) , while expose privacy and security threat . recent research show that llm-based cais can be manipulate to extract private information from human user , pose serious security threat . however , the method propose in that study rely on a white-box setting that adversary can directly modify the system prompt . this condition be unlikely to hold in real-world deployment . the limitation raise a critical question : can unprivileged attacker still induce such privacy risk in practical llm-integrated application ? to address this question , we propose \textsc { vortexpia } , a novel indirect prompt injection attack that induce privacy extraction in llm-integrated application under black-box setting . by inject token-efficient data contain false memory , \textsc { vortexpia } mislead llm to actively request private information in batch . unlike prior method , \textsc { vortexpia } allow attacker to flexibly define multiple category of sensitive data . we evaluate \textsc { vortexpia } on six llm , cover both traditional and reason llm , across four benchmark datasets . the result show that \textsc { vortexpia } significantly outperform baseline and achieve state-of-the-art ( sota ) performance . it also demonstrate efficient privacy request , reduce token consumption , and enhance robustness against defense mechanism . we further validate \textsc { vortexpia } on multiple realistic open-source llm-integrated application , demonstrate it practical effectiveness .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04257	agenttypo : adaptive typographic prompt injection attack against black-box multimodal agent	Yanjie Li, Yiming Cao, Dong Wang, Bin Xiao	multimodal agent build on large vision-language model ( lvlms ) be increasingly deploy in open-world setting but remain highly vulnerable to prompt injection , especially through visual input . we introduce agenttypo , a black-box red-teaming framework that mount adaptive typographic prompt injection by embed optimized text into webpage image . our automatic typographic prompt injection ( atpi ) algorithm maximize prompt reconstruction by substitute captioners while minimize human detectability via a stealth loss , with a tree-structured parzen estimator guide black-box optimization over text placement , size , and color . to further enhance attack strength , we develop agenttypo-pro , a multi-llm system that iteratively refine injection prompt use evaluation feedback and retrieve successful past example for continual learning . effective prompt be abstract into generalizable strategy and store in a strategy repository , enable progressive knowledge accumulation and reuse in future attack . experiment on the vwa-adv benchmark across classified , shopping , and reddit scenario show that agenttypo significantly outperform the late image-based attack such a agentattack . on gpt-4o agent , our image-only attack raise the success rate from 0.23 to 0.45 , with consistent result across gpt-4v , gpt-4o-mini , gemini 1.5 pro , and claude 3 opus . in image+text setting , agenttypo achieve 0.68 asr , also outperform the late baseline . our finding reveal that agenttypo pose a practical and potent threat to multimodal agent and highlight the urgent need for effective defense .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04159	proof of quantum memory	Minki Hhan, Tomoyuki Morimae, Yasuaki Okinaka, Takashi Yamakawa	with the rapid advance in quantum computer architecture and the emerge prospect of large-scale quantum memory , it be become essential to classically verify that remote device genuinely allocate the promised quantum memory with specified number of qubits and coherence time . in this paper , we introduce a new concept , proof of quantum memory ( poqm ) . a poqm be an interactive protocol between a classical probabilistic polynomial-time ( ppt ) verifier and a quantum polynomial-time ( qpt ) prover over a classical channel where the verifier can verify that the prover have possess a quantum memory with a certain number of qubits during a specified period of time . poqm generalize the notion of proof of quantumness ( poq ) [ brakerski , christiano , mahadev , vazirani , and vidick , jacm 2021 ] . our main contribution be a formal definition of poqm and it construction base on hardness of lwe . specifically , we give two construction of poqm . the first be of a four-round and have negligible soundness error under subexponential-hardness of lwe . the second be of a polynomial-round and have inverse-polynomial soundness error under polynomial-hardness of lwe . a a lowerbound of poqm , we also show that poqm imply one-way puzzle . moreover , a certain restricted version of poqm implies quantum computation classical communication ( qccc ) key exchange .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04153	obclip : oblivious cloud-device hybrid image generation with privacy preservation	Haoqi Wu, Wei Dai, Ming Xu, Li Wang, Qiang Yan	diffusion model have gain significant popularity due to their remarkable capability in image generation , albeit at the cost of intensive computation requirement . meanwhile , despite their widespread deployment in inference service such a midjourney , concern about the potential leakage of sensitive information in uploaded user prompt have arise . exist solution either lack rigorous privacy guarantee or fail to strike an effective balance between utility and efficiency . to bridge this gap , we propose obclip , a plug-and-play safeguard that enable oblivious cloud-device hybrid generation . by oblivious , each input prompt be transform into a set of semantically similar candidate prompt that differ only in sensitive attribute ( e.g. , gender , ethnicity ) . the cloud server process all candidate prompt without know which one be the real one , thus prevent any prompt leakage . to mitigate server cost , only a small portion of denoising step be perform upon the large cloud model . the intermediate latents be then send back to the client , which select the targeted latent and complete the remain denoising use a small device model . additionally , we analyze and incorporate several cache-based acceleration that leverage temporal and batch redundancy , effectively reduce computation cost with minimal utility degradation . extensive experiment across multiple datasets demonstrate that obclip provide rigorous privacy and comparable utility to cloud model with slightly increase server cost .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04118	cyber warfare during operation sindoor : malware campaign analysis and detection framework	Prakhar Paliwal, Atul Kabra, Manjesh Kumar Hanawal	rapid digitization of critical infrastructure have make cyberwarfare one of the important dimension of modern conflict . attack the critical infrastructure be an attractive pre-emptive proposition for adversary a it can be do remotely without cross border . such attack disturb the support system of the opponent to launch any offensive activity , cripple their fighting capability . cyberattacks during cyberwarfare can not only be use to steal information , but also to spread disinformation to bring down the morale of the opponent . recent war in europe , africa , and asia have demonstrate the scale and sophistication that the warring nation have deploy to take the early upper hand . in this work , we focus on the military action launch by india , code-named operation sindoor , to dismantle terror infrastructure emanate from pakistan and the cyberattacks launch by pakistan . in particular , we study the malware use by pakistan apt group to deploy remote access trojan in indian system . we provide detail of the tactic and technique use in the rat deployment and develop a telemetry framework to collect necessary event log use osquery with a custom extension . finally , we develop a detection rule that can be readily deploy to detect the presence of the rat or any exploitation perform by the malware .	Cryptography and Security	05/10/2025
10.1007/978-3-032-01878-6_10	glue random unitaries with inverse and application to strong pseudorandom unitaries	Prabhanjan Ananth, John Bostanci, Aditya Gulati, Yao-Ting Lin	glue theorem for random unitaries [ schuster , haferkamp , huang , qip 2025 ] have find numerous application , include design low depth random unitaries [ schuster , haferkamp , huang , qip 2025 ] , random unitaries in $ { \sf qac0 } $ [ foxman , parham , vasconcelos , yuen'25 ] and generically shorten the key length of pseudorandom unitaries [ ananth , bostanci , gulati , lin eurocrypt'25 ] . we present an alternate method of combine haar random unitaries from the glue lemma from [ schuster , haferkamp , huang , qip 2025 ] that be secure against adversary with inverse query access to the joined unitary . a a consequence , we show for the first time that strong pseudorandom unitaries can generically have their length extend , and can be construct use only $ o ( n^ { 1/c } ) $ bit of randomness , for any constant $ c $ , if any family of strong pseudorandom unitaries exist .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04056	real-vulllm : an llm base assessment framework in the wild	Rijha Safdar, Danyail Mateen, Syed Taha Ali, Wajahat Hussain	artificial intelligence ( ai ) and more specifically large language model ( llm ) have demonstrate exceptional progress in multiple area include software engineering , however , their capability for vulnerability detection in the wild scenario and it corresponding reasoning remain underexplored . prompt pre-trained llm in an effective way offer a computationally effective and scalable solution . our contribution be ( i ) vary prompt design for vulnerability detection and it correspond reasoning in the wild . ( ii ) a real-world vector data store construct from the national vulnerability database , that will provide real time context to vulnerability detection framework , and ( iii ) a scoring measure for combined measurement of accuracy and reason quality . our contribution aim to examine whether llm be ready for wild deployment , thus enable the reliable use of llm strong for the development of secure software 's .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.04027	multi-class support vector machine with differential privacy	Jinseong Park, Yujin Choi, Jaewook Lee	with the increase need to safeguard data privacy in machine learning model , differential privacy ( dp ) be one of the major framework to build privacy-preserving model . support vector machine ( svms ) be widely use traditional machine learning model due to their robust margin guarantee and strong empirical performance in binary classification . however , apply dp to multi-class svms be inadequate , a the standard one-versus-rest ( ovr ) and one-versus-one ( ovo ) approach repeatedly query each data sample when building multiple binary classifier , thus consume the privacy budget proportionally to the number of class . to overcome this limitation , we explore all-in-one svm approach for dp , which access each data sample only once to construct multi-class svm boundary with margin maximization property . we propose a novel differentially private multi-class svm ( pmsvm ) with weight and gradient perturbation method , provide rigorous sensitivity and convergence analysis to ensure dp in all-in-one svms . empirical result demonstrate that our approach surpass exist dp-svm method in multi-class scenario .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.03996	fheon : a configurable framework for develop privacy-preserving neural network use homomorphic encryption	Nges Brian Njungle, Eric Jahns, Michel A. Kinsy	the widespread adoption of machine learning a a service raise critical privacy and security concern , particularly about data confidentiality and trust in both cloud provider and the machine learning model . homomorphic encryption ( he ) have emerge a a promising solution to this problem , allow computation on encrypt data without decryption . despite it potential , exist approach to integrate he into neural network be often limited to specific architecture , leave a wide gap in provide a framework for easy development of he-friendly privacy-preserving neural network model similar to what we have in the broad field of machine learning . in this paper , we present fheon , a configurable framework for develop privacy-preserving convolutional neural network ( cnn ) model for inference use he . fheon introduces optimize and configurable implementation of privacy-preserving cnn layer include convolutional layer , average pool layer , relu activation function , and fully connect layer . these layer be configure use parameter like input channel , output channel , kernel size , stride , and pad to support arbitrary cnn architecture . we assess the performance of fheon use several cnn architecture , include lenet-5 , vgg-11 , vgg- 16 , resnet-20 , and resnet-34 . fheon maintain encrypted-domain accuracy within +/- 1 % of their plaintext counterpart for resnet-20 and lenet-5 model . notably , on a consumer-grade cpu , the model build on fheon achieve 98.5 % accuracy with a latency of 13 second on mnist use lenet-5 , and 92.2 % accuracy with a latency of 403 second on cifar-10 use resnet-20 . additionally , fheon operates within a practical memory budget require not more than 42.3 gb for vgg-16 .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.03995	privspike : employing homomorphic encryption for private inference of deep spike neural network	Nges Brian Njungle, Eric Jahns, Milan Stojkov, Michel A. Kinsy	deep learning have become a cornerstone of modern machine learning . it rely heavily on vast datasets and significant computational resource for high performance . this data often contain sensitive information , make privacy a major concern in deep learning . spike neural network ( snns ) have emerge a an energy-efficient alternative to conventional deep learning approach . nevertheless , snns still depend on large volume of data , inherit all the privacy challenge of deep learning . homomorphic encryption address this challenge by allow computation to be perform on encrypt data , ensure data confidentiality throughout the entire processing pipeline . in this paper , we introduce privspike , a privacy-preserving inference framework for snns use the ckks homomorphic encryption scheme . privspike support arbitrary depth snns and introduces two key algorithm for evaluate the leaky integrate-and-fire activation function : ( 1 ) a polynomial approximation algorithm design for high-performance snn inference , and ( 2 ) a novel scheme-switching algorithm that optimize precision at a high computational cost . we evaluate privspike on mnist , cifar-10 , neuromorphic mnist , and cifar-10 dvs use model from lenet-5 and resnet-19 architecture , achieve encrypt inference accuracy of 98.10 % , 79.3 % , 98.1 % , and 66.0 % , respectively . on a consumer-grade cpu , snn lenet-5 model achieve inference time of 28 second on mnist and 212 second on neuromorphic mnist . for snn resnet-19 model , inference take 784 second on cifar-10 and 1846 second on cifar-10 dvs . these result establish privspike a a viable and efficient solution for secure snn inference , bridge the gap between energy-efficient deep neural network and strong cryptographic privacy guarantee while outperform prior encrypt snn solution .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.03992	quantify distributional robustness of agentic tool-selection	Jehyeok Yeon, Isha Chaudhary, Gagandeep Singh	large language model ( llm ) be increasingly deploy in agentic system where they map user intent to relevant external tool to fulfill a task . a critical step in this process be tool selection , where a retriever first surface candidate tool from a large pool , after which the llm select the most appropriate one . this pipeline present an underexplored attack surface where error in selection can lead to severe outcome like unauthorized data access or denial of service , all without modify the agent 's model or code . while exist evaluation measure task performance in benign setting , they overlook the specific vulnerability of the tool selection mechanism under adversarial condition . to address this gap , we introduce toolcert , the first statistical framework that formally certify tool selection robustness . toolcert model tool selection a a bernoulli success process and evaluate it against a strong , adaptive attacker who introduce adversarial tool with mislead metadata , and be iteratively refine base on the agent 's previous choice . by sample these adversarial interaction , toolcert produce a high-confidence low bound on accuracy , formally quantify the agent 's worst-case performance . our evaluation with toolcert uncovers the severe fragility : under attack inject deceptive tool or saturate retrieval , the certified accuracy bound drop near zero , an average performance drop of over 60 % compare to non-adversarial setting . for attack target the retrieval and selection stage , the certified accuracy bound plummet to less than 20 % after just a single round of adversarial adaptation . toolcert thus reveal previously unexamined security threat inherent to tool selection and provide a principled method to quantify an agent 's robustness to such threat , a necessary step for the safe deployment of agentic system .	Cryptography and Security	05/10/2025
10.48550/arXiv.2510.03973	strategic communication protocol for interstellar object use a threat-communication viability index and the information-communication paradox	David R. Gruber	strategic communication protocol provide a structured approach for first contact with interstellar object that demonstrate technological characteristic and high level of threat . the protocol find their starting point in an iso information-communication paradox , namely , a our knowledge of an iso 's threatening capability increase , the probability of successful communication decrease while the urgency of communication attempt simultaneously intensifies . from this paradox , a threat-communication viability index be create to describe when the value of communication attempt outweigh strategic silence . the index score the situation and operate a a decision-making tool for stakeholder track an iso . the communication protocols subsequently outline several diplomatic strategy in case where the index recommend communication .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03969	quantify risk in multi-turn conversation with large language model	Chengxiao Wang, Isha Chaudhary, Qian Hu, Weitong Ruan, Rahul Gupta, Gagandeep Singh	large language model ( llm ) can produce catastrophic response in conversational setting that pose serious risk to public safety and security . exist evaluation often fail to fully reveal these vulnerability because they rely on fixed attack prompt sequence , lack statistical guarantee , and do not scale to the vast space of multi-turn conversation . in this work , we propose qrllm , a novel , principled certification framework for catastrophic risk in multi-turn conversation for llm that bound the probability of an llm generate catastrophic response under multi-turn conversation distribution with statistical guarantee . we model multi-turn conversation a probability distribution over query sequence , represent by a markov process on a query graph whose edge encode semantic similarity to capture realistic conversational flow , and quantify catastrophic risk use confidence interval . we define several inexpensive and practical distribution : random node , graph path , adaptive with rejection . our result demonstrate that these distribution can reveal substantial catastrophic risk in frontier model , with certify low bound as high a 70\ % for the bad model , highlight the urgent need for improved safety training strategy in frontier llm .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03863	spatial captcha : generatively benchmarking spatial reason for human-machine differentiation	Arina Kharlamova, Bowei He, Chen Ma, Xue Liu	online service rely on captchas a a first line of defense against automate abuse , yet recent advance in multi-modal large language model ( mllms ) have erode the effectiveness of conventional design that focus on text recognition or 2d image understanding . to address this challenge , we present spatial captcha , a novel human-verification framework that leverage fundamental difference in spatial reasoning between human and mllms . unlike exist captchas which rely on low-level perception task that be vulnerable to modern ai , spatial captcha generates dynamic question require geometric reasoning , perspective-taking , occlusion handling , and mental rotation . these skill be intuitive for human but difficult for state-of-the-art ( sota ) ai system . the system employ a procedural generation pipeline with constraint-based difficulty control , automate correctness verification , and human-in-the-loop validation to ensure scalability , robustness , and adaptability . evaluation on a corresponding benchmark , spatial-captcha-bench , demonstrate that human vastly outperform 10 state-of-the-art mllms , with the best model achieve only 31.0 % pas @ 1 accuracy . furthermore , we compare spatial captcha with google recaptcha , which confirm it effectiveness a both a security mechanism and a diagnostic tool for spatial reasoning in ai .	Cryptography and Security	04/10/2025
10.1007/s11235-024-01163-0	pilot contamination attack detection with machine learn for multi-user massive mimo	Pedro Ivo da Cruz, Dimitri Silva, Tito Spadini, Ricardo Suyama, Murilo Bellezoni Loiola	massive multiple-input multiple-output ( mmimo ) be essential to modern wireless communication system , like 5g and 6g , but it be vulnerable to active eavesdropping attack . one type of such attack be the pilot contamination attack ( pca ) , where a malicious user copy pilot signal from an authentic user during uplink , intentionally interfere with the base station 's ( b ) channel estimation accuracy . in this work , we propose to use a decision tree ( dt ) algorithm for pca detection at the b in a multi-user system . we present a methodology to generate training data for the dt classifier and select the best dt accord to their depth . then , we simulate different scenario that could be encounter in practice and compare the dt to a classical technique base on likelihood ratio test ( lrt ) submit to the same scenario . the result reveal that a dt with only one level of depth be sufficient to outperform the lrt . the dt show a good performance regard the probability of detection in noisy scenario and when the malicious user transmits with low power , in which case the lrt fail to detect the pca . we also show that the reason for the good performance of the dt be it ability to compute a threshold that separate pca data from non-pca data well than the lrt 's threshold . moreover , the dt do not necessitate prior knowledge of noise power or assumption regard the signal power of malicious user , prerequisites typically essential for lrt and other hypothesis test methodology .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03819	security analysis of ponzi scheme in ethereum smart contract	Chunyi Zhang, Qinghong Wei, Xiaoqi Li	the rapid advancement of blockchain technology have precipitate the widespread adoption of ethereum and smart contract across a variety of sector . however , this have also give rise to numerous fraudulent activity , with many speculator embed ponzi scheme within smart contract , result in significant financial loss for investor . currently , there be a lack of effective method for identify and analyze such new type of fraudulent activity . this paper categorize these scam into four structural type and explore the intrinsic characteristic of ponzi scheme contract source code from a program analysis perspective . the mythril tool be employ to conduct static and dynamic analysis of representative case , thereby reveal their vulnerability and operational mechanism . furthermore , this paper employ shell script and command pattern to conduct batch detection of open-source smart contract code , thereby unveil the common characteristic of ponzi scheme smart contract .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03770	complex domain approach for reversible data hiding and homomorphic encryption : general framework and application to disperse data	David Megias	ensure the trustworthiness of data from distribute and resource-constrained environment , such a wireless sensor network or iot device , be critical . exist reversible data hiding ( rdh ) method for scalar data suffer from low embed capacity and poor intrinsic mixing between host data and watermark . this paper introduce hide in the imaginary domain with data encryption ( h [ i ] dden ) , a novel framework base on complex number arithmetic for simultaneous information embedding and encryption . the h [ i ] dden framework offer perfect reversibility , in-principle unlimited watermark size , and intrinsic data-watermark mixing . the paper further introduces two protocol : h [ i ] dden-eg , for joint reversible data hiding and encryption , and h [ i ] dden-aggp , for privacy-preserving aggregation of watermarked data , base on partially homomorphic encryption . these protocol provide efficient and resilient solution for data integrity , provenance and confidentiality , serve a a foundation for new scheme base on the algebraic property of the complex domain .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03761	you have be latexposed : a systematic analysis of information leakage in preprint archive use large language model	Richard A. Dubniczky, Bertalan Borsos, Tihanyi Norbert	the widespread use of preprint repository such a arxiv have accelerate the communication of scientific result but also introduce overlooked security risk . beyond pdfs , these platform provide unrestricted access to original source material , include latex source , auxiliary code , figure , and embed comment . in the absence of sanitization , submission may disclose sensitive information that adversary can harvest use open-source intelligence . in this work , we present the first large-scale security audit of preprint archive , analyze more than 1.2 tb of source data from 100,000 arxiv submission . we introduce latexposed , a four-stage framework that integrate pattern matching , logical filtering , traditional harvesting technique , and large language model ( llm ) to uncover hidden disclosure within non-referenced file and latex comment . to evaluate llm ' secret-detection capability , we introduce llmsec-db , a benchmark on which we test 25 state-of-the-art model . our analysis uncovered thousand of pii leak , gps-tagged exif file , publicly available google drive and dropbox folder , editable private sharepoint link , expose github and google credential , and cloud api key . we also uncover confidential author communication , internal disagreement , and conference submission credential , expose information that pose serious reputational risk to both researcher and institution . we urge the research community and repository operator to take immediate action to close these hidden security gap . to support open science , we release all script and method from this study but withhold sensitive finding that could be misuse , in line with ethical principle . the source code and relate material be available at the project website http : //github.com/latexposed	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03752	public-key encryption from the minrank problem	Rohit Chatterjee, Changrui Mu, Prashant Nalini Vasudevan	we construct a public-key encryption scheme from the hardness of the ( plant ) minrank problem over uniformly random instance . this correspond to the hardness of decode random linear rank-metric code . exist construction of public-key encryption from such problem require hardness for structured instance arise from the masking of efficiently decodable code . central to our construction be the development of a new notion of duality for rank-metric code .	Cryptography and Security	04/10/2025
10.1109/JIOT.2022.3222074	secure operate system through fine-grained kernel access limitation for iot system	Dongyang Zhan, Zhaofeng Yu, Xiangzhan Yu, Hongli Zhang, Lin Ye, Likun Liu	with the development of internet of thing ( iot ) , it be gain a lot of attention . it be important to secure the embedded system with low overhead . the linux seccomp be widely use by developer to secure the kernel by block the access of unused syscalls , which introduce less overhead . however , there be no systematic seccomp configuration approach for iot application without the help of developer . in addition , the exist seccomp configuration approach be coarse-grained , which can not analyze and limit the syscall argument . in this paper , a novel static dependent syscall analysis approach for embedded application be propose , which can obtain all of the possible dependent syscalls and the corresponding argument of the target application . so , a fine-grained kernel access limitation can be perform for the iot application . to this end , the mapping between dynamic library apis and syscalls accord with their argument be build , by analyze the control flow graph and the data dependency relationship of the dynamic library . to the best of our knowledge , this be the first work to generate the fine-grained seccomp profile for embedded application .	Cryptography and Security	04/10/2025
10.1109/TSC.2022.3173791	shrink the kernel attack surface through static and dynamic syscall limitation	Dongyang Zhan, Zhaofeng Yu, Xiangzhan Yu, Hongli Zhang, Lin Ye	linux seccomp be widely use by the program developer and the system maintainer to secure the operating system , which can block unused syscalls for different application and container to shrink the attack surface of the operating system . however , it be difficult to configure the whitelist of a container or application without the help of program developer . docker container block about only 50 syscalls by default , and lot of unblocked useless syscalls introduce a big kernel attack surface . to obtain the dependent syscalls , dynamic tracking be a straight-forward approach but it can not get the full syscall list . static analysis can construct an over-approximated syscall list , but the list contain many false positive . in this paper , a systematic dependent syscall analysis approach , sysverify , be propose by combine static analysis and dynamic verification together to shrink the kernel attack surface . the semantic gap between the binary executables and syscalls be bridge by analyze the binary and the source code , which build the mapping between the library apis and syscalls systematically . to further reduce the attack surface at best effort , we propose a dynamic verification approach to intercept and analyze the security of the invocation of indirect-call-related or rarely invoked syscalls with low overhead .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03705	backdoor-powered prompt injection attack nullify defense method	Yulin Chen, Haoran Li, Yuan Sui, Yangqiu Song, Bryan Hooi	with the development of technology , large language model ( llm ) have dominate the downstream natural language processing ( nlp ) task . however , because of the llm ' instruction-following ability and inability to distinguish the instruction in the data content , such a web page from search engine , the llm be vulnerable to prompt injection attack . these attack trick the llm into deviate from the original input instruction and execute the attacker ' target instruction . recently , various instruction hierarchy defense strategy be propose to effectively defend against prompt injection attack via fine-tuning . in this paper , we explore more vicious attack that nullify the prompt injection defense method , even the instruction hierarchy : backdoor-powered prompt injection attack , where the attacker utilize the backdoor attack for prompt injection attack purpose . specifically , the attacker poison the supervised fine-tuning sample and insert the backdoor into the model . once the trigger be activate , the backdoored model execute the injected instruction surround by the trigger . we construct a benchmark for comprehensive evaluation . our experiment demonstrate that backdoor-powered prompt injection attack be more harmful than previous prompt injection attack , nullify exist prompt injection defense method , even the instruction hierarchy technique .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03697	a time-bound signature scheme for blockchains	Benjamin Marsh, Paolo Serafino	we introduce a modified schnorr signature scheme to allow for time-bound signature for transaction fee auction bidding and smart contract purpose in a blockchain context , ensure an honest producer can only validate a signature before a give block height . the immutable blockchain be use a a source of universal time for the signature scheme . we show the use of such a signature scheme lead to lower mev revenue for builder . we then apply our time-bound signature to ethereum 's eip-1559 and show how it can be use to mitigate the effect of mev on predicted equilibrium strategy .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03636	from theory to practice : evaluate data poison attack and defense in in-context learning on social medium health discourse	Rabeya Amin Jhuma, Mostafa Mohaimen Akand Faisal	this study explore how in-context learning ( icl ) in large language model can be disrupt by data poison attack in the setting of public health sentiment analysis . use tweet of human metapneumovirus ( hmpv ) , small adversarial perturbation such a synonym replacement , negation insertion , and randomized perturbation be introduce into the support examples . even these minor manipulation cause major disruption , with sentiment label flip in up to 67 % of case . to address this , a spectral signature defense be apply , which filter out poisoned example while keep the data 's meaning and sentiment intact . after defense , icl accuracy remain steady at around 46.7 % , and logistic regression validation reach 100 % accuracy , show that the defense successfully preserve the dataset 's integrity . overall , the finding extend prior theoretical study of icl poisoning to a practical , high-stakes setting in public health discourse analysis , highlight both the risk and potential defense for robust llm deployment . this study also highlight the fragility of icl under attack and the value of spectral defense in make ai system more reliable for health-related social medium monitoring .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03631	qpadl : post-quantum private spectrum access with verified location and do resilience	Saleh Darzi, Saif Eddine Nouma, Kiarash Sedghighadikolaei, Attila Altay	with advance in wireless communication and grow spectrum scarcity , spectrum access system ( sas ) offer an opportunistic solution but face significant security challenge . regulation require disclosure of location coordinate and transmission detail , expose user privacy and anonymity during spectrum query , while the database operation themselves permit denial-of-service ( do ) attack . a location-based service , sa be also vulnerable to compromise or malicious user conduct spoof attack . these threat be further amplify give the quantum compute advancement . thus , we propose qpadl , the first post-quantum ( pq ) secure framework that simultaneously ensure privacy , anonymity , location verification , and dos resilience while maintain efficiency for large-scale spectrum access system . qpadl introduces sas-tailored private information retrieval for location privacy , a pq-variant of tor for anonymity , and employ advanced signature construction for location verification alongside client puzzle protocol and rate-limiting technique for do defense . we formally assess it security and conduct a comprehensive performance evaluation , incorporate gpu parallelization and optimization strategy to demonstrate practicality and scalability .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03625	on the limit of consensus under dynamic availability and reconfiguration	Joachim Neu, Javier Nieto, Ling Ren	proof-of-stake blockchains require consensus protocol that support dynamic availability and reconfiguration ( so-called dar setting ) , where the former mean that the consensus protocol should remain live even if a large number of node temporarily crash , and the latter mean it should be possible to change the set of operating node over time . state-of-the-art protocol for the dar setting , such a ethereum , cardano 's ouroboros , or snow white , require unrealistic additional assumption , such a social consensus , or that key evolution be perform even while node be not participate . in this paper , we identify the necessary and sufficient adversarial condition under which consensus can be achieve in the dar set without additional assumption . we then introduce a new and realistic additional assumption : honest node dispose of their cryptographic key the moment they express intent to exit from the set of operating node . to add reconfiguration to any dynamically available consensus protocol , we provide a bootstrapping gadget that be particularly simple and efficient in the common optimistic case of few reconfigurations and no double-spending attempt .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03623	explainable but vulnerable : adversarial attack on xai explanation in cybersecurity application	Maraz Mia, Mir Mehedi A. Pritom	explainable artificial intelligence ( xai ) have aid machine learning ( ml ) researcher with the power of scrutinize the decision of the black-box model . xai method enable look deep inside the model ' behavior , eventually generate explanation along with a perceived trust and transparency . however , depend on any specific xai method , the level of trust can vary . it be evident that xai method can themselves be a victim of post-adversarial attack that manipulate the expected outcome from the explanation module . among such attack tactic , fairwashing explanation ( fe ) , manipulation explanation ( me ) , and backdoor-enabled manipulation attack ( bd ) be the notable one . in this paper , we try to understand these adversarial attack technique , tactic , and procedure ( ttps ) on explanation alteration and thus the effect on the model 's decision . we have explore a total of six different individual attack procedure on post-hoc explanation method such a shap ( shapley additive explanation ) , lime ( local interpretable model-agnostic explanation ) , and ig ( integrated gradient ) , and investigate those adversarial attack in cybersecurity application scenario such a phishing , malware , intrusion , and fraudulent website detection . our experimental study reveal the actual effectiveness of these attack , thus provide an urgency for immediate attention to enhance the resiliency of xai method and their application .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03612	cross-modal content optimization for steer web agent preference	Tanqiu Jiang, Min Bai, Nikolaos Pappas, Yanjun Qi, Sandesh Swamy	vision-language model ( vlm ) -based web agent increasingly power high-stakes selection task like content recommendation or product ranking by combine multimodal perception with preference reasoning . recent study reveal that these agent be vulnerable against attacker who can bias selection outcome through preference manipulation use adversarial pop-up , image perturbation , or content tweak . exist work , however , either assume strong white-box access , with limited single-modal perturbation , or use impractical setting . in this paper , we demonstrate , for the first time , that joint exploitation of visual and textual channel yield significantly more powerful preference manipulation under realistic attacker capability . we introduce cross-modal preference steering ( cps ) that jointly optimize imperceptible modification to an item 's visual and natural language description , exploit clip-transferable image perturbation and rlhf-induced linguistic bias to steer agent decision . in contrast to prior study that assume gradient access , or control over webpage , or agent memory , we adopt a realistic black-box threat setup : a non-privileged adversary can edit only their own listing 's image and textual metadata , with no insight into the agent 's model internals . we evaluate cps on agent power by state-of-the-art proprietary and open source vlms include gpt-4.1 , qwen-2.5vl and pixtral-large on both movie selection and e-commerce task . our result show that cps be significantly more effective than lead baseline method . for instance , our result show that cps consistently outperform baseline across all model while maintain 70 % low detection rate , demonstrate both effectiveness and stealth . these finding highlight an urgent need for robust defense a agentic system play an increasingly consequential role in society .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03610	pentestmcp : a toolkit for agentic penetration test	Zachary Ezetta, Wu-chang Feng	agentic ai be transform security by automate many task be perform manually . while initial agentic approach employ a monolithic architecture , the model-context-protocol have now enable a remote-procedure call ( rpc ) paradigm to agentic application , allow for the flexible construction and composition of multi-function agent . this paper describe pentestmcp , a library of mcp server implementation that support agentic penetration test . by support common penetration test task such a network scanning , resource enumeration , service fingerprinting , vulnerability scanning , exploitation , and post-exploitation , pentestmcp allow a developer to customize multi-agent workflow for perform penetration test .	Cryptography and Security	04/10/2025
10.48550/arXiv.2510.03567	machine unlearn meet adversarial robustness via constrained intervention on llm	Fatmazohra Rezkellah, Ramzi Dakhmouche	with the increase adoption of large language model ( llm ) , more customization be need to ensure privacy-preserving and safe generation . we address this objective from two critical aspect : unlearning of sensitive information and robustness to jail-breaking attack . we investigate various constrain optimization formulation that address both aspect in a \emph { unified manner } , by find the small possible intervention on llm weight that either make a give vocabulary set unreachable or embed the llm with robustness to tailor attack by shift part of the weight to a \emph { safer } region . beyond unify two key property , this approach contrast with previous work in that it do n't require an oracle classifier that be typically not available or represent a computational overhead . surprisingly , we find that the simple point-wise constraint-based intervention we propose lead to good performance than max-min intervention , while have a low computational cost . comparison against state-of-the-art defense method demonstrate superior performance of the propose approach .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03565	cryptoracle : a modular framework to characterize fully homomorphic encryption	Cory Brynds, Parker McLeod, Lauren Caccamise, Asmita Pal, Dewan Saiham, Sazadur Rahman, Joshua San Miguel, Di Wu	privacy-preserving machine learning have become an important long-term pursuit in this era of artificial intelligence ( ai ) . fully homomorphic encryption ( fhe ) be a uniquely promising solution , offer provable privacy and security guarantee . unfortunately , computational cost be impede it mass adoption . modern solution be up to six order of magnitude slow than plaintext execution . understanding and reduce this overhead be essential to the advancement of fhe , particularly a the underlie algorithm evolve rapidly . this paper present a detailed characterization of openfhe , a comprehensive open-source library for fhe , with a particular focus on the ckks scheme due to it significant potential for ai and machine learning application . we introduce cryptoracle , a modular evaluation framework comprising ( 1 ) a benchmark suite , ( 2 ) a hardware profiler , and ( 3 ) a predictive performance model . the benchmark suite encompass openfhe kernel at three abstraction level : workload , microbenchmarks , and primitive . the profiler be compatible with standard and user-specified security parameter . cryptoracle monitor application performance , capture microarchitectural event , and logs power and energy usage for amd and intel system . these metric be consume by a modeling engine to estimate runtime and energy efficiency across different configuration scenario , with error geomean of $ -7.02\ % \sim8.40\ % $ for runtime and $ -9.74\ % \sim15.67\ % $ for energy . cryptoracle be open source , fully modular , and serve a a share platform to facilitate the collaborative advancement of application , algorithm , software , and hardware in fhe . the cryptoracle code can be access at http : //github.com/unarylab/cryptoracle .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03559	privacymotiv : speculative persona journey for empathic and motivate privacy review in ux design	Zeya Chen, Jianing Wen, Ruth Schmidt, Yaxing Yao, Toby Jia-Jun Li, Tianshi Li	ux professional routinely conduct design review , yet privacy concern be often overlook -- not only due to limited tool , but more critically because of low intrinsic motivation . limited privacy knowledge , weak empathy for unexpectedly affected user , and low confidence in identify harm make it difficult to address risk . we present privacymotiv , an llm-powered system that support privacy-oriented design diagnosis by generate speculative persona with ux user journey center on individual vulnerable to privacy risk . draw on narrative strategy , the system construct relatable and attention-drawing scenario that show how ordinary design choice may cause unintended harm , expand the scope of privacy reflection in ux . in a within-subjects study with professional ux practitioner ( n=16 ) , we compare participant ' self-proposed method with privacymotiv across two privacy review task . result show significant improvement in empathy , intrinsic motivation , and perceive usefulness . this work contribute a promising privacy review approach which address the motivational barrier in privacy-aware ux .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03542	a multi-layer electronic and cyber interference model for ai-driven cruise missile : the case of khuzestan province	Pouriya Alimoradi, Ali Barati, Hamid Barati	the rapid advancement of artificial intelligence have enable the development of cruise missile endow with high level of autonomy , adaptability , and precision . these ai driven missile integrate deep learning algorithm , real time data processing , and advance guidance system pose critical threat to strategic infrastructure , especially under complex geographic and climatic condition such a those find in iran khuzestan province . in this paper , we propose a multi layer interference model , encompass electronic warfare , cyberattacks , and deception strategy , to degrade the performance of ai guide cruise missile significantly . our experimental result , derive from 400 simulation run across four distinct scenario , demonstrate notable improvement when employ the integrate multi layer approach compare to single layer or no interference baseline . specifically , the average missile deviation from it intend target increase from 0.25 to 8.65 under multi layer interference a more than 3300 increase in angular deviation . furthermore , the target acquisition success rate be reduce from 92.7 in the baseline scenario to 31.5 , indicate a 66 decrease in successful strike . while resource consumption for multi layer strategy rise by approximately 25 compare to single layer method , the significant drop in missile accuracy and reliability justify the more intensive deployment of jam power , cyber resource , and decoy measure . beyond these quantitative improvement , the propose framework use a deep reinforcement learn base defense coordinator to adaptively select the optimal configuration of ew , cyber , and deception tactic in real time .	Cryptography and Security	03/10/2025
10.1109/ACDSA65407.2025.11165820	a lightweight federate learning approach for privacy-preserving botnet detection in iot	Taha M. Mahmoud, Naima Kaabouch	the rapid growth of the internet of thing ( iot ) have expand opportunity for innovation but also increase exposure to botnet-driven cyberattacks . conventional detection method often struggle with scalability , privacy , and adaptability in resource-constrained iot environment . to address these challenge , we present a lightweight and privacy-preserving botnet detection framework base on federated learning . this approach enable distribute device to collaboratively train model without exchange raw data , thus maintain user privacy while preserve detection accuracy . a communication-efficient aggregation strategy be introduce to reduce overhead , ensure suitability for constrained iot network . experiment on benchmark iot botnet datasets demonstrate that the framework achieve high detection accuracy while substantially reduce communication cost . these finding highlight federated learning a a practical path toward scalable , secure , and privacy-aware intrusion detection for iot ecosystem .	Cryptography and Security	03/10/2025
10.1109/ACDSA65407.2025.11165862	a quantum-secure voting framework use qkd , dual-key symmetric encryption , and verifiable receipt	Taha M. Mahmoud, Naima Kaabouch	electronic vote system face grow risk from cyberattacks and data breach , which be expect to intensify with the advent of quantum compute . to address these challenge , we introduce a quantum-secure voting framework that integrate quantum key distribution ( qkd ) , dual-key symmetric encryption , and verifiable receipt mechanism to strengthen the privacy , integrity , and reliability of the voting process . the framework enable voter to establish encryption key securely , cast encrypted ballot , and verify their vote through receipt-based confirmation , all without expose the vote content . to evaluate performance , we simulate both quantum and classical communication channel use the message queue telemetry transport ( mqtt ) protocol . result demonstrate that the system can process large number of vote efficiently with low latency and minimal error rate . this approach offer a scalable and practical path toward secure , transparent , and verifiable electronic voting in the quantum era .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03461	repair leak in resource wrapper	Sanjay Malakar, Michael D. Ernst, Martin Kellogg, Manu Sridharan	a resource leak occur when a program fail to release a finite resource like a socket , file descriptor or database connection . while sound static analysis tool can detect all leak , automatically repair them remain challenge . prior work take the output of a detection tool and attempt to repair only leak from a hard-coded list of library resource type . that approach limit the scope of repairable leak : real-world code use resource wrapper that store a resource in a field and must themselves be close . this paper make four key contribution to improve resource leak repair in the presence of wrapper . ( 1 ) it integrate inference of resource management specification into the repair pipeline , enable extant fix approach to reason about wrapper . ( 2 ) it transform program into variant that be easy to analyze , make inference , detection , and fix tool more effective ; for instance , it make detection tool report problem closer to the root cause , often in a client of a resource wrapper rather than within the wrapper class itself . ( 3 ) a novel field containment analysis reason about resource lifetime , enable repair of more leak involve resource store in field . ( 4 ) it introduce a new repair pattern and more precise reasoning to well handle resource store in non-final field . prior work fix 41 % of resource leak warning in the njr benchmark suite ; our implementation arodnap fix 68 % .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03417	nexus : network exploration for exploit unsafe sequence in multi-turn llm jailbreak	Javad Rafiei Asl, Sidhant Narula, Mohammad Ghasemigol, Eduardo Blanco, Daniel Takabi	large language model ( llm ) have revolutionize natural language processing but remain vulnerable to jailbreak attack , especially multi-turn jailbreak that distribute malicious intent across benign exchange and bypass alignment mechanism . exist approach often explore the adversarial space poorly , rely on hand-crafted heuristic , or lack systematic query refinement . we present nexus ( network exploration for exploit unsafe sequence ) , a modular framework for construct , refining , and execute optimize multi-turn attack . nexus comprises : ( 1 ) thoughtnet , which hierarchically expand a harmful intent into a structure semantic network of topic , entity , and query chain ; ( 2 ) a feedback-driven simulator that iteratively refine and prune these chain through attacker-victim-judge llm collaboration use harmfulness and semantic-similarity benchmark ; and ( 3 ) a network traverser that adaptively navigate the refined query space for real-time attack . this pipeline uncover stealthy , high-success adversarial path across llm . on several closed-source and open-source llm , nexus increase attack success rate by 2.1 % to 19.4 % over prior method . code : http : //github.com/inspire-lab/nexus	Cryptography and Security	03/10/2025
10.1109/SoutheastCon56624.2025.10971598	security analysis and threat modeling of research management application [ extend version ]	Boniface M. Sindala, Ragib Hasan	research management application ( rma ) be widely use in clinical research environment to collect , transmit , analyze , and store sensitive data . this data be so valuable make rmas susceptible to security threat . this analysis , analyze rmas ' security , focus on research electronic data capture ( redcap ) a an example . we explore the strength and vulnerability within rmas by evaluate the architecture , data flow , and security feature . we identify and assess potential risk use the mitre att\ & ck framework and stride model . we assess redcap 's defense against common attack vector focus on security to provide confidentiality , integrity , availability , non-repudiation , and authentication . we conclude by propose recommendation for enhance the security of rmas , ensure that critical research data remain protect without compromise usability . this research aim to contribute towards a more secure framework for manage sensitive information in research-intensive environment .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03405	legalsim : multi-agent simulation of legal system for discover procedural exploit	Sanket Badhe	we present legalsim , a modular multi-agent simulation of adversarial legal proceeding that explore how ai system can exploit procedural weakness in codified rule . plaintiff and defendant agent choose from a constrain action space ( for example , discovery request , motion , meet-and-confer , sanction ) govern by a json rule engine , while a stochastic judge model with calibrated grant rate , cost allocation , and sanction tendency resolve outcomes . we compare four policy : ppo , a contextual bandit with an llm , a direct llm policy , and a hand-crafted heuristic ; instead of optimize binary case outcome , agent be train and evaluate use effective win rate and a composite exploit score that combine opponent-cost inflation , calendar pressure , settlement pressure at low merit , and a rule-compliance margin . across configurable regime ( e.g. , bankruptcy stay , inter partes review , tax procedure ) and heterogeneous judge , we observe emergent `` exploit chain '' , such a cost-inflating discovery sequence and calendar-pressure tactic that remain procedurally valid yet systemically harmful . evaluation via cross-play and bradley-terry rating show , ppo win more often , the bandit be the most consistently competitive across opponent , the llm trail them , and the heuristic be weak . the result be stable in judge setting , and the simulation reveals emergent exploit chain , motivate red-teaming of legal rule system in addition to model-level testing .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03219	tpm-based continuous remote attestation and integrity verification for 5g vnfs on kubernetes	Al Nahian Bin Emran, Rajendra Upadhyay, Rajendra Paudyal, Lisa Donnan, Duminda Wijesekera	in the rapidly evolve landscape of 5g technology , the adoption of cloud-based infrastructure for the deployment of 5g service have become increasingly common . use a service-based architecture , critical 5g component , such a the access and mobility management function ( amf ) , session management function ( smf ) , and user plane function ( upf ) , now run a containerize pod on kubernetes cluster . although this approach improve scalability , flexibility , and resilience , it also introduce new security challenge , particularly to ensure the integrity and trustworthiness of these component . current 5g security specification ( for example , 3gpp t 33.501 ) focus on communication security and assume that network function remain trustworthy after authentication , consequently lack mechanism to continuously validate the integrity of nvfs at runtime . to close this gap , and to align with zero trust principle of 'never trust , always verify ' , we present a tpm 2.0-based continuous remote attestation solution for core 5g component deploy on kubernetes . our approach use the linux integrity measurement architecture ( ima ) and a trusted platform module ( tpm ) to provide hardware-based runtime validation . we integrate the open-source keylime framework with a custom ima template that isolate pod-level measurement , allow per-pod integrity verification . a prototype on a k3s cluster ( consist of 1 master , 2 worker node ) be implement to attest to core function , include amf , smf and upf . the experimental result show that the system detect unauthorized modification in real time , label each pod 's trust state , and generates detail audit log . this work provide hardware-based continuous attestation for cloud native and edge deployment , strengthen the resilience of 5g a critical infrastructure in multi-vendor and mission-critical scenario of 5g .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03218	cheat-penalised quantum weak coin-flipping	Atul Singh Arora, Carl A. Miller, Mauro E. S. Morales, Jamie Sikora	coin-flipping be a fundamental task in two-party cryptography where two remote mistrustful party wish to generate a share uniformly random bit . while quantum protocol promise near-perfect security exist for weak coin-flipping -- when the party want oppose outcome -- it have be show that they must be inefficient in term of their round complexity , and it be an open question of how space efficient they can be . in this work , we consider a variant call cheat-penalised weak coin-flipping in which if a party get caught cheating , they lose $ \lambda $ point ( compare to $ 0 $ in the standard definition ) . we find that already for a small cheating penalty , the landscape of coin-flipping change dramatically . for example , with $ \lambda=0.01 $ , we exhibit a protocol where neither alice nor bob can bias the result in their favour beyond $ 1/2 + 10^ { -8 } $ , which use $ 24 $ qubits and $ 10^ { 16 } $ round of communication ( provably $ 10^ { 7 } $ time well than any weak coin-flipping protocol with matching security ) . for the same space requirement , we demonstrate how one can choose between lower how much a malicious party can bias the result ( down to $ 1/2 + 10^ { -10 } $ ) and reduce the round of communication ( down to $ 25,180 $ ) , depend on what be prefer . to find these protocol , we make two technical contribution . first , we extend the point game-protocol correspondence introduce by kitaev and mochon , to incorporate : ( i ) approximate point game , ( ii ) the cheat-penalised setting , and ( iii ) round and space complexity . second , we give the first ( to the best of our knowledge ) numerical algorithm for construct ( approximate ) point game that correspond to high security and low complexity . our result open up the possibility of have secure and practical quantum protocol for multiparty computation .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.03035	protect persona biometric data : the case of facial privacy	Lambert Hogenhout, Rinzin Wangmo	the proliferation of digital technology have lead to unprecedented data collection , with facial data emerge a a particularly sensitive commodity . company be increasingly leverage advanced facial recognition technology , often without the explicit consent or awareness of individual , to build sophisticated surveillance capability . this practice , fuel by weak and fragmented law in many jurisdiction , have create a regulatory vacuum that allow for the commercialization of personal identity and pose significant threat to individual privacy and autonomy . this article introduce the concept of facial privacy . it analyze the profound challenge pose by unregulated facial recognition by conduct a comprehensive review of exist legal framework . it examine and compare regulation such a the gdpr , brazil 's lgpd , canada 's pipeda , and privacy act in china , singapore , south korea , and japan , alongside sector-specific law in the united state like the illinois biometric information privacy act ( bipa ) . the analysis highlight the societal impact of this technology , include the potential for discriminatory bias and the long-lasting harm that can result from the theft of immutable biometric data . ultimately , the paper argue that exist legal loophole and ambiguity leave individual vulnerable . it propose a new policy framework that shift the paradigm from data a property to a model of inalienable right , ensure that fundamental human right be upheld against unchecked technological expansion .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02999	untargeted jailbreak attack	Xinzhe Huang, Wenjing Hu, Tianhang Zheng, Kedong Xiu, Xiaojun Jia, Di Wang, Zhan Qin, Kui Ren	exist gradient-based jailbreak attack on large language model ( llm ) , such a greedy coordinate gradient ( gcg ) and cold-attack , typically optimize adversarial suffix to align the llm output with a predefined target response . however , by restrict the optimization objective a induce a predefined target , these method inherently constrain the adversarial search space , which limit their overall attack efficacy . furthermore , exist method typically require a large number of optimization iteration to fulfill the large gap between the fixed target and the original model response , result in low attack efficiency . to overcome the limitation of targeted jailbreak attack , we propose the first gradient-based untargeted jailbreak attack ( uja ) , aim to elicit an unsafe response without enforce any predefined pattern . specifically , we formulate an untargeted attack objective to maximize the unsafety probability of the llm response , which can be quantify use a judge model . since the objective be non-differentiable , we further decompose it into two differentiable sub-objectives for optimize an optimal harmful response and the corresponding adversarial prompt , with a theoretical analysis to validate the decomposition . in contrast to target jailbreak attack , uja 's unrestricted objective significantly expand the search space , enable a more flexible and efficient exploration of llm vulnerabilities.extensive evaluation demonstrate that \textsc { uja } can achieve over 80\ % attack success rate against recent safety-aligned llm with only 100 optimization iteration , outperform the state-of-the-art gradient-based attack such a i-gcg and cold-attack by over 20\ % .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02964	external data extraction attack against retrieval-augmented large language model	Yu He, Yifei Chen, Yiming Li, Shuo Shao, Leyi Qi, Boheng Li, Dacheng Tao, Zhan Qin	in recent year , rag have emerge a a key paradigm for enhance large language model ( llm ) . by integrate externally retrieve information , rag alleviates issue like outdated knowledge and , crucially , insufficient domain expertise . while effective , rag introduces new risk of external data extraction attack ( edeas ) , where sensitive or copyright data in it knowledge base may be extract verbatim . these risk be particularly acute when rag be use to customize specialized llm application with private knowledge base . despite initial study explore these risk , they often lack a formalized framework , robust attack performance , and comprehensive evaluation , leave critical question about real-world edea feasibility unanswered . in this paper , we present the first comprehensive study to formalize edeas against retrieval-augmented llm . we first formally define edeas and propose a unified framework decompose their design into three component : extraction instruction , jailbreak operator , and retrieval trigger , under which prior attack can be consider instance within our framework . guide by this framework , we develop secret : a scalable and effective external data extraction attack . specifically , secret incorporates ( 1 ) an adaptive optimization process use llm a optimizers to generate specialized jailbreak prompt for edeas , and ( 2 ) cluster-focused triggering , an adaptive strategy that alternate between global exploration and local exploitation to efficiently generate effective retrieval trigger . extensive evaluation across 4 model reveal that secret significantly outperform previous attack , and be highly effective against all 16 test rag instance . notably , secret successfully extract 35 % of the data from rag power by claude 3.7 sonnet for the first time , whereas other attack yield 0 % extraction . our finding call for attention to this emerge threat .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02960	sok : kicking can down the road . systematize can security knowledge	Khaled Serag, Zhaozhou Tang, Sungwoo Kim, Vireshwar Kumar, Dave, Tian, Saman Zonouz, Raheem Beyah, Dongyan Xu, Z. Berkay Celik	for decade , the controller area network ( can ) have serve a the primary in-vehicle bus ( ivb ) and extend it use to many non-vehicular system . over the past year , can security have be intensively scrutinize , yield extensive research literature . despite it wealth , the literature lack structure systematization , complicate effort to assess attack severity , defense efficacy , identify security gap , or root cause . this leave non expert uncertain about the relevancy of specific attack or defense to their system , inadvertently portray can a irredeemably insecure . far , the introduction of new ivb technology -- can evolution , add-on , and alternative bus -- with heightened security claim risk foster the misconception that merely adopt these technology resolve can 's security challenge . this paper systematize exist can security knowledge , present a comprehensive taxonomy and assessment model of attacker , attack , and defense . it identify replicable attack and defense gap , investigate their root cause a inherent , accidental , unique , or universal . it then extrapolate these insight to emerge ivb technology by formally analyze three emerge ivbs to identify share root cause with can and assess their ability to close security gap . the finding challenge common perception , demonstrate that can be more securable than perceive , that most insecurity root cause be share across ivbs , and that merely adopt new ivb technology do not solve persistent security issue . the paper conclude by highlight future research direction to secure ivb communication down the road .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02947	sok : preconfirmations	Aikaterini-Panagiota Stouka, Conor McMenamin, Demetris Kyriacou, Lin Oshitani, Quentin Botha	in recent year , significant research effort have focus on improve blockchain throughput and confirmation speed without compromise security . while decrease the time it take for a transaction to be include in the blockchain ledger enhance user experience , a fundamental delay still remain between when a transaction be issue by a user and when it inclusion be confirm in the blockchain ledger . this delay limit user experience gain through the confirmation uncertainty it bring for user . this inherent delay in conventional blockchain protocol have lead to the emergence of preconfirmation protocol -- protocols that provide user with early guarantee of eventual transaction confirmation . this article present a systematization of knowledge ( sok ) on preconfirmations . we present the core term and definition need to understand preconfirmations , outline a general framework for preconfirmation protocol , and explore the economics and risk of preconfirmations . finally , we survey and apply our framework to several implementation of real-world preconfirmation protocol , bridge the gap between theory and practice .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02944	improve search-to-decision reduction for random local function	Kel Zin Tan, Prashant Nalini Vasudevan	a random local function define by a $ d $ -ary predicate $ p $ be one where each output bit be compute by apply $ p $ to $ d $ randomly choose bit of it input . these represent natural distribution of instance for constraint satisfaction problem . they be put forward by goldreich a candidate for low-complexity one-way function , and have subsequently be widely study also a potential pseudo-random generator . we present a new search-to-decision reduction for random local function define by any predicate of constant arity . give any efficient algorithm that can distinguish , with advantage $ \epsilon $ , the output of a random local function with $ m $ output and $ n $ input from random , our reduction produce an efficient algorithm that can invert such function with $ \tilde { o } ( m ( n/\epsilon ) ^2 ) $ output , succeed with probability $ \omega ( \epsilon ) $ . this imply that if a family of local function be one-way , then a related family with short output length be family of pseudo-random generator . prior to our work , all such reduction that be know require the predicate to have additional sensitivity property , whereas our reduction work for any predicate . our result also generalise to some super-constant value of the arity $ d $ , and to noisy predicate .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02915	wavinwav : time-domain speech hide via invertible neural network	Wei Fan, Kejiang Chen, Xiangkun Wang, Weiming Zhang, Nenghai Yu	data hiding be essential for secure communication across digital medium , and recent advance in deep neural network ( dnns ) provide enhance method for embed secret information effectively . however , previous audio hiding method often result in unsatisfactory quality when recover secret audio , due to their inherent limitation in the modeling of time-frequency relationship . in this paper , we explore these limitation and introduce a new dnn-based approach . we use a flow-based invertible neural network to establish a direct link between stego audio , cover audio , and secret audio , enhance the reversibility of embed and extract message . to address common issue from time-frequency transformation that degrade secret audio quality during recovery , we implement a time-frequency loss on the time-domain signal . this approach not only retain the benefit of time-frequency constraint but also enhance the reversibility of message recovery , which be vital for practical application . we also add an encryption technique to protect the hidden data from unauthorized access . experimental result on the vctk and librispeech datasets demonstrate that our method outperform previous approach in term of subjective and objective metric and exhibit robustness to various type of noise , suggest it utility in targeted secure communication scenario .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02902	dmark : order-agnostic watermarking for diffusion large language model	Linyu Wu, Linhao Zhong, Wenjie Qu, Yuexin Li, Yue Liu, Shengfang Zhai, Chunhua Shen, Jiaheng Zhang	diffusion large language model ( dllms ) offer fast generation than autoregressive model while maintain comparable quality , but exist watermarking method fail on them due to their non-sequential decoding . unlike autoregressive model that generate token left-to-right , dllms can finalize token in arbitrary order , break the causal design underlying traditional watermark . we present dmark , the first watermarking framework design specifically for dllms . dmark introduces three complementary strategy to restore watermark detectability : predictive watermarking use model-predicted token when actual context be unavailable ; bidirectional watermarking exploit both forward and backward dependency unique to diffusion decoding ; and predictive-bidirectional watermarking combine both approach to maximize detection strength . experiment across multiple dllms show that dmark achieves 92.0-99.5 % detection rate at 1 % false positive rate while maintain text quality , compare to only 49.6-71.2 % for naive adaptation of exist method . dmark also demonstrate robustness against text manipulation , establish that effective watermarking be feasible for non-autoregressive language model .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02833	attack via overfitting : 10-shot benign fine-tuning to jailbreak llm	Zhixin Xie, Xurui Song, Jun Luo	despite substantial effort in safety alignment , recent research indicate that large language model ( llm ) remain highly susceptible to jailbreak attack . among these attack , finetuning-based one that compromise llm ' safety alignment via fine-tuning stand out due to it stable jailbreak performance . in particular , a recent study indicate that fine-tuning with as few a 10 harmful question-answer ( qa ) pair can lead to successful jailbreaking across various harmful question . however , such malicious fine-tuning attack be readily detectable and hence thwart by moderation model . in this paper , we demonstrate that llm can be jailbroken by fine-tuning with only 10 benign qa pair ; our attack exploit the increased sensitivity of llm to fine-tuning data after be overfitted . specifically , our fine-tuning process start with overfitting an llm via fine-tuning with benign qa pair involve identical refusal answer . further fine-tuning be then perform with standard benign answer , cause the overfitted llm to forget the refusal attitude and thus provide compliant answer regardless of the harmfulness of a question . we implement our attack on the ten llm and compare it with five exist baseline . experiment demonstrate that our method achieve significant advantage in both attack effectiveness and attack stealth . our finding expose previously unreported security vulnerability in current llm and provide a new perspective on understand how llms ' security be compromise , even with benign fine-tuning . our code be available at http : //github.com/zhixinxie/tenbenign .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02773	automate repair of openid connect program ( extended version )	Tamjid Al Rahat, Yanju Chen, Yu Feng, Yuan Tian	openid connect have revolutionize online authentication base on single sign-on ( sso ) by provide a secure and convenient method for access multiple service with a single set of credential . despite it widespread adoption , critical security bug in openid connect have result in significant financial loss and security breach , highlight the need for robust mitigation strategy . automate program repair present a promising solution for generate candidate patch for openid implementation . however , challenge such a domain-specific complexity and the necessity for precise fault localization and patch verification must be address . we propose authfix , a counterexample-guided repair engine leverage llm for automated openid bug fix . authfix integrate three key component : fault localization , patch synthesis , and patch verification . by employ a novel petri-net-based model checker , authfix ensure the correctness of patch by effectively model interaction . our evaluation on a dataset of openid bug demonstrate that authfix successfully generate correct patch for 17 out of 23 bug ( 74 % ) , with a high proportion of patch semantically equivalent to developer-written fix .	Cryptography and Security	03/10/2025
10.1016/j.array.2025.100501	cst-afnet : a dual attention-based deep learning framework for intrusion detection in iot network	Waqas Ishtiaq, Ashrafun Zannat, A. H. M. Shahariar Parvez, Md. Alamgir Hossain, Muntasir Hasan Kanchan, Muhammad Masud Tarek	the rapid expansion of the internet of thing ( iot ) have revolutionize modern industry by enable smart automation and real time connectivity . however , this evolution have also introduce complex cybersecurity challenge due to the heterogeneous , resource constrain , and distributed nature of these environment . to address these challenge , this research present cst afnet , a novel dual attention base deep learning framework specifically design for robust intrusion detection in iot network . the model integrate multi scale convolutional neural network ( cnns ) for spatial feature extraction , bidirectional gate recurrent unit ( bigrus ) for capture temporal dependency , and a dual attention mechanism , channel and temporal attention , to enhance focus on critical pattern in the data . the propose method be train and evaluate on the edge iiotset dataset , a comprehensive and realistic benchmark contain more than 2.2 million labeled instance span 15 attack type and benign traffic , collect from a seven layer industrial testbed . our propose model achieve outstanding accuracy for both 15 attack type and benign traffic . cst afnet achieve 99.97 percent accuracy . moreover , this model demonstrate exceptional performance with macro average precision , recall , and f1 score all above 99.3 percent . experimental result show that cst afnet achieves superior detection accuracy , significantly outperform traditional deep learning model . the finding confirm that cst afnet be a powerful and scalable solution for real time cyber threat detection in complex iot and iiot environment , pave the way for more secure , intelligent , and adaptive cyber physical system .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02711	a novel unified lightweight temporal-spatial transformer approach for intrusion detection in drone network	Tarun Kumar Biswas, Ashrafun Zannat, Waqas Ishtiaq, Md. Alamgir Hossain	the grow integration of drone across commercial , industrial , and civilian domain have introduce significant cybersecurity challenge , particularly due to the susceptibility of drone network to a wide range of cyberattacks . exist intrusion detection mechanism often lack the adaptability , efficiency , and generalizability require for the dynamic and resource constrain environment in which drone operate . this paper propose tslt-net , a novel lightweight and unified temporal spatial transformer base intrusion detection system tailor specifically for drone network . by leverage self attention mechanism , tslt-net effectively model both temporal pattern and spatial dependency in network traffic , enable accurate detection of diverse intrusion type . the framework include a streamlined preprocessing pipeline and support both multiclass attack classification and binary anomaly detection within a single architecture . extensive experiment conduct on the isot drone anomaly detection dataset , consist of more than 2.3 million label record , demonstrate the superior performance of tslt-net with 99.99 percent accuracy in multiclass detection and 100 percent in binary anomaly detection , while maintain a minimal memory footprint of only 0.04 mb and 9722 trainable parameter . these result establish tslt-net a an effective and scalable solution for real time drone cybersecurity , particularly suitable for deployment on edge device in mission critical uav system .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02707	a statistical method for attack-agnostic adversarial attack detection with compressive sense comparison	Chinthana Wimalasuriya, Spyros Tragoudas	adversarial attack present a significant threat to modern machine learn system . yet , exist detection method often lack the ability to detect unseen attack or detect different attack type with a high level of accuracy . in this work , we propose a statistical approach that establish a detection baseline before a neural network 's deployment , enable effective real-time adversarial detection . we generate a metric of adversarial presence by compare the behavior of a compressed/uncompressed neural network pair . our method have be test against state-of-the-art technique , and it achieve near-perfect detection across a wide range of attack type . moreover , it significantly reduce false positive , make it both reliable and practical for real-world application .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02694	malf : a multi-agent llm framework for intelligent fuzzing of industrial control protocol	Bowei Ning, Xuejun Zong, Kan He	industrial control system ( ic ) be vital to modern infrastructure but increasingly vulnerable to cybersecurity threat , particularly through weakness in their communication protocol . this paper present malf ( multi-agent llm fuzzing framework ) , an advanced fuzzing solution that integrate large language model ( llm ) with multi-agent coordination to identify vulnerability in industrial control protocol ( icps ) . by leverage retrieval-augmented generation ( rag ) for domain-specific knowledge and qlora fine-tuning for protocol-aware input generation , malf enhances fuzz test precision and adaptability . the multi-agent framework optimizes seed generation , mutation strategy , and feedback-driven refinement , lead to improve vulnerability discovery . experiment on protocol like modbus/tcp , s7comm , and ethernet/ip demonstrate that malf surpass traditional method , achieve a test case pas rate ( tcpr ) of 88-92 % and generate more exception trigger ( etn ) . malf also maintain over 90 % seed coverage and shannon entropy value between 4.2 and 4.6 bit , ensure diverse , protocol-compliant mutation . deploy in a real-world industrial attack-defense range for power plant , malf identify critical vulnerability , include three zero-day flaw , one confirmed and register by cnvd . these result validate malf 's effectiveness in real-world fuzzing application . this research highlight the transformative potential of multi-agent llm in ic cybersecurity , offer a scalable , automated framework that set a new standard for vulnerability discovery and strengthen critical infrastructure security against emerge threat .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02643	use preform resistive random access memory to create a strong physically unclonable function	Jack Garrard, John F. Hardy II, Carlo daCunha, Mayank Bakshi	physically unclonable function ( pufs ) be a promising solution for identity verification and asymmetric encryption . in this paper , a new resistive random access memory ( reram ) puf-based protocol be present to create a physical reram puf with a large challenge space . this protocol use differential read from unformed reram a the method for response generation . lastly , this paper also provide an experimental hardware demonstration of this protocol on a physical reram device , along with provide notable result a a puf , with excellent performance characteristic .	Cryptography and Security	03/10/2025
10.48550/arXiv.2510.02563	who 's wear ? ear canal biometric key extraction for user authentication on wireless earbuds	Chenpei Huang, Lingfeng Yao, Hui Zhong, Kyu In Lee, Lan Zhang, Xiaoyong Yuan, Tomoaki Ohtsuki, Miao Pan	ear canal scanning/sensing ( ec ) have emerge a a novel biometric authentication method for mobile device pair with wireless earbuds . exist study have demonstrate the uniqueness of ear canal by training and test machine learn classifier on ec data . however , implement practical ecs-based authentication require prevent raw biometric data leakage and design computationally efficient protocol suitable for resource-constrained earbuds . to address these challenge , we propose an ear canal key extraction protocol , \textbf { earid } . without rely on classifier , earid extract unique binary key directly on the earbuds during authentication . these key far allow the use of privacy-preserving fuzzy commitment scheme that verify the wearer 's key on mobile device . our evaluation result demonstrate that earid achieve a 98.7\ % authentication accuracy , comparable to machine learn classifier . the mobile enrollment time ( 160~ms ) and earbuds processing time ( 226~ms ) be negligible in term of wearer 's experience . moreover , our approach be robust and attack-resistant , maintain a false acceptance rate below 1\ % across all adversarial scenario . we believe the propose earid offer a practical and secure solution for next-generation wireless earbuds .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02554	tooltweak : an attack on tool selection in llm-based agent	Jonathan Sneh, Ruomei Yan, Jialin Yu, Philip Torr, Yarin Gal, Sunando Sengupta, Eric Sommerlade, Alasdair Paren, Adel Bibi	a llm increasingly power agent that interact with external tool , tool use have become an essential mechanism for extend their capability . these agent typically select tool from grow database or marketplace to solve user task , create implicit competition among tool provider and developer for visibility and usage . in this paper , we show that this selection process harbor a critical vulnerability : by iteratively manipulate tool name and description , adversary can systematically bias agent toward select specific tool , gain unfair advantage over equally capable alternative . we present tooltweak , a lightweight automatic attack that increase selection rate from a baseline of around 20 % to as high a 81 % , with strong transferability between open-source and closed-source model . beyond individual tool , we show that such attack cause distributional shift in tool usage , reveal risk to fairness , competition , and security in emerge tool ecosystem . to mitigate these risk , we evaluate two defense : paraphrasing and perplexity filtering , which reduce bias and lead agent to select functionally similar tool more equally . all code will be open-sourced upon acceptance .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02519	tlora : implementing tl over lora for secure http communication in iot	Atonu Ghosh, Akhilesh Mohanasundaram, Srishivanth R F, Sudip Misra	we present tlora , an end-to-end architecture for https communication over lora by integrate tcp tunneling and a complete tl 1.3 handshake . it enable a seamless and secure communication channel between wifi-enabled end device and the internet over lora use an end hub ( eh ) and a net relay ( nr ) . the eh tether a wifi hotspot and a captive portal for user device to connect and request url . the eh forward the requested url to the nr use a secure tunnel over lora . the nr , which act a a server-side proxy , receives and resolve the request from the internet-based server . it then relay back the encrypt response from the server over the same secure tunnel . tlora operate in three phase -session setup , secure tunneling , and render . in the first phase , it manage the tcp socket and initiate the tls handshake . in the second , it create a secure tunnel and transfer encrypt tl data over lora . finally , it deliver the url content to the user . tlora also implement a lightweight tl record reassembly layer and a queuing mechanism for session multiplexing . we evaluate tlora on real hardware use multiple access to a web api . result indicate that it provide a practical solution by successfully establish a tl session over lora in 9.9 second and take 3.58 second to fulfill api request . to the best of our knowledge , this be the first work to comprehensively design , implement , and evaluate the performance of https access over lora use full tl .	Cryptography and Security	02/10/2025
10.3390/act14100480	a bilevel optimization framework for adversarial control of gas pipeline operation	Tejaswini Sanjay Katale, Lu Gao, Yunpeng Zhang, Alaa Senouci	cyberattacks on pipeline operational technology system pose grow risk to energy infrastructure . this study develop a physics-informed simulation and optimization framework for analyze cyber-physical threat in petroleum pipeline network . the model integrate networked hydraulic dynamic , scada-based state estimation , model predictive control ( mpc ) , and a bi-level formulation for stealthy false-data injection ( fdi ) attack . pipeline flow and pressure dynamic be model on a direct graph use nodal pressure evolution and edge-based weymouth-type relation , include control-aware equipment such a valve and compressor . an extended kalman filter estimate the full network state from partial scada telemetry . the controller compute pressure-safe control input via mpc under actuator constraint and forecast demand . adversarial manipulation be formalize a a bi-level optimization problem where an attacker perturbs sensor data to degrade throughput while remain undetected by bad-data detector . this attack-control interaction be solve via karush-kuhn-tucker ( kkt ) reformulation , which result in a tractable mixed-integer quadratic program . test gas pipeline case study demonstrate the covert reduction of service delivery under attack . result show that undetectable attack can cause sustained throughput loss with minimal instantaneous deviation . this reveal the need for integrated detection and control strategy in cyber-physical infrastructure .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02487	interplay between security , privacy and trust in 6g-enabled intelligent transportation system	Ahmed Danladi Abdullahi, Erfan Bahrami, Tooska Dargahi, Mohammed Al-Khalidi, Mohammad Hammoudeh	the advancement of 6g technology have the potential to revolutionize the transportation sector and significantly improve how we travel . 6g-enabled intelligent transportation system ( it ) promise to offer high-speed , low-latency communication and advance data analytics capability , support the development of safer , more efficient , and more sustainable transportation solution . however , various security and privacy challenge be identify in the literature that must be address to enable the safe and secure deployment of 6g-its and ensure people 's trust in use these technology . this paper review the opportunity and challenge of 6g-its , particularly focus on trust , security , and privacy , with special attention to quantum technology that both enhance security through quantum key distribution and introduce new vulnerability . it discuss the potential benefit of 6g technology in the transportation sector , include improve communication , device interoperability support , data analytic capability , and increase automation for different component , such a transportation management and communication system . a taxonomy of different attack model in 6g-its be propose , and a comparison of the security threat in 5g-its and 6g-its be provide , along with potential mitigating solution . this research highlight the urgent need for a comprehensive , multi-layered security framework span physical infrastructure protection , network protocol security , data management safeguard , application security measure , and trust management system to effectively mitigate emerge security and privacy risk and ensure the integrity and resilience of future transportation ecosystem .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02475	rigorous evaluation of microarchitectural side-channels with statistical model check	Weihang Li, Pete Crowley, Arya Tschand, Yu Wang, Miroslav Pajic, Daniel Sorin	rigorous quantitative evaluation of microarchitectural side channel be challenge for two reason . first , the processor , attack , and defense often exhibit probabilistic behavior . these probabilistic behavior arise due to natural noise in system ( e.g. , from co-running process ) , probabilistic side channel attack , and probabilistic obfuscation defense . second , microprocessor be extremely complex . previous evaluation method have rely on abstract or simplify model , which be necessarily less detailed than real system or cycle-by-cycle simulator , and these model may miss important phenomenon . whereas a simple model may suffice for estimate performance , security issue frequently manifest in the detail . we address this challenge by introduce statistical model checking ( smc ) to the quantitative evaluation of microarchitectural side channel . smc be a rigorous statistical technique that can process the result of probabilistic experiment and provide statistical guarantee , and it have be use in compute application that depend heavily on statistical guarantee ( e.g. , medical implant , vehicular compute ) . with smc , we can treat processor a opaque box , and we do not have to abstract or simplify them . we demonstrate the effectiveness of smc through three case study , in which we experimentally show that smc can evaluate existing security vulnerability and defense and provide qualitatively similar conclusion with great statistical rigor , while make no simplifying assumption or abstraction . we also show that smc can enable a defender to quantify the amount of noise necessary to have a desired level of confidence that she have reduce an attacker 's probability of success to less than a desired threshold , thus provide the defender with an actionable plan for obfuscation via noise injection .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02280	an efficient quantum algorithm for compute $ s $ -units and it application	Jean-Francois Biasse, Fang Song	in this paper , we provide detail on the proof of the quantum polynomial time algorithm of biasse and song ( soda 16 ) for compute the $ s $ -unit group of a number field . this algorithm directly imply polynomial time method to calculate class group , s-class group , relative class group and the unit group , ray class group , solve the principal ideal problem , solve certain norm equation , and decompose ideal class in the ideal class group . additionally , combine with a result of cramer , ducas , peikert and regev ( eurocrypt 2016 ) , the resolution of the principal ideal problem allow one to find short generator of a principal ideal . likewise , method due to cramer , ducas and wesolowski ( eurocrypt 2017 ) use the resolution of the principal ideal problem and the decomposition of ideal class to find so-called `` mildly short vector '' in ideal lattice of cyclotomic field .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02251	reproducible build for quantum computing	Iyán Méndez Veiga, Esther Hänggi	reproducible build be a set of software development practice that establish an independently verifiable path from source code to binary artifact , help to detect and mitigate certain class of supply chain attack . although quantum computing be a rapidly evolve field of research , it can already benefit from adopt reproducible build . this paper aim to bridge the gap between the quantum computing and reproducible build community . we propose a generalization of the definition of reproducible build in the quantum setting , motivate by two threat model : one target the confidentiality of end user ' data during circuit preparation and submission to a quantum computer , and another compromise the integrity of quantum computation result . this work present three example that show how classical information can be hide in transpiled quantum circuit , and two case illustrate how even minimal modification to these circuit can lead to incorrect quantum computation result . our work provide initial step towards a framework for reproducibility in quantum software toolchains .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02424	adaptive deception framework with behavioral analysis for enhanced cybersecurity defense	Basil Abdullah AL-Zahrani	this paper present cadl ( cognitive-adaptive deception layer ) , an adaptive deception framework achieve 99.88 % detection rate with 0.13 % false positive rate on the cicids2017 dataset . the framework employ ensemble machine learning ( random forest , xgboost , neural network ) combine with behavioral profile to identify and adapt response to network intrusion . through a coordinated signal bus architecture , security component share real-time intelligence , enable collective decision-making . the system profile attacker base on temporal pattern and deploy customized deception strategy across five escalation level . evaluation on 50,000 cicids2017 test sample demonstrate that cadl significantly outperform traditional intrusion detection system ( snort : 71.2 % , suricata : 68.5 % ) while maintain production-ready false positive rate . the framework 's behavioral analysis achieve 89 % accuracy in classify attacker profile . we provide open-source implementation and transparent performance metric , offer an accessible alternative to commercial deception platform cost $ 150-400 per host annually .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02196	authentication security of prf gnss range	Jason Anderson	this work derive the authentication security of pseudorandom function ( prf ) gnss range under multiple gnss spoofing model , include the security code estimation and replay ( scer ) spoofer . when gnss range code derive from a prf utilize a secret know only to the broadcaster , the spoofer can not predict the range code before broadcast . therefore , prf range can be use to establish trust in the gnss pseudoranges and the result receiver position , navigation , and timing ( pnt ) solution . i apply the method herein to galileo 's signal authentication service ( sa ) utilize the encrypted galileo e6-c signal to compute that , at most , 400 m of galileo e6-c data to assert 128-bit authentication security under non-scer model . for the scer adversary , i predict the adversary 's need receiving radio equipment to break authentication security . one can use this work to design a prf gnss range protocol to meet useful authentication security requirement by compute the probability of missed detection .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02194	upsafe $ ^\circ $ c : upcycling for controllable safety in large language model	Yuhao Sun, Zhuoer Xu, Shiwen Cui, Kun Yang, Lingyun Yu, Yongdong Zhang, Hongtao Xie	large language model ( llm ) have achieve remarkable progress across a wide range of task , but remain vulnerable to safety risk such a harmful content generation and jailbreak attack . exist safety technique -- include external guardrail , inference-time guidance , and post-training alignment -- each face limitation in balance safety , utility , and controllability . in this work , we propose upsafe $ ^\circ $ c , a unified framework for enhance llm safety through safety-aware upcycling . our approach first identify safety-critical layer and upcycles them into a sparse mixture-of-experts ( moe ) structure , where the router act a a soft guardrail that selectively activate original mlps and add safety expert . we further introduce a two-stage sft strategy to strengthen safety discrimination while preserve general capability . to enable flexible control at inference time , we introduce a safety temperature mechanism , allow dynamic adjustment of the trade-off between safety and utility . experiment across multiple benchmark , base model , and model scale demonstrate that upsafe $ ^\circ $ c achieve robust safety improvement against harmful and jailbreak input , while maintain competitive performance on general task . moreover , analysis show that safety temperature provide fine-grained inference-time control that achieve the pareto-optimal frontier between utility and safety . our result highlight a new direction for llm safety : move from static alignment toward dynamic , modular , and inference-aware control .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02422	dynamic target attack	Kedong Xiu, Churui Zeng, Tianhang Zheng, Xinzhe Huang, Xiaojun Jia, Di Wang, Puning Zhao, Zhan Qin, Kui Ren	exist gradient-based jailbreak attack typically optimize an adversarial suffix to induce a fixed affirmative response . however , this fixed target usually reside in an extremely low-density region of a safety-aligned llm 's output distribution condition on diverse harmful input . due to the substantial discrepancy between the target and the original output , exist attack require numerous iteration to optimize the adversarial prompt , which might still fail to induce the low-probability target response from the target llm . in this paper , we propose dynamic target attack ( dta ) , a new jailbreaking framework rely on the target llm 's own response a target to optimize the adversarial prompt . in each optimization round , dta iteratively sample multiple candidate response directly from the output distribution condition on the current prompt , and select the most harmful response a a temporary target for prompt optimization . in contrast to exist attack , dta significantly reduce the discrepancy between the target and the output distribution , substantially ease the optimization process to search for an effective adversarial prompt . extensive experiment demonstrate the superior effectiveness and efficiency of dta : under the white-box setting , dta only need 200 optimization iteration to achieve an average attack success rate ( asr ) of over 87\ % on recent safety-aligned llm , exceed the state-of-the-art baseline by over 15\ % . the time cost of dta be 2-26 time less than exist baseline . under the black-box setting , dta use llama-3-8b-instruct a a surrogate model for target sampling and achieve an asr of 85\ % against the black-box target model llama-3-70b-instruct , exceed it counterpart by over 25\ % .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02185	falsecrashreducer : mitigating false positive crash in oss-fuzz-gen use agentic ai	Paschal C. Amusuo, Dongge Liu, Ricardo Andres Calvo Mendez, Jonathan Metzman, Oliver Chang, James C. Davis	fuzz testing have become a cornerstone technique for identify software bug and security vulnerability , with broad adoption in both industry and open-source community . directly fuzzing a function require fuzz driver , which translate random fuzzer input into valid argument for the target function . give the cost and expertise require to manually develop fuzz driver , method exist that leverage program analysis and large language model to automatically generate these driver . however , the generated fuzz driver frequently lead to false positive crash , especially in function highly structure input and complex state requirement . this problem be especially crucial in industry-scale fuzz driver generation effort like oss-fuzz-en , a report false positive crash to maintainer impede trust in both the system and the team . this paper present two ai-driven strategy to reduce false positive in oss-fuzz-gen , a multi-agent system for automated fuzz driver generation . first , constraint-based fuzz driver generation proactively enforce constraint on a function 's input and state to guide driver creation . second , context-based crash validation reactively analyze function caller to determine whether report crash be feasible from program entry point . use 1,500 benchmark function from oss-fuzz , we show that these strategy reduce spurious crash by up to 8 % , cut report crash by more than half , and demonstrate that frontier llm can serve a reliable program analysis agent . our result highlight the promise and challenge of integrate ai into large-scale fuzzing pipeline .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02169	taibom : bringing trustworthiness to ai-enabled system	Vadim Safronov, Anthony McCaigue, Nicholas Allott, Andrew Martin	the grow integration of open-source software and ai-driven technology have introduce new layer of complexity into the software supply chain , challenge exist method for dependency management and system assurance . while software bill of material ( sboms ) have become critical for enhance transparency and traceability , current framework fall short in capture the unique characteristic of ai system -- namely , their dynamic , data-driven nature and the loosely coupled dependency across datasets , model , and software component . these challenge be compound by fragmented governance structure and the lack of robust tool for ensure integrity , trust , and compliance in ai-enabled environment . in this paper , we introduce trust ai bill of material ( taibom ) -- a novel framework extend sbom principle to the ai domain . taibom provide ( i ) a structured dependency model tailor for ai component , ( ii ) mechanism for propagate integrity statement across heterogeneous ai pipeline , and ( iii ) a trust attestation process for verify component provenance . we demonstrate how taibom support assurance , security , and compliance across ai workflow , highlight it advantage over exist standard such a spdx and cyclonedx . this work lay the foundation for trustworthy and verifiable ai system through structured software transparency .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02162	nomod : a non-modular attack on module learn with error	Cristian Bassotto, Ermes Franch, Marina Krček, Stjepan Picek	the advent of quantum compute threatens classical public-key cryptography , motivate nist 's adoption of post-quantum scheme such a those base on the module learn with error ( module-lwe ) problem . we present nomod ml-attack , a hybrid white-box cryptanalytic method that circumvent the challenge of model modular reduction by treat wrap-arounds a statistical corruption and casting secret recovery a robust linear estimation . our approach combine optimize lattice preprocessing -- include reduced-vector saving and algebraic amplification -- with robust estimator train via tukey 's biweight loss . experiment show nomod achieves full recovery of binary secret for dimension $ n = 350 $ , recovery of sparse binomial secret for $ n = 256 $ , and successful recovery of sparse secret in crystals-kyber setting with parameter $ ( n , k ) = ( 128 , 3 ) $ and $ ( 256 , 2 ) $ . we release our implementation in an anonymous repository http : //anonymous.4open.science/r/nomod-3bd4 .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.02158	mirage fool the ear , mute hide the truth : precise target adversarial attack on polyphonic sound event detection system	Junjie Su, Weifei Jin, Yuxin Cao, Derui Wang, Kai Ye, Jie Hao	sound event detection ( sed ) system be increasingly deploy in safety-critical application such a industrial monitoring and audio surveillance . however , their robustness against adversarial attack have not be well explore . exist audio adversarial attack target sed system , which incorporate both detection and localization capability , often lack effectiveness due to sed 's strong contextual dependency or lack precision by focus solely on misclassifying the target region a the target event , inadvertently affect non-target region . to address these challenge , we propose the mirage and mute attack ( m2a ) framework , which be design for target adversarial attack on polyphonic sed system . in our optimization process , we impose specific constraint on the non-target output , which we refer to a preservation loss , ensure that our attack do not alter the model output for non-target region , thus achieve precise attack . furthermore , we introduce a novel evaluation metric edit precison ( ep ) that balance effectiveness and precision , enable our method to simultaneously enhance both . comprehensive experiment show that m2a achieve 94.56 % and 99.11 % ep on two state-of-the-art sed model , demonstrate that the framework be sufficiently effective while significantly enhance attack precision .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01967	zk-wagon : imperceptible watermark for image generation model use zk-snarks	Aadarsh Anantha Ramakrishnan, Shubham Agarwal, Selvanayagam S, Kunwar Singh	a image generation model grow increasingly powerful and accessible , concern around authenticity , ownership , and misuse of synthetic medium have become critical . the ability to generate lifelike image indistinguishable from real one introduces risk such a misinformation , deepfakes , and intellectual property violation . traditional watermarking method either degrade image quality , be easily remove , or require access to confidential model internals - make them unsuitable for secure and scalable deployment . we be the first to introduce zk-wagon , a novel system for watermarking image generation model use the zero-knowledge succinct non interactive argument of knowledge ( zk-snarks ) . our approach enable verifiable proof of origin without expose model weight , generation prompt , or any sensitive internal information . we propose selective layer zk-circuit creation ( sl-zkcc ) , a method to selectively convert key layer of an image generation model into a circuit , reduce proof generation time significantly . generate zk-snark proof be imperceptibly embed into a generated image via least significant bit ( lsb ) steganography . we demonstrate this system on both gan and diffusion model , provide a secure , model-agnostic pipeline for trustworthy ai image generation .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01780	secure multi-modal data fusion in federated digital health system via mcp	Aueaphum Aueawatthanaphisut	secure and interoperable integration of heterogeneous medical data remain a grand challenge in digital health . current federate learning ( fl ) frameworks offer privacy-preserving model training but lack standardized mechanism to orchestrate multi-modal data fusion across distribute and resource-constrained environment . this study introduce a novel framework that leverage the model context protocol ( mcp ) a an interoperability layer for secure , cross-agent communication in multi-modal federated healthcare system . the proposed architecture unifies three pillar : ( i ) multi-modal feature alignment for clinical imaging , electronic medical record , and wearable iot data ; ( ii ) secure aggregation with differential privacy to protect patient-sensitive update ; and ( iii ) energy-aware schedule to mitigate dropout in mobile client . by employ mcp a a schema-driven interface , the framework enable adaptive orchestration of ai agent and toolchains while ensure compliance with privacy regulation . experimental evaluation on benchmark datasets and pilot clinical cohort demonstrate up to 9.8\ % improvement in diagnostic accuracy compare with baseline fl , a 54\ % reduction in client dropout rate , and clinically acceptable privacy -- utility trade-off . these result highlight mcp-enabled multi-modal fusion a a scalable and trustworthy pathway toward equitable , next-generation federate health infrastructure .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01720	construction of efficiently implementable boolean function with provable nonlinearity/resiliency/algebraic immunity trade-off	Palash Sarkar	we describe several family of efficiently implementable boolean function achieve provable trade-off between resiliency , nonlinearity , and algebraic immunity . in particular , the following statement hold for each of the function family that we propose . give integer $ m_0\geq 0 $ , $ x_0\geq 1 $ , and $ a_0\geq 1 $ , it be possible to construct an $ n $ -variable function which have resiliency at least $ m_0 $ , linear bias ( which be an equivalent method of express nonlinearity ) at most $ 2^ { -x_0 } $ and algebraic immunity at least $ a_0 $ ; further , $ n $ be linear in $ m_0 $ , $ x_0 $ and $ a_0 $ , and the function can be implement use $ o ( n ) $ 2-input gate , which be essentially optimal .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01699	towards imperceptible adversarial defense : a gradient-driven shield against facial manipulation	Yue Li, Linying Xue, Dongdong Lin, Qiushi Li, Hui Tian, Hongxia Wang	with the flourish prosperity of generative model , manipulate facial image have become increasingly accessible , raise concern regard privacy infringement and societal trust . in response , proactive defense strategy embed adversarial perturbation into facial image to counter deepfake manipulation . however , exist method often face a tradeoff between imperceptibility and defense effectiveness-strong perturbation may disrupt forgery but degrade visual fidelity . recent study have attempt to address this issue by introduce additional visual loss constraint , yet often overlook the underlying gradient conflict among loss , ultimately weaken defense performance . to bridge the gap , we propose a gradient-projection-based adversarial proactive defense ( grasp ) method that effectively counter facial deepfakes while minimize perceptual degradation . grasp be the first approach to successfully integrate both structural similarity loss and low-frequency loss to enhance perturbation imperceptibility . by analyze gradient conflict between defense effectiveness loss and visual quality loss , grasp pioneer the design of the gradient-projection mechanism to mitigate these conflict , enable balance optimization that preserve image fidelity without sacrifice defensive performance . extensive experiment validate the efficacy of grasp , achieve a psnr exceed 40 db , ssim of 0.99 , and a 100 % defense success rate against facial attribute manipulation , significantly outperform exist approach in visual quality .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01676	evaluate the robustness of a production malware detection system to transferable adversarial attack	Milad Nasr, Yanick Fratantonio, Luca Invernizzi, Ange Albertini, Loua Farah, Alex Petit-Bianco, Andreas Terzis, Kurt Thomas, Elie Bursztein, Nicholas Carlini	a deep learning model become widely deploy a component within large production system , their individual shortcoming can create system-level vulnerability with real-world impact . this paper study how adversarial attack target an ml component can degrade or bypass an entire production-grade malware detection system , perform a case study analysis of gmail 's pipeline where file-type identification relies on a ml model . the malware detection pipeline in use by gmail contains a machine learn model that rout each potential malware sample to a specialize malware classifier to improve accuracy and performance . this model , call magika , have be open source . by design adversarial example that fool magika , we can cause the production malware service to incorrectly route malware to an unsuitable malware detector thereby increase our chance of evade detection . specifically , by change just 13 byte of a malware sample , we can successfully evade magika in 90 % of case and thereby allow u to send malware file over gmail . we then turn our attention to defense , and develop an approach to mitigate the severity of these type of attack . for our defended production model , a highly resourced adversary require 50 byte to achieve just a 20 % attack success rate . we implement this defense , and , thanks to a collaboration with google engineer , it have already be deploy in production for the gmail classifier .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01670	just do it ! ? computer-use agent exhibit blind goal-directedness	Erfan Shayegani, Keegan Hines, Yue Dong, Nael Abu-Ghazaleh, Roman Lutz, Spencer Whitehead, Vidhisha Balachandran, Besmira Nushi, Vibhav Vineet	computer-use agent ( cuas ) be an increasingly deployed class of agent that take action on gui to accomplish user goal . in this paper , we show that cuas consistently exhibit blind goal-directedness ( bgd ) : a bias to pursue goal regardless of feasibility , safety , reliability , or context . we characterize three prevalent pattern of bgd : ( i ) lack of contextual reasoning , ( ii ) assumption and decision under ambiguity , and ( iii ) contradictory or infeasible goal . we develop blind-act , a benchmark of 90 task capture these three pattern . build on osworld , blind-act provide realistic environment and employ llm-based judge to evaluate agent behavior , achieve 93.75 % agreement with human annotation . we use blind-act to evaluate nine frontier model , include claude sonnet and opus 4 , computer-use-preview , and gpt-5 , observe high average bgd rate ( 80.8 % ) across them . we show that bgd expose subtle risk that arise even when input be not directly harmful . while prompting-based intervention low bgd level , substantial risk persists , highlight the need for strong training- or inference-time intervention . qualitative analysis reveals observe failure mode : execution-first bias ( focus on how to act over whether to act ) , thought-action disconnect ( execution diverge from reason ) , and request-primacy ( justify action due to user request ) . identify bgd and introduce blind-act establishes a foundation for future research on study and mitigate this fundamental risk and ensure safe cua deployment .	Cryptography and Security	02/10/2025
10.48550/arXiv.2510.01645	position : privacy be not just memorization !	Niloofar Mireshghallah, Tianshi Li	the discourse on privacy risk in large language model ( llm ) have disproportionately focus on verbatim memorization of training data , while a constellation of more immediate and scalable privacy threat remain underexplored . this position paper argue that the privacy landscape of llm system extend far beyond train data extraction , encompass risk from data collection practice , inference-time context leakage , autonomous agent capability , and the democratization of surveillance through deep inference attack . we present a comprehensive taxonomy of privacy risk across the llm lifecycle -- from data collection through deployment -- and demonstrate through case study how current privacy framework fail to address these multifaceted threat . through a longitudinal analysis of 1,322 ai/ml privacy paper publish at leading conference over the past decade ( 2016 -- 2025 ) , we reveal that while memorization receives outsized attention in technical research , the most pressing privacy harm lie elsewhere , where current technical approach offer little traction and viable path forward remain unclear . we call for a fundamental shift in how the research community approach llm privacy , move beyond the narrow focus of current technical solution and embrace interdisciplinary approach that address the sociotechnical nature of these emerge threat .	Cryptography and Security	02/10/2025
