# Sistema de Similitud de Documentos

Este proyecto implementa una **tuber√≠a completa de procesamiento de lenguaje natural (PLN)** para la **b√∫squeda, normalizaci√≥n, representaci√≥n y comparaci√≥n de art√≠culos cient√≠ficos** obtenidos de los repositorios **arXiv** y **PubMed**.  

Su prop√≥sito es identificar los documentos m√°s similares a partir de una consulta, aplicando t√©cnicas de **vectorizaci√≥n** y **similitud coseno**.

---

## üß† Descripci√≥n General

El sistema realiza las siguientes tareas:

1. **Recolecci√≥n** de art√≠culos cient√≠ficos mediante *web scraping*.  
2. **Normalizaci√≥n** del texto (tokenizaci√≥n, lematizaci√≥n y eliminaci√≥n de palabras vac√≠as).  
3. **Representaci√≥n vectorial** del texto utilizando modelos de frecuencia, binario y TF-IDF.  
4. **Comparaci√≥n de similitud** entre art√≠culos mediante el c√°lculo de la similitud coseno.  

Con esto, se logra una recuperaci√≥n eficiente de los art√≠culos m√°s parecidos a una consulta dada (por t√≠tulo o resumen).

---

## ‚öôÔ∏è Componentes Principales

### 1. Recolecci√≥n de Art√≠culos (`web_scrapping.py`)
Obtiene art√≠culos recientes desde los siguientes repositorios:

- **arXiv:** Computation and Language, Computer Vision and Pattern Recognition, Cryptography and Security.  
- **PubMed:** Art√≠culos de la secci√≥n *Trending*.

Datos recolectados:
- DOI  
- T√≠tulo  
- Autores  
- Resumen  
- Secci√≥n o Revista  
- Fecha de publicaci√≥n  

Los art√≠culos se guardan en archivos CSV separados por tabulaciones.

---

### 2. Normalizaci√≥n del Texto

#### üîπ Usando NLTK 
- Tokenizaci√≥n  
- Etiquetado gramatical (POS tagging)  
- Eliminaci√≥n de *stop words* (art√≠culos, preposiciones, conjunciones y pronombres)  
- Lematizaci√≥n con **WordNetLemmatizer**


---

### 3. Representaci√≥n Vectorial (`vectorizacion.py`)
Genera representaciones num√©ricas de los textos mediante tres m√©todos:

- **Frecuencia (CountVectorizer)**  
- **Binaria (CountVectorizer con binary=True)**  
- **TF-IDF (TfidfVectorizer)**  

Rangos de n-gramas:
- Unigramas `(1,1)`  
- Bigramas `(2,2)`  
- Combinados `(1,3)`

Las representaciones se guardan como archivos `.pkl` para su reutilizaci√≥n.

---

### 4. Similitud de Documentos (`document_similarity 1.py`)
Calcula la **similitud coseno** entre los vectores de los documentos:

\[
\text{Similitud}(x, y) = \frac{\sum_i x_i y_i}{\sqrt{\sum_i x_i^2} \sqrt{\sum_i y_i^2}}
\]

El sistema muestra los **10 documentos m√°s similares** en orden descendente, permitiendo comparar art√≠culos por su t√≠tulo o resumen.

---

## üß© Flujo de Trabajo

1. **Recolectar** art√≠culos ‚Üí `web_scrapping.py`  
2. **Normalizar** el corpus ‚Üí `normalization_nltk_english.py` o `normalization_spacy_english.py`  
3. **Vectorizar** el texto ‚Üí `vectorizacion.py`  
4. **Comparar** documentos ‚Üí `document_similarity 1.py`  

---

## üñ•Ô∏è Interfaz

Se puede a√±adir una interfaz gr√°fica para facilitar:
- La recolecci√≥n de art√≠culos.  
- La normalizaci√≥n y vectorizaci√≥n del corpus.  
- La comparaci√≥n y visualizaci√≥n de art√≠culos similares.  

---

## üìà Resultados Esperados

Archivos generados:
- `arxiv_raw_corpus.csv`, `pubmed_raw_corpus.csv`  
- `arxiv_normalized_corpus.csv`, `pubmed_normalized_corpus.csv`  
- Archivos `.pkl` de representaciones vectoriales  
- Archivos `.tsv` o `.csv` con los resultados de similitud  

---

## üß∞ Tecnolog√≠as Utilizadas

- **Python 3**
- **BeautifulSoup4**
- **Requests**
- **NLTK**
- **spaCy**
- **scikit-learn**
- **pandas**
- **pickle**

---

## üë©‚Äçüíª Autores

Proyecto desarrollado con fines acad√©micos e investigativos, orientado al **procesamiento de lenguaje natural** y **recuperaci√≥n de informaci√≥n** a partir de repositorios cient√≠ficos de libre acceso.

---

## üìú Licencia

Este proyecto se distribuye bajo la licencia **MIT**, y su uso est√° permitido con fines acad√©micos y de investigaci√≥n.

